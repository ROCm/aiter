============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-7.3.2, pluggy-1.6.0 -- /opt/venv/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('/workspace/aiter/.hypothesis/examples')
rootdir: /workspace/aiter
plugins: hypothesis-5.35.1, xdist-3.3.1, subtests-0.13.1, shard-0.1.2, xdoctest-1.1.0, rerunfailures-14.0, flakefinder-1.1.0, cpp-2.3.0
collecting ... [aiter] import [module_aiter_enum] under /workspace/aiter/aiter/jit/module_aiter_enum.so
collected 659 items
Running 659 items in this shard: op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-256], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-16-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2048-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-7168], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-2112], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-256], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-16-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2048-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-7168], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-2112], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-1-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-1-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-1-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-1-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-2-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-2-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-2-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-2-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-4-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-8-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-8-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-8-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-256], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-16-4096], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2048-4-512], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-7168], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-2112], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_epsilon[32-4-1024-1e-06], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_epsilon[32-4-1024-1e-05], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_epsilon[32-4-1024-1e-08], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[0.1], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[0.5], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[1.0], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[2.0], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[10.0], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_zero_input, op_tests/triton_tests/fusions/test_mhc.py::test_mhc_large_values, op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype0-32-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype0-64-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype0-128-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype1-32-4-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype1-64-4-2048], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype1-128-8-1024], op_tests/triton_tests/fusions/test_mhc.py::test_mhc_output_range, op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-1-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-1-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-1-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-1-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-1-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-4-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-4-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-4-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-4-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-4-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-16-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-16-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-16-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-16-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-16-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-64-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-64-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-64-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-64-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-64-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-256-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-256-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-256-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-256-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-256-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-1-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-1-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-1-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-1-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-1-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-4-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-4-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-4-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-4-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-4-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-16-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-16-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-16-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-16-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-16-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-64-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-64-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-64-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-64-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-64-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-256-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-256-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-256-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-256-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-256-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[1-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[1-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[1-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[1-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[1-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[4-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[4-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[4-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[4-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[4-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[16-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[16-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[16-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[16-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[16-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[64-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[64-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[64-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[64-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[64-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[256-2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[256-4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[256-8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[256-16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[256-32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_different_iters[5], op_tests/triton_tests/fusions/test_mhc.py::test_sk_different_iters[10], op_tests/triton_tests/fusions/test_mhc.py::test_sk_different_iters[20], op_tests/triton_tests/fusions/test_mhc.py::test_sk_different_iters[50], op_tests/triton_tests/fusions/test_mhc.py::test_sk_batch_sizes[1], op_tests/triton_tests/fusions/test_mhc.py::test_sk_batch_sizes[4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_batch_sizes[16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_batch_sizes[64], op_tests/triton_tests/fusions/test_mhc.py::test_sk_batch_sizes[256], op_tests/triton_tests/fusions/test_mhc.py::test_sk_batch_sizes[1024], op_tests/triton_tests/fusions/test_mhc.py::test_sk_matrix_sizes[2], op_tests/triton_tests/fusions/test_mhc.py::test_sk_matrix_sizes[4], op_tests/triton_tests/fusions/test_mhc.py::test_sk_matrix_sizes[8], op_tests/triton_tests/fusions/test_mhc.py::test_sk_matrix_sizes[16], op_tests/triton_tests/fusions/test_mhc.py::test_sk_matrix_sizes[32], op_tests/triton_tests/fusions/test_mhc.py::test_sk_matrix_sizes[64], op_tests/triton_tests/fusions/test_mhc.py::test_sk_numerical_stability_small_values, op_tests/triton_tests/fusions/test_mhc.py::test_sk_log_domain_stability_large_values[10.0], op_tests/triton_tests/fusions/test_mhc.py::test_sk_log_domain_stability_large_values[20.0], op_tests/triton_tests/fusions/test_mhc.py::test_sk_preallocated_output, op_tests/triton_tests/fusions/test_mhc.py::test_sk_identity_initialization, op_tests/triton_tests/fusions/test_mhc.py::test_sk_uniform_input, op_tests/triton_tests/fusions/test_mhc.py::test_sk_convergence, op_tests/triton_tests/fusions/test_mhc.py::test_sk_output_range

op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-256] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-16-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2048-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-7168] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-2112] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-256] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-16-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2048-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-7168] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-2112] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-1-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-1-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-1-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-1-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-2-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-2-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-2-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-2-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-4-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-8-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-8-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-8-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-256] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-16-4096] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2048-4-512] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-7168] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-2112] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_epsilon[32-4-1024-1e-06] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_epsilon[32-4-1024-1e-05] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_epsilon[32-4-1024-1e-08] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[0.1] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[0.5] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[1.0] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[2.0] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[10.0] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_zero_input FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_large_values FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype0-32-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype0-64-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype0-128-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype1-32-4-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype1-64-4-2048] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype1-128-8-1024] FAILED
op_tests/triton_tests/fusions/test_mhc.py::test_mhc_output_range PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-1-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-1-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-1-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-1-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-1-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-4-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-4-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-4-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-4-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-4-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-16-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-16-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-16-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-16-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-16-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-64-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-64-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-64-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-64-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-64-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-256-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-256-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-256-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-256-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype0-256-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-1-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-1-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-1-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-1-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-1-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-4-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-4-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-4-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-4-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-4-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-16-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-16-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-16-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-16-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-16-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-64-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-64-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-64-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-64-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-64-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-256-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-256-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-256-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-256-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_correctness[dtype1-256-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[1-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[1-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[1-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[1-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[1-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[4-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[4-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[4-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[4-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[4-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[16-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[16-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[16-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[16-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[16-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[64-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[64-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[64-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[64-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[64-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[256-2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[256-4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[256-8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[256-16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_doubly_stochastic[256-32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_different_iters[5] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_different_iters[10] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_different_iters[20] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_different_iters[50] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_batch_sizes[1] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_batch_sizes[4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_batch_sizes[16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_batch_sizes[64] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_batch_sizes[256] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_batch_sizes[1024] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_matrix_sizes[2] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_matrix_sizes[4] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_matrix_sizes[8] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_matrix_sizes[16] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_matrix_sizes[32] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_matrix_sizes[64] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_numerical_stability_small_values PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_log_domain_stability_large_values[10.0] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_log_domain_stability_large_values[20.0] PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_preallocated_output PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_identity_initialization PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_uniform_input PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_convergence PASSED
op_tests/triton_tests/fusions/test_mhc.py::test_sk_output_range PASSED

=================================== FAILURES ===================================
_____________________ test_mhc_correctness[dtype0-1-1-512] _____________________

M = 1, n = 1, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-1-1024] _____________________

M = 1, n = 1, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-1-2048] _____________________

M = 1, n = 1, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-1-4096] _____________________

M = 1, n = 1, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-1-2-512] _____________________

M = 1, n = 2, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-2-1024] _____________________

M = 1, n = 2, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-2-2048] _____________________

M = 1, n = 2, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-2-4096] _____________________

M = 1, n = 2, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-1-4-512] _____________________

M = 1, n = 4, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-4-1024] _____________________

M = 1, n = 4, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-4-2048] _____________________

M = 1, n = 4, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-4-4096] _____________________

M = 1, n = 4, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-1-8-512] _____________________

M = 1, n = 8, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-8-1024] _____________________

M = 1, n = 8, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-8-2048] _____________________

M = 1, n = 8, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-8-4096] _____________________

M = 1, n = 8, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-2-1-512] _____________________

M = 2, n = 1, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-2-1-1024] _____________________

M = 2, n = 1, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-2-1-2048] _____________________

M = 2, n = 1, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-2-1-4096] _____________________

M = 2, n = 1, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-2-2-512] _____________________

M = 2, n = 2, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-2-2-1024] _____________________

M = 2, n = 2, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-2-2-2048] _____________________

M = 2, n = 2, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-2-2-4096] _____________________

M = 2, n = 2, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-2-4-512] _____________________

M = 2, n = 4, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-2-4-1024] _____________________

M = 2, n = 4, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-2-4-2048] _____________________

M = 2, n = 4, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-2-4-4096] _____________________

M = 2, n = 4, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-2-8-512] _____________________

M = 2, n = 8, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-2-8-1024] _____________________

M = 2, n = 8, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-2-8-2048] _____________________

M = 2, n = 8, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-2-8-4096] _____________________

M = 2, n = 8, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-4-1-512] _____________________

M = 4, n = 1, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-4-1-1024] _____________________

M = 4, n = 1, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-4-1-2048] _____________________

M = 4, n = 1, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-4-1-4096] _____________________

M = 4, n = 1, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-4-2-512] _____________________

M = 4, n = 2, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-4-2-1024] _____________________

M = 4, n = 2, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-4-2-2048] _____________________

M = 4, n = 2, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-4-2-4096] _____________________

M = 4, n = 2, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-4-4-512] _____________________

M = 4, n = 4, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-4-4-1024] _____________________

M = 4, n = 4, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-4-4-2048] _____________________

M = 4, n = 4, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-4-4-4096] _____________________

M = 4, n = 4, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-4-8-512] _____________________

M = 4, n = 8, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-4-8-1024] _____________________

M = 4, n = 8, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-4-8-2048] _____________________

M = 4, n = 8, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-4-8-4096] _____________________

M = 4, n = 8, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-8-1-512] _____________________

M = 8, n = 1, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-8-1-1024] _____________________

M = 8, n = 1, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-8-1-2048] _____________________

M = 8, n = 1, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-8-1-4096] _____________________

M = 8, n = 1, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-8-2-512] _____________________

M = 8, n = 2, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-8-2-1024] _____________________

M = 8, n = 2, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-8-2-2048] _____________________

M = 8, n = 2, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-8-2-4096] _____________________

M = 8, n = 2, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-8-4-512] _____________________

M = 8, n = 4, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-8-4-1024] _____________________

M = 8, n = 4, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-8-4-2048] _____________________

M = 8, n = 4, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-8-4-4096] _____________________

M = 8, n = 4, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-8-8-512] _____________________

M = 8, n = 8, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-8-8-1024] _____________________

M = 8, n = 8, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-8-8-2048] _____________________

M = 8, n = 8, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-8-8-4096] _____________________

M = 8, n = 8, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-1-512] _____________________

M = 16, n = 1, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-1-1024] ____________________

M = 16, n = 1, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-1-2048] ____________________

M = 16, n = 1, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-1-4096] ____________________

M = 16, n = 1, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-2-512] _____________________

M = 16, n = 2, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-2-1024] ____________________

M = 16, n = 2, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-2-2048] ____________________

M = 16, n = 2, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-2-4096] ____________________

M = 16, n = 2, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-4-512] _____________________

M = 16, n = 4, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-4-1024] ____________________

M = 16, n = 4, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-4-2048] ____________________

M = 16, n = 4, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-4-4096] ____________________

M = 16, n = 4, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-8-512] _____________________

M = 16, n = 8, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-8-1024] ____________________

M = 16, n = 8, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-8-2048] ____________________

M = 16, n = 8, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-16-8-4096] ____________________

M = 16, n = 8, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-1-512] _____________________

M = 32, n = 1, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-1-1024] ____________________

M = 32, n = 1, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-1-2048] ____________________

M = 32, n = 1, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-1-4096] ____________________

M = 32, n = 1, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-2-512] _____________________

M = 32, n = 2, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-2-1024] ____________________

M = 32, n = 2, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-2-2048] ____________________

M = 32, n = 2, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-2-4096] ____________________

M = 32, n = 2, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-4-512] _____________________

M = 32, n = 4, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-4-1024] ____________________

M = 32, n = 4, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-4-2048] ____________________

M = 32, n = 4, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-4-4096] ____________________

M = 32, n = 4, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-8-512] _____________________

M = 32, n = 8, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-8-1024] ____________________

M = 32, n = 8, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-8-2048] ____________________

M = 32, n = 8, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-32-8-4096] ____________________

M = 32, n = 8, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-1-512] _____________________

M = 64, n = 1, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-1-1024] ____________________

M = 64, n = 1, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-1-2048] ____________________

M = 64, n = 1, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-1-4096] ____________________

M = 64, n = 1, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-2-512] _____________________

M = 64, n = 2, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-2-1024] ____________________

M = 64, n = 2, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-2-2048] ____________________

M = 64, n = 2, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-2-4096] ____________________

M = 64, n = 2, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-4-512] _____________________

M = 64, n = 4, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-4-1024] ____________________

M = 64, n = 4, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-4-2048] ____________________

M = 64, n = 4, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-4-4096] ____________________

M = 64, n = 4, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-8-512] _____________________

M = 64, n = 8, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-8-1024] ____________________

M = 64, n = 8, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-8-2048] ____________________

M = 64, n = 8, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-8-4096] ____________________

M = 64, n = 8, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-128-1-512] ____________________

M = 128, n = 1, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-1-1024] ____________________

M = 128, n = 1, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-1-2048] ____________________

M = 128, n = 1, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-1-4096] ____________________

M = 128, n = 1, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-128-2-512] ____________________

M = 128, n = 2, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-2-1024] ____________________

M = 128, n = 2, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-2-2048] ____________________

M = 128, n = 2, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-2-4096] ____________________

M = 128, n = 2, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-128-4-512] ____________________

M = 128, n = 4, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-4-1024] ____________________

M = 128, n = 4, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-4-2048] ____________________

M = 128, n = 4, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-4-4096] ____________________

M = 128, n = 4, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-128-8-512] ____________________

M = 128, n = 8, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-8-1024] ____________________

M = 128, n = 8, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-8-2048] ____________________

M = 128, n = 8, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-8-4096] ____________________

M = 128, n = 8, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-256-1-512] ____________________

M = 256, n = 1, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-256-1-1024] ____________________

M = 256, n = 1, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-256-1-2048] ____________________

M = 256, n = 1, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-256-1-4096] ____________________

M = 256, n = 1, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-256-2-512] ____________________

M = 256, n = 2, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-256-2-1024] ____________________

M = 256, n = 2, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-256-2-2048] ____________________

M = 256, n = 2, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-256-2-4096] ____________________

M = 256, n = 2, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-256-4-512] ____________________

M = 256, n = 4, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-256-4-1024] ____________________

M = 256, n = 4, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-256-4-2048] ____________________

M = 256, n = 4, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-256-4-4096] ____________________

M = 256, n = 4, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-256-8-512] ____________________

M = 256, n = 8, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-256-8-1024] ____________________

M = 256, n = 8, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-256-8-2048] ____________________

M = 256, n = 8, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-256-8-4096] ____________________

M = 256, n = 8, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-512-1-512] ____________________

M = 512, n = 1, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-512-1-1024] ____________________

M = 512, n = 1, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-512-1-2048] ____________________

M = 512, n = 1, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-512-1-4096] ____________________

M = 512, n = 1, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-512-2-512] ____________________

M = 512, n = 2, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-512-2-1024] ____________________

M = 512, n = 2, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-512-2-2048] ____________________

M = 512, n = 2, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-512-2-4096] ____________________

M = 512, n = 2, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-512-4-512] ____________________

M = 512, n = 4, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-512-4-1024] ____________________

M = 512, n = 4, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-512-4-2048] ____________________

M = 512, n = 4, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-512-4-4096] ____________________

M = 512, n = 4, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-512-8-512] ____________________

M = 512, n = 8, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-512-8-1024] ____________________

M = 512, n = 8, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-512-8-2048] ____________________

M = 512, n = 8, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-512-8-4096] ____________________

M = 512, n = 8, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-1-512] ____________________

M = 1024, n = 1, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-1-1024] ___________________

M = 1024, n = 1, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-1-2048] ___________________

M = 1024, n = 1, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-1-4096] ___________________

M = 1024, n = 1, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-2-512] ____________________

M = 1024, n = 2, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-2-1024] ___________________

M = 1024, n = 2, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-2-2048] ___________________

M = 1024, n = 2, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-2-4096] ___________________

M = 1024, n = 2, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-4-512] ____________________

M = 1024, n = 4, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-4-1024] ___________________

M = 1024, n = 4, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-4-2048] ___________________

M = 1024, n = 4, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-4-4096] ___________________

M = 1024, n = 4, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-8-512] ____________________

M = 1024, n = 8, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-8-1024] ___________________

M = 1024, n = 8, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-8-2048] ___________________

M = 1024, n = 8, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-1024-8-4096] ___________________

M = 1024, n = 8, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype0-1-4-256] _____________________

M = 1, n = 4, C = 256, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-1-16-4096] ____________________

M = 1, n = 16, C = 4096, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-2048-4-512] ____________________

M = 2048, n = 4, C = 512, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype0-128-4-7168] ____________________

M = 128, n = 4, C = 7168, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype0-64-8-2112] ____________________

M = 64, n = 8, C = 2112, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-1-1-512] _____________________

M = 1, n = 1, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-1-1024] _____________________

M = 1, n = 1, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-1-2048] _____________________

M = 1, n = 1, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-1-4096] _____________________

M = 1, n = 1, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-1-2-512] _____________________

M = 1, n = 2, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-2-1024] _____________________

M = 1, n = 2, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-2-2048] _____________________

M = 1, n = 2, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-2-4096] _____________________

M = 1, n = 2, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-1-4-512] _____________________

M = 1, n = 4, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-4-1024] _____________________

M = 1, n = 4, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-4-2048] _____________________

M = 1, n = 4, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-4-4096] _____________________

M = 1, n = 4, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-1-8-512] _____________________

M = 1, n = 8, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-8-1024] _____________________

M = 1, n = 8, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-8-2048] _____________________

M = 1, n = 8, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-8-4096] _____________________

M = 1, n = 8, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-2-1-512] _____________________

M = 2, n = 1, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-2-1-1024] _____________________

M = 2, n = 1, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-2-1-2048] _____________________

M = 2, n = 1, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-2-1-4096] _____________________

M = 2, n = 1, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-2-2-512] _____________________

M = 2, n = 2, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-2-2-1024] _____________________

M = 2, n = 2, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-2-2-2048] _____________________

M = 2, n = 2, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-2-2-4096] _____________________

M = 2, n = 2, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-2-4-512] _____________________

M = 2, n = 4, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-2-4-1024] _____________________

M = 2, n = 4, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-2-4-2048] _____________________

M = 2, n = 4, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-2-4-4096] _____________________

M = 2, n = 4, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-2-8-512] _____________________

M = 2, n = 8, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-2-8-1024] _____________________

M = 2, n = 8, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-2-8-2048] _____________________

M = 2, n = 8, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-2-8-4096] _____________________

M = 2, n = 8, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-4-1-512] _____________________

M = 4, n = 1, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-4-1-1024] _____________________

M = 4, n = 1, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-4-1-2048] _____________________

M = 4, n = 1, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-4-1-4096] _____________________

M = 4, n = 1, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-4-2-512] _____________________

M = 4, n = 2, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-4-2-1024] _____________________

M = 4, n = 2, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-4-2-2048] _____________________

M = 4, n = 2, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-4-2-4096] _____________________

M = 4, n = 2, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-4-4-512] _____________________

M = 4, n = 4, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-4-4-1024] _____________________

M = 4, n = 4, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-4-4-2048] _____________________

M = 4, n = 4, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-4-4-4096] _____________________

M = 4, n = 4, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-4-8-512] _____________________

M = 4, n = 8, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-4-8-1024] _____________________

M = 4, n = 8, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-4-8-2048] _____________________

M = 4, n = 8, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-4-8-4096] _____________________

M = 4, n = 8, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-8-1-512] _____________________

M = 8, n = 1, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-8-1-1024] _____________________

M = 8, n = 1, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-8-1-2048] _____________________

M = 8, n = 1, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-8-1-4096] _____________________

M = 8, n = 1, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-8-2-512] _____________________

M = 8, n = 2, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-8-2-1024] _____________________

M = 8, n = 2, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-8-2-2048] _____________________

M = 8, n = 2, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-8-2-4096] _____________________

M = 8, n = 2, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-8-4-512] _____________________

M = 8, n = 4, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-8-4-1024] _____________________

M = 8, n = 4, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-8-4-2048] _____________________

M = 8, n = 4, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-8-4-4096] _____________________

M = 8, n = 4, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-8-8-512] _____________________

M = 8, n = 8, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-8-8-1024] _____________________

M = 8, n = 8, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-8-8-2048] _____________________

M = 8, n = 8, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-8-8-4096] _____________________

M = 8, n = 8, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-1-512] _____________________

M = 16, n = 1, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-1-1024] ____________________

M = 16, n = 1, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-1-2048] ____________________

M = 16, n = 1, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-1-4096] ____________________

M = 16, n = 1, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-2-512] _____________________

M = 16, n = 2, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-2-1024] ____________________

M = 16, n = 2, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-2-2048] ____________________

M = 16, n = 2, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-2-4096] ____________________

M = 16, n = 2, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-4-512] _____________________

M = 16, n = 4, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-4-1024] ____________________

M = 16, n = 4, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-4-2048] ____________________

M = 16, n = 4, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-4-4096] ____________________

M = 16, n = 4, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-8-512] _____________________

M = 16, n = 8, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-8-1024] ____________________

M = 16, n = 8, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-8-2048] ____________________

M = 16, n = 8, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-16-8-4096] ____________________

M = 16, n = 8, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-1-512] _____________________

M = 32, n = 1, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-1-1024] ____________________

M = 32, n = 1, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-1-2048] ____________________

M = 32, n = 1, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-1-4096] ____________________

M = 32, n = 1, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-2-512] _____________________

M = 32, n = 2, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-2-1024] ____________________

M = 32, n = 2, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-2-2048] ____________________

M = 32, n = 2, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-2-4096] ____________________

M = 32, n = 2, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-4-512] _____________________

M = 32, n = 4, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-4-1024] ____________________

M = 32, n = 4, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-4-2048] ____________________

M = 32, n = 4, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-4-4096] ____________________

M = 32, n = 4, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-8-512] _____________________

M = 32, n = 8, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-8-1024] ____________________

M = 32, n = 8, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-8-2048] ____________________

M = 32, n = 8, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-32-8-4096] ____________________

M = 32, n = 8, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-1-512] _____________________

M = 64, n = 1, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-1-1024] ____________________

M = 64, n = 1, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-1-2048] ____________________

M = 64, n = 1, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-1-4096] ____________________

M = 64, n = 1, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-2-512] _____________________

M = 64, n = 2, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-2-1024] ____________________

M = 64, n = 2, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-2-2048] ____________________

M = 64, n = 2, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-2-4096] ____________________

M = 64, n = 2, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-4-512] _____________________

M = 64, n = 4, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-4-1024] ____________________

M = 64, n = 4, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-4-2048] ____________________

M = 64, n = 4, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-4-4096] ____________________

M = 64, n = 4, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-8-512] _____________________

M = 64, n = 8, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-8-1024] ____________________

M = 64, n = 8, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-8-2048] ____________________

M = 64, n = 8, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-8-4096] ____________________

M = 64, n = 8, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-128-1-512] ____________________

M = 128, n = 1, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-1-1024] ____________________

M = 128, n = 1, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-1-2048] ____________________

M = 128, n = 1, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-1-4096] ____________________

M = 128, n = 1, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-128-2-512] ____________________

M = 128, n = 2, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-2-1024] ____________________

M = 128, n = 2, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-2-2048] ____________________

M = 128, n = 2, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-2-4096] ____________________

M = 128, n = 2, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-128-4-512] ____________________

M = 128, n = 4, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-4-1024] ____________________

M = 128, n = 4, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-4-2048] ____________________

M = 128, n = 4, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-4-4096] ____________________

M = 128, n = 4, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-128-8-512] ____________________

M = 128, n = 8, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-8-1024] ____________________

M = 128, n = 8, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-8-2048] ____________________

M = 128, n = 8, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-8-4096] ____________________

M = 128, n = 8, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-256-1-512] ____________________

M = 256, n = 1, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-256-1-1024] ____________________

M = 256, n = 1, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-256-1-2048] ____________________

M = 256, n = 1, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-256-1-4096] ____________________

M = 256, n = 1, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-256-2-512] ____________________

M = 256, n = 2, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-256-2-1024] ____________________

M = 256, n = 2, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-256-2-2048] ____________________

M = 256, n = 2, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-256-2-4096] ____________________

M = 256, n = 2, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-256-4-512] ____________________

M = 256, n = 4, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-256-4-1024] ____________________

M = 256, n = 4, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-256-4-2048] ____________________

M = 256, n = 4, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-256-4-4096] ____________________

M = 256, n = 4, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-256-8-512] ____________________

M = 256, n = 8, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-256-8-1024] ____________________

M = 256, n = 8, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-256-8-2048] ____________________

M = 256, n = 8, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-256-8-4096] ____________________

M = 256, n = 8, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-512-1-512] ____________________

M = 512, n = 1, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-512-1-1024] ____________________

M = 512, n = 1, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-512-1-2048] ____________________

M = 512, n = 1, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-512-1-4096] ____________________

M = 512, n = 1, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-512-2-512] ____________________

M = 512, n = 2, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-512-2-1024] ____________________

M = 512, n = 2, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-512-2-2048] ____________________

M = 512, n = 2, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-512-2-4096] ____________________

M = 512, n = 2, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-512-4-512] ____________________

M = 512, n = 4, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-512-4-1024] ____________________

M = 512, n = 4, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-512-4-2048] ____________________

M = 512, n = 4, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-512-4-4096] ____________________

M = 512, n = 4, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-512-8-512] ____________________

M = 512, n = 8, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-512-8-1024] ____________________

M = 512, n = 8, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-512-8-2048] ____________________

M = 512, n = 8, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-512-8-4096] ____________________

M = 512, n = 8, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-1-512] ____________________

M = 1024, n = 1, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-1-1024] ___________________

M = 1024, n = 1, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-1-2048] ___________________

M = 1024, n = 1, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-1-4096] ___________________

M = 1024, n = 1, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-2-512] ____________________

M = 1024, n = 2, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-2-1024] ___________________

M = 1024, n = 2, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-2-2048] ___________________

M = 1024, n = 2, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-2-4096] ___________________

M = 1024, n = 2, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-4-512] ____________________

M = 1024, n = 4, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-4-1024] ___________________

M = 1024, n = 4, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-4-2048] ___________________

M = 1024, n = 4, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-4-4096] ___________________

M = 1024, n = 4, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-8-512] ____________________

M = 1024, n = 8, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-8-1024] ___________________

M = 1024, n = 8, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-8-2048] ___________________

M = 1024, n = 8, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-1024-8-4096] ___________________

M = 1024, n = 8, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
_____________________ test_mhc_correctness[dtype1-1-4-256] _____________________

M = 1, n = 4, C = 256, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-1-16-4096] ____________________

M = 1, n = 16, C = 4096, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-2048-4-512] ____________________

M = 2048, n = 4, C = 512, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
___________________ test_mhc_correctness[dtype1-128-4-7168] ____________________

M = 128, n = 4, C = 7168, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_correctness[dtype1-64-8-2112] ____________________

M = 64, n = 8, C = 2112, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_correctness(M, n, C, dtype):
        """
        Test that Triton kernel matches PyTorch reference for equations 14-18.
    
        Validates correctness across various shapes and data types.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:56: ValueError
____________________ test_mhc_preallocated_output[1-1-512] _____________________

M = 1, n = 1, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-1-1024] ____________________

M = 1, n = 1, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-1-2048] ____________________

M = 1, n = 1, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-1-4096] ____________________

M = 1, n = 1, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-2-512] _____________________

M = 1, n = 2, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-2-1024] ____________________

M = 1, n = 2, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-2-2048] ____________________

M = 1, n = 2, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-2-4096] ____________________

M = 1, n = 2, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-4-512] _____________________

M = 1, n = 4, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-4-1024] ____________________

M = 1, n = 4, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-4-2048] ____________________

M = 1, n = 4, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-4-4096] ____________________

M = 1, n = 4, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-8-512] _____________________

M = 1, n = 8, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-8-1024] ____________________

M = 1, n = 8, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-8-2048] ____________________

M = 1, n = 8, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-8-4096] ____________________

M = 1, n = 8, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-1-512] _____________________

M = 2, n = 1, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-1-1024] ____________________

M = 2, n = 1, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-1-2048] ____________________

M = 2, n = 1, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-1-4096] ____________________

M = 2, n = 1, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-2-512] _____________________

M = 2, n = 2, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-2-1024] ____________________

M = 2, n = 2, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-2-2048] ____________________

M = 2, n = 2, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-2-4096] ____________________

M = 2, n = 2, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-4-512] _____________________

M = 2, n = 4, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-4-1024] ____________________

M = 2, n = 4, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-4-2048] ____________________

M = 2, n = 4, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-4-4096] ____________________

M = 2, n = 4, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-8-512] _____________________

M = 2, n = 8, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-8-1024] ____________________

M = 2, n = 8, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-8-2048] ____________________

M = 2, n = 8, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[2-8-4096] ____________________

M = 2, n = 8, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 2)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-1-512] _____________________

M = 4, n = 1, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-1-1024] ____________________

M = 4, n = 1, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-1-2048] ____________________

M = 4, n = 1, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-1-4096] ____________________

M = 4, n = 1, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-2-512] _____________________

M = 4, n = 2, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-2-1024] ____________________

M = 4, n = 2, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-2-2048] ____________________

M = 4, n = 2, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-2-4096] ____________________

M = 4, n = 2, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-4-512] _____________________

M = 4, n = 4, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-4-1024] ____________________

M = 4, n = 4, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-4-2048] ____________________

M = 4, n = 4, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-4-4096] ____________________

M = 4, n = 4, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-8-512] _____________________

M = 4, n = 8, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-8-1024] ____________________

M = 4, n = 8, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-8-2048] ____________________

M = 4, n = 8, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[4-8-4096] ____________________

M = 4, n = 8, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-1-512] _____________________

M = 8, n = 1, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-1-1024] ____________________

M = 8, n = 1, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-1-2048] ____________________

M = 8, n = 1, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-1-4096] ____________________

M = 8, n = 1, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-2-512] _____________________

M = 8, n = 2, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-2-1024] ____________________

M = 8, n = 2, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-2-2048] ____________________

M = 8, n = 2, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-2-4096] ____________________

M = 8, n = 2, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-4-512] _____________________

M = 8, n = 4, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-4-1024] ____________________

M = 8, n = 4, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-4-2048] ____________________

M = 8, n = 4, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-4-4096] ____________________

M = 8, n = 4, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-8-512] _____________________

M = 8, n = 8, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-8-1024] ____________________

M = 8, n = 8, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-8-2048] ____________________

M = 8, n = 8, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[8-8-4096] ____________________

M = 8, n = 8, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[16-1-512] ____________________

M = 16, n = 1, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[16-1-1024] ____________________

M = 16, n = 1, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[16-1-2048] ____________________

M = 16, n = 1, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[16-1-4096] ____________________

M = 16, n = 1, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[16-2-512] ____________________

M = 16, n = 2, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[16-2-1024] ____________________

M = 16, n = 2, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[16-2-2048] ____________________

M = 16, n = 2, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[16-2-4096] ____________________

M = 16, n = 2, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[16-4-512] ____________________

M = 16, n = 4, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[16-4-1024] ____________________

M = 16, n = 4, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[16-4-2048] ____________________

M = 16, n = 4, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[16-4-4096] ____________________

M = 16, n = 4, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[16-8-512] ____________________

M = 16, n = 8, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[16-8-1024] ____________________

M = 16, n = 8, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[16-8-2048] ____________________

M = 16, n = 8, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[16-8-4096] ____________________

M = 16, n = 8, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[32-1-512] ____________________

M = 32, n = 1, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[32-1-1024] ____________________

M = 32, n = 1, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[32-1-2048] ____________________

M = 32, n = 1, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[32-1-4096] ____________________

M = 32, n = 1, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[32-2-512] ____________________

M = 32, n = 2, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[32-2-1024] ____________________

M = 32, n = 2, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[32-2-2048] ____________________

M = 32, n = 2, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[32-2-4096] ____________________

M = 32, n = 2, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[32-4-512] ____________________

M = 32, n = 4, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[32-4-1024] ____________________

M = 32, n = 4, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[32-4-2048] ____________________

M = 32, n = 4, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[32-4-4096] ____________________

M = 32, n = 4, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[32-8-512] ____________________

M = 32, n = 8, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[32-8-1024] ____________________

M = 32, n = 8, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[32-8-2048] ____________________

M = 32, n = 8, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[32-8-4096] ____________________

M = 32, n = 8, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[64-1-512] ____________________

M = 64, n = 1, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-1-1024] ____________________

M = 64, n = 1, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-1-2048] ____________________

M = 64, n = 1, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-1-4096] ____________________

M = 64, n = 1, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[64-2-512] ____________________

M = 64, n = 2, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-2-1024] ____________________

M = 64, n = 2, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-2-2048] ____________________

M = 64, n = 2, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-2-4096] ____________________

M = 64, n = 2, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[64-4-512] ____________________

M = 64, n = 4, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-4-1024] ____________________

M = 64, n = 4, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-4-2048] ____________________

M = 64, n = 4, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-4-4096] ____________________

M = 64, n = 4, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[64-8-512] ____________________

M = 64, n = 8, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-8-1024] ____________________

M = 64, n = 8, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-8-2048] ____________________

M = 64, n = 8, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-8-4096] ____________________

M = 64, n = 8, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-1-512] ____________________

M = 128, n = 1, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-1-1024] ___________________

M = 128, n = 1, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-1-2048] ___________________

M = 128, n = 1, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-1-4096] ___________________

M = 128, n = 1, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-2-512] ____________________

M = 128, n = 2, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-2-1024] ___________________

M = 128, n = 2, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-2-2048] ___________________

M = 128, n = 2, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-2-4096] ___________________

M = 128, n = 2, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-4-512] ____________________

M = 128, n = 4, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-4-1024] ___________________

M = 128, n = 4, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-4-2048] ___________________

M = 128, n = 4, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-4-4096] ___________________

M = 128, n = 4, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-8-512] ____________________

M = 128, n = 8, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-8-1024] ___________________

M = 128, n = 8, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-8-2048] ___________________

M = 128, n = 8, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-8-4096] ___________________

M = 128, n = 8, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-1-512] ____________________

M = 256, n = 1, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-1-1024] ___________________

M = 256, n = 1, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-1-2048] ___________________

M = 256, n = 1, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-1-4096] ___________________

M = 256, n = 1, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-2-512] ____________________

M = 256, n = 2, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-2-1024] ___________________

M = 256, n = 2, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-2-2048] ___________________

M = 256, n = 2, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-2-4096] ___________________

M = 256, n = 2, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-4-512] ____________________

M = 256, n = 4, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-4-1024] ___________________

M = 256, n = 4, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-4-2048] ___________________

M = 256, n = 4, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-4-4096] ___________________

M = 256, n = 4, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-8-512] ____________________

M = 256, n = 8, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-8-1024] ___________________

M = 256, n = 8, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-8-2048] ___________________

M = 256, n = 8, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[256-8-4096] ___________________

M = 256, n = 8, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-1-512] ____________________

M = 512, n = 1, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-1-1024] ___________________

M = 512, n = 1, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-1-2048] ___________________

M = 512, n = 1, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-1-4096] ___________________

M = 512, n = 1, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-2-512] ____________________

M = 512, n = 2, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-2-1024] ___________________

M = 512, n = 2, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-2-2048] ___________________

M = 512, n = 2, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-2-4096] ___________________

M = 512, n = 2, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-4-512] ____________________

M = 512, n = 4, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-4-1024] ___________________

M = 512, n = 4, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-4-2048] ___________________

M = 512, n = 4, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-4-4096] ___________________

M = 512, n = 4, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-8-512] ____________________

M = 512, n = 8, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-8-1024] ___________________

M = 512, n = 8, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-8-2048] ___________________

M = 512, n = 8, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[512-8-4096] ___________________

M = 512, n = 8, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[1024-1-512] ___________________

M = 1024, n = 1, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
__________________ test_mhc_preallocated_output[1024-1-1024] ___________________

M = 1024, n = 1, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
__________________ test_mhc_preallocated_output[1024-1-2048] ___________________

M = 1024, n = 1, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
__________________ test_mhc_preallocated_output[1024-1-4096] ___________________

M = 1024, n = 1, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[1024-2-512] ___________________

M = 1024, n = 2, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
__________________ test_mhc_preallocated_output[1024-2-1024] ___________________

M = 1024, n = 2, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
__________________ test_mhc_preallocated_output[1024-2-2048] ___________________

M = 1024, n = 2, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
__________________ test_mhc_preallocated_output[1024-2-4096] ___________________

M = 1024, n = 2, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[1024-4-512] ___________________

M = 1024, n = 4, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
__________________ test_mhc_preallocated_output[1024-4-1024] ___________________

M = 1024, n = 4, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
__________________ test_mhc_preallocated_output[1024-4-2048] ___________________

M = 1024, n = 4, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
__________________ test_mhc_preallocated_output[1024-4-4096] ___________________

M = 1024, n = 4, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[1024-8-512] ___________________

M = 1024, n = 8, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
__________________ test_mhc_preallocated_output[1024-8-1024] ___________________

M = 1024, n = 8, C = 1024

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
__________________ test_mhc_preallocated_output[1024-8-2048] ___________________

M = 1024, n = 8, C = 2048

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
__________________ test_mhc_preallocated_output[1024-8-4096] ___________________

M = 1024, n = 8, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
____________________ test_mhc_preallocated_output[1-4-256] _____________________

M = 1, n = 4, C = 256

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[1-16-4096] ____________________

M = 1, n = 16, C = 4096

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: not enough values to unpack (expected 3, got 1)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[2048-4-512] ___________________

M = 2048, n = 4, C = 512

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[128-4-7168] ___________________

M = 128, n = 4, C = 7168

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
___________________ test_mhc_preallocated_output[64-8-2112] ____________________

M = 64, n = 8, C = 2112

    @pytest.mark.parametrize("M, n, C", get_test_shapes())
    def test_mhc_preallocated_output(M, n, C):
        """
        Test mHC with pre-allocated output tensors.
    
        Verifies that the kernel correctly writes to user-provided output buffers.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
        n_squared = n * n
        out_pre = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_post = torch.empty(M, n, dtype=x.dtype, device=x.device)
        out_res = torch.empty(M, n_squared, dtype=x.dtype, device=x.device)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:94: ValueError
_________________ test_mhc_different_epsilon[32-4-1024-1e-06] __________________

eps = 1e-06, M = 32, n = 4, C = 1024

    @pytest.mark.parametrize("eps", [1e-6, 1e-5, 1e-8])
    @pytest.mark.parametrize("M, n, C", [(32, 4, 1024)])
    def test_mhc_different_epsilon(eps, M, n, C):
        """
        Test mHC with different epsilon values for RMSNorm (Eq 15).
    
        Validates numerical stability parameter handling.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams, eps=eps)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:134: ValueError
_________________ test_mhc_different_epsilon[32-4-1024-1e-05] __________________

eps = 1e-05, M = 32, n = 4, C = 1024

    @pytest.mark.parametrize("eps", [1e-6, 1e-5, 1e-8])
    @pytest.mark.parametrize("M, n, C", [(32, 4, 1024)])
    def test_mhc_different_epsilon(eps, M, n, C):
        """
        Test mHC with different epsilon values for RMSNorm (Eq 15).
    
        Validates numerical stability parameter handling.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams, eps=eps)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:134: ValueError
_________________ test_mhc_different_epsilon[32-4-1024-1e-08] __________________

eps = 1e-08, M = 32, n = 4, C = 1024

    @pytest.mark.parametrize("eps", [1e-6, 1e-5, 1e-8])
    @pytest.mark.parametrize("M, n, C", [(32, 4, 1024)])
    def test_mhc_different_epsilon(eps, M, n, C):
        """
        Test mHC with different epsilon values for RMSNorm (Eq 15).
    
        Validates numerical stability parameter handling.
        """
        torch.cuda.empty_cache()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams, eps=eps)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:134: ValueError
________________________ test_mhc_different_alpha[0.1] _________________________

alpha_scale = 0.1

    @pytest.mark.parametrize("alpha_scale", [0.1, 0.5, 1.0, 2.0, 10.0])
    def test_mhc_different_alpha(alpha_scale):
        """
        Test mHC with different scaling factors  (Eq 16).
    
        Validates stream-specific scaling behavior across range of  values.
        """
        torch.cuda.empty_cache()
    
        M, n, C = 32, 4, 1024
        x, phi, _, _, _, bias, n_streams = generate_mhc_inputs(M, n, C)
    
        # Use same alpha for all streams, scaled by alpha_scale
        alpha_pre = alpha_scale
        alpha_post = alpha_scale
        alpha_res = alpha_scale
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:163: ValueError
________________________ test_mhc_different_alpha[0.5] _________________________

alpha_scale = 0.5

    @pytest.mark.parametrize("alpha_scale", [0.1, 0.5, 1.0, 2.0, 10.0])
    def test_mhc_different_alpha(alpha_scale):
        """
        Test mHC with different scaling factors  (Eq 16).
    
        Validates stream-specific scaling behavior across range of  values.
        """
        torch.cuda.empty_cache()
    
        M, n, C = 32, 4, 1024
        x, phi, _, _, _, bias, n_streams = generate_mhc_inputs(M, n, C)
    
        # Use same alpha for all streams, scaled by alpha_scale
        alpha_pre = alpha_scale
        alpha_post = alpha_scale
        alpha_res = alpha_scale
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:163: ValueError
________________________ test_mhc_different_alpha[1.0] _________________________

alpha_scale = 1.0

    @pytest.mark.parametrize("alpha_scale", [0.1, 0.5, 1.0, 2.0, 10.0])
    def test_mhc_different_alpha(alpha_scale):
        """
        Test mHC with different scaling factors  (Eq 16).
    
        Validates stream-specific scaling behavior across range of  values.
        """
        torch.cuda.empty_cache()
    
        M, n, C = 32, 4, 1024
        x, phi, _, _, _, bias, n_streams = generate_mhc_inputs(M, n, C)
    
        # Use same alpha for all streams, scaled by alpha_scale
        alpha_pre = alpha_scale
        alpha_post = alpha_scale
        alpha_res = alpha_scale
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:163: ValueError
________________________ test_mhc_different_alpha[2.0] _________________________

alpha_scale = 2.0

    @pytest.mark.parametrize("alpha_scale", [0.1, 0.5, 1.0, 2.0, 10.0])
    def test_mhc_different_alpha(alpha_scale):
        """
        Test mHC with different scaling factors  (Eq 16).
    
        Validates stream-specific scaling behavior across range of  values.
        """
        torch.cuda.empty_cache()
    
        M, n, C = 32, 4, 1024
        x, phi, _, _, _, bias, n_streams = generate_mhc_inputs(M, n, C)
    
        # Use same alpha for all streams, scaled by alpha_scale
        alpha_pre = alpha_scale
        alpha_post = alpha_scale
        alpha_res = alpha_scale
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:163: ValueError
________________________ test_mhc_different_alpha[10.0] ________________________

alpha_scale = 10.0

    @pytest.mark.parametrize("alpha_scale", [0.1, 0.5, 1.0, 2.0, 10.0])
    def test_mhc_different_alpha(alpha_scale):
        """
        Test mHC with different scaling factors  (Eq 16).
    
        Validates stream-specific scaling behavior across range of  values.
        """
        torch.cuda.empty_cache()
    
        M, n, C = 32, 4, 1024
        x, phi, _, _, _, bias, n_streams = generate_mhc_inputs(M, n, C)
    
        # Use same alpha for all streams, scaled by alpha_scale
        alpha_pre = alpha_scale
        alpha_post = alpha_scale
        alpha_res = alpha_scale
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:163: ValueError
_____________________________ test_mhc_zero_input ______________________________

    def test_mhc_zero_input():
        """
        Test mHC with zero input (edge case for RMSNorm).
    
        When x = 0, RMS norm  , testing numerical stability of Eq 15.
        """
        torch.cuda.empty_cache()
    
        M, n, C = 16, 4, 512
        nC = n * C
        N_total = n * n + 2 * n
    
        x = torch.zeros(M, nC, dtype=torch.bfloat16, device="cuda")
        phi = torch.randn(nC, N_total, dtype=torch.bfloat16, device="cuda") * 0.1
        alpha_pre = alpha_post = alpha_res = 1.0
        bias = torch.randn(N_total, dtype=torch.float32, device="cuda") * 0.1
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:192: ValueError
____________________________ test_mhc_large_values _____________________________

    def test_mhc_large_values():
        """
        Test numerical stability with large input values.
    
        Validates that float32 accumulation prevents overflow/underflow.
        """
        torch.cuda.empty_cache()
    
        M, n, C = 32, 4, 1024
        nC = n * C
        N_total = n * n + 2 * n
    
        x = torch.randn(M, nC, dtype=torch.bfloat16, device="cuda") * 100
        phi = torch.randn(nC, N_total, dtype=torch.bfloat16, device="cuda") * 0.01
        alpha_pre = alpha_post = alpha_res = 1.0
        bias = torch.randn(N_total, dtype=torch.float32, device="cuda")
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:221: ValueError
___________________ test_mhc_small_shapes[dtype0-32-4-1024] ____________________

M = 32, n = 4, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", [(32, 4, 1024), (64, 4, 2048), (128, 8, 1024)])
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_small_shapes(M, n, C, dtype):
        """
        Quick smoke test with representative shapes.
    
        Subset of test_mhc_correctness for faster validation during development.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:246: ValueError
___________________ test_mhc_small_shapes[dtype0-64-4-2048] ____________________

M = 64, n = 4, C = 2048, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", [(32, 4, 1024), (64, 4, 2048), (128, 8, 1024)])
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_small_shapes(M, n, C, dtype):
        """
        Quick smoke test with representative shapes.
    
        Subset of test_mhc_correctness for faster validation during development.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:246: ValueError
___________________ test_mhc_small_shapes[dtype0-128-8-1024] ___________________

M = 128, n = 8, C = 1024, dtype = torch.bfloat16

    @pytest.mark.parametrize("M, n, C", [(32, 4, 1024), (64, 4, 2048), (128, 8, 1024)])
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_small_shapes(M, n, C, dtype):
        """
        Quick smoke test with representative shapes.
    
        Subset of test_mhc_correctness for faster validation during development.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:246: ValueError
___________________ test_mhc_small_shapes[dtype1-32-4-1024] ____________________

M = 32, n = 4, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", [(32, 4, 1024), (64, 4, 2048), (128, 8, 1024)])
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_small_shapes(M, n, C, dtype):
        """
        Quick smoke test with representative shapes.
    
        Subset of test_mhc_correctness for faster validation during development.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:246: ValueError
___________________ test_mhc_small_shapes[dtype1-64-4-2048] ____________________

M = 64, n = 4, C = 2048, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", [(32, 4, 1024), (64, 4, 2048), (128, 8, 1024)])
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_small_shapes(M, n, C, dtype):
        """
        Quick smoke test with representative shapes.
    
        Subset of test_mhc_correctness for faster validation during development.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:246: ValueError
___________________ test_mhc_small_shapes[dtype1-128-8-1024] ___________________

M = 128, n = 8, C = 1024, dtype = torch.float16

    @pytest.mark.parametrize("M, n, C", [(32, 4, 1024), (64, 4, 2048), (128, 8, 1024)])
    @pytest.mark.parametrize("dtype", [torch.bfloat16, torch.float16])
    def test_mhc_small_shapes(M, n, C, dtype):
        """
        Quick smoke test with representative shapes.
    
        Subset of test_mhc_correctness for faster validation during development.
        """
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    
        x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams = generate_mhc_inputs(M, n, C, dtype)
    
>       H_pre_torch, H_post_torch, H_res_torch = mhc_torch(x, phi, alpha_pre, alpha_post, alpha_res, bias, n_streams)
E       ValueError: too many values to unpack (expected 3)

op_tests/triton_tests/fusions/test_mhc.py:246: ValueError
=========================== short test summary info ============================
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-4-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-8-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-16-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-32-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-256-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-512-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1024-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-4-256]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-1-16-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-2048-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-128-4-7168]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype0-64-8-2112]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-4-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-8-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-16-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-32-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-256-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-512-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1024-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-4-256]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-1-16-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-2048-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-128-4-7168]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_correctness[dtype1-64-8-2112]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[4-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[8-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[16-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[32-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[256-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[512-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-1-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-1-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-1-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-1-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-2-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-2-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-2-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-2-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-4-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-8-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-8-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1024-8-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-4-256]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[1-16-4096]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[2048-4-512]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[128-4-7168]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_preallocated_output[64-8-2112]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_epsilon[32-4-1024-1e-06]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_epsilon[32-4-1024-1e-05]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_epsilon[32-4-1024-1e-08]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[0.1]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[0.5]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[1.0]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[2.0]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_different_alpha[10.0]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_zero_input - Value...
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_large_values - Val...
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype0-32-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype0-64-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype0-128-8-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype1-32-4-1024]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype1-64-4-2048]
FAILED op_tests/triton_tests/fusions/test_mhc.py::test_mhc_small_shapes[dtype1-128-8-1024]
======================= 559 failed, 100 passed in 18.23s =======================
