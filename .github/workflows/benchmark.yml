name: vLLM Benchmark

on:
  pull_request:
    branches: [main]  # Triggers on PRs targeting `main`

jobs:
  build_and_benchmark:
    name: Build and Run Benchmark
    runs-on: [aiter]
    env:
      HF_TOKEN: ${{ secrets.HF_TOKEN }}
    steps:
      - name: Checkout aiter repo
        uses: actions/checkout@v4

      - name: Clone vLLM repo
        run: |
          git clone https://github.com/ROCm/vllm.git

      - name: Build vllm_aiter_base Image
        run: |
          cd vllm
          docker build --no-cache -f docker/Dockerfile.rocm_base \
            --build-arg AITER_BRANCH=main \
            --build-arg AITER_REPO=https://github.com/ROCm/aiter.git \
            --build-arg PYTORCH_ROCM_ARCH=gfx942 \
            -t vllm_aiter_base .

      - name: Build Final Benchmark Image
        run: |
          cd vllm
          docker build --no-cache -f docker/Dockerfile.rocm \
            --build-arg BASE_IMAGE=vllm_aiter_base \
            -t vllm_aiter_benchmark .

      - name: Run Benchmark and Save Result
        run: |
          docker run --rm --device=/dev/kfd --device=/dev/dri --group-add video \
            --ulimit core=0:0 --ulimit memlock=-1:-1 --cap-add=SYS_PTRACE \
            -e HF_TOKEN=$HF_TOKEN -e VLLM_ROCM_USE_AITER=1 \
            vllm_aiter_benchmark \
            python3 /app/vllm/benchmarks/benchmark_latency.py \
              --model mistralai/Mixtral-8x7B-Instruct-v0.1 \
              --batch-size 1 --input-len 128 --output-len 128 \
              -tp 8 --num-scheduler-steps 10 | tee result.log

      - name: Extract and Print Average Latency
        run: |
          LATENCY=$(grep "Avg latency:" result.log | awk '{print $3}')
          if [ -z "$LATENCY" ]; then
            echo "Error: Latency value not found!" >&2
            exit 1
          fi
          echo "Average Latency: $LATENCY"
