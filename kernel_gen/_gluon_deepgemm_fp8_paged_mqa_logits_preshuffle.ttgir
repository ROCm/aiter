#blocked = #ttg.blocked<{sizePerThread = [2, 16], threadsPerWarp = [8, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc(unknown)
#loc1 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":652:0)
#mma = #ttg.amd_mfma<{version = 3, warpsPerCTA = [1, 4], instrShape = [16, 16], isTransposed = false}>
#loc131 = loc("batch_size"(#loc1))
#loc132 = loc("heads_num"(#loc1))
#loc133 = loc("Q_buffer"(#loc1))
#loc134 = loc("stride_q_batch"(#loc1))
#loc135 = loc("stride_q_next_n"(#loc1))
#loc136 = loc("stride_q_heads"(#loc1))
#loc137 = loc("KV_buffer"(#loc1))
#loc138 = loc("stride_k_seq"(#loc1))
#loc139 = loc("scale_buffer"(#loc1))
#loc140 = loc("stride_scale_seq"(#loc1))
#loc141 = loc("context_len_ptr"(#loc1))
#loc142 = loc("kv_indices"(#loc1))
#loc143 = loc("weights"(#loc1))
#loc144 = loc("stride_w_batch"(#loc1))
#loc145 = loc("OutLogits_buffer"(#loc1))
#loc146 = loc("stride_out_batch"(#loc1))
#loc147 = loc("max_model_len"(#loc1))
#loc148 = loc("max_block_len"(#loc1))
#loc149 = loc("SplitKV"(#loc1))
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx942", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_gluon_deepgemm_fp8_paged_mqa_logits_preshuffle(%batch_size: i32 loc("batch_size"(#loc1)), %heads_num: i32 {tt.divisibility = 16 : i32} loc("heads_num"(#loc1)), %Q_buffer: !tt.ptr<f8E4M3FNUZ> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("Q_buffer"(#loc1)), %stride_q_batch: i32 {tt.divisibility = 16 : i32} loc("stride_q_batch"(#loc1)), %stride_q_next_n: i32 {tt.divisibility = 16 : i32} loc("stride_q_next_n"(#loc1)), %stride_q_heads: i32 {tt.divisibility = 16 : i32} loc("stride_q_heads"(#loc1)), %KV_buffer: !tt.ptr<f8E4M3FNUZ> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("KV_buffer"(#loc1)), %stride_k_seq: i32 {tt.divisibility = 16 : i32} loc("stride_k_seq"(#loc1)), %scale_buffer: !tt.ptr<f32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("scale_buffer"(#loc1)), %stride_scale_seq: i32 {tt.divisibility = 16 : i32} loc("stride_scale_seq"(#loc1)), %context_len_ptr: !tt.ptr<i32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("context_len_ptr"(#loc1)), %kv_indices: !tt.ptr<i32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("kv_indices"(#loc1)), %weights: !tt.ptr<f32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("weights"(#loc1)), %stride_w_batch: i32 {tt.divisibility = 16 : i32} loc("stride_w_batch"(#loc1)), %OutLogits_buffer: !tt.ptr<f32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("OutLogits_buffer"(#loc1)), %stride_out_batch: i32 {tt.divisibility = 16 : i32} loc("stride_out_batch"(#loc1)), %max_model_len: i32 {tt.divisibility = 16 : i32} loc("max_model_len"(#loc1)), %max_block_len: i32 {tt.divisibility = 16 : i32} loc("max_block_len"(#loc1)), %SplitKV: i32 loc("SplitKV"(#loc1))) attributes {noinline = false} {
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %cst = arith.constant dense<16> : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc)
    %cst_0 = arith.constant dense<0> : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc)
    %cst_1 = arith.constant dense<16> : tensor<128xi32, #ttg.slice<{dim = 1, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc)
    %cst_2 = arith.constant dense<256> : tensor<128xi32, #ttg.slice<{dim = 1, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc)
    %cst_3 = arith.constant dense<0.000000e+00> : tensor<64x256xf32, #mma> loc(#loc)
    %cst_4 = arith.constant dense<0xFF800000> : tensor<64x256xf32, #mma> loc(#loc)
    %cst_5 = arith.constant dense<0> : tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %c255_i32 = arith.constant 255 : i32 loc(#loc)
    %c1_i32 = arith.constant 1 : i32 loc(#loc)
    %c15_i32 = arith.constant 15 : i32 loc(#loc)
    %pid = tt.get_program_id x : i32 loc(#loc150)
    %num_block_q_head = arith.addi %heads_num, %c63_i32 : i32 loc(#loc253)
    %num_block_q_head_6 = arith.divsi %num_block_q_head, %c64_i32 : i32 loc(#loc254)
    %0 = arith.remsi %pid, %batch_size : i32 loc(#loc6)
    %1 = arith.divsi %pid, %batch_size : i32 loc(#loc7)
    %2 = arith.remsi %1, %num_block_q_head_6 : i32 loc(#loc8)
    %3 = arith.divsi %1, %num_block_q_head_6 : i32 loc(#loc9)
    %context_length = tt.addptr %context_len_ptr, %0 : !tt.ptr<i32>, i32 loc(#loc152)
    %context_length_7 = tt.load %context_length : !tt.ptr<i32> loc(#loc153)
    %context_chunk_num = arith.addi %context_length_7, %c255_i32 : i32 loc(#loc255)
    %context_chunk_num_8 = arith.divsi %context_chunk_num, %c256_i32 : i32 loc(#loc256)
    %split_context_chunk_num = arith.addi %context_chunk_num_8, %SplitKV : i32 loc(#loc257)
    %split_context_chunk_num_9 = arith.subi %split_context_chunk_num, %c1_i32 : i32 loc(#loc258)
    %split_context_chunk_num_10 = arith.divsi %split_context_chunk_num_9, %SplitKV : i32 loc(#loc259)
    %split_context_start = arith.muli %3, %split_context_chunk_num_10 : i32 loc(#loc156)
    %split_context_start_11 = arith.muli %split_context_start, %c256_i32 : i32 loc(#loc157)
    %split_context_length = arith.subi %context_length_7, %split_context_start_11 : i32 loc(#loc158)
    %split_context_length_12 = arith.muli %split_context_chunk_num_10, %c256_i32 : i32 loc(#loc159)
    %split_context_length_13 = arith.minsi %split_context_length, %split_context_length_12 : i32 loc(#loc160)
    %4 = arith.cmpi sle, %split_context_length_13, %c0_i32 : i32 loc(#loc20)
    cf.cond_br %4, ^bb1, ^bb2 loc(#loc20)
  ^bb1:  // pred: ^bb0
    tt.return loc(#loc21)
  ^bb2:  // pred: ^bb0
    cf.br ^bb3 loc(#loc)
  ^bb3:  // pred: ^bb2
    %split_context_block = arith.addi %split_context_length_13, %c15_i32 : i32 loc(#loc260)
    %split_context_block_14 = arith.divsi %split_context_block, %c16_i32 : i32 loc(#loc261)
    %split_context_length_15 = arith.muli %split_context_block_14, %c16_i32 : i32 loc(#loc162)
    %residual_context_blocks = arith.remsi %split_context_block_14, %c16_i32 : i32 loc(#loc163)
    %residual_context_blocks_16 = arith.subi %c16_i32, %residual_context_blocks : i32 loc(#loc164)
    %residual_context_blocks_17 = arith.remsi %residual_context_blocks_16, %c16_i32 : i32 loc(#loc165)
    %residual_context = arith.muli %residual_context_blocks_17, %c16_i32 : i32 loc(#loc166)
    %q = arith.muli %0, %stride_q_batch : i32 loc(#loc167)
    %q_18 = arith.muli %2, %c64_i32 : i32 loc(#loc168)
    %q_19 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc169)
    %q_20 = tt.splat %q_18 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc170)
    %q_21 = arith.addi %q_20, %q_19 : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc170)
    %q_22 = tt.splat %stride_q_heads : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc171)
    %q_23 = arith.muli %q_21, %q_22 : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc171)
    %q_24 = tt.expand_dims %q_23 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<64x1xi32, #blocked> loc(#loc172)
    %q_25 = tt.splat %q : i32 -> tensor<64x1xi32, #blocked> loc(#loc173)
    %q_26 = arith.addi %q_25, %q_24 : tensor<64x1xi32, #blocked> loc(#loc173)
    %q_27 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc174)
    %q_28 = tt.expand_dims %q_27 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x128xi32, #blocked> loc(#loc175)
    %q_29 = tt.broadcast %q_26 : tensor<64x1xi32, #blocked> -> tensor<64x128xi32, #blocked> loc(#loc176)
    %q_30 = tt.broadcast %q_28 : tensor<1x128xi32, #blocked> -> tensor<64x128xi32, #blocked> loc(#loc176)
    %q_31 = arith.addi %q_29, %q_30 : tensor<64x128xi32, #blocked> loc(#loc176)
    %q_32 = amdgpu.buffer_load %Q_buffer[%q_31] : tensor<64x128xf8E4M3FNUZ, #blocked> loc(#loc177)
    %scale_weight = arith.muli %0, %stride_w_batch : i32 loc(#loc178)
    %scale_weight_33 = arith.addi %scale_weight, %q_18 : i32 loc(#loc179)
    %scale_weight_34 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc180)
    %scale_weight_35 = tt.splat %scale_weight_33 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc181)
    %scale_weight_36 = arith.addi %scale_weight_35, %scale_weight_34 : tensor<64xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc181)
    %scale_weight_37 = amdgpu.buffer_load %weights[%scale_weight_36] : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc182)
    %mask_kv_next = arith.subi %split_context_start_11, %residual_context : i32 loc(#loc183)
    %mask_kv_next_38 = arith.divsi %mask_kv_next, %c16_i32 : i32 loc(#loc184)
    %mask_kv_next_39 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc185)
    %mask_kv_next_40 = arith.divsi %mask_kv_next_39, %cst : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc186)
    %mask_kv_next_41 = tt.splat %mask_kv_next_38 : i32 -> tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc187)
    %mask_kv_next_42 = arith.addi %mask_kv_next_41, %mask_kv_next_40 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc187)
    %mask_kv_next_43 = arith.cmpi sge, %mask_kv_next_42, %cst_0 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc188)
    %context_kv_idx_next = arith.muli %0, %max_block_len : i32 loc(#loc189)
    %context_kv_idx_next_44 = arith.addi %context_kv_idx_next, %mask_kv_next_38 : i32 loc(#loc190)
    %context_kv_idx_next_45 = tt.splat %context_kv_idx_next_44 : i32 -> tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc191)
    %context_kv_idx_next_46 = arith.addi %context_kv_idx_next_45, %mask_kv_next_40 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc191)
    %context_kv_idx_next_47 = amdgpu.buffer_load %kv_indices[%context_kv_idx_next_46], %mask_kv_next_43 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc192)
    %offset_k_fixed = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc193)
    %offset_k_fixed_48 = arith.remsi %offset_k_fixed, %cst_1 : tensor<128xi32, #ttg.slice<{dim = 1, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc194)
    %offset_k_fixed_49 = arith.divsi %offset_k_fixed, %cst_1 : tensor<128xi32, #ttg.slice<{dim = 1, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc195)
    %offset_k_fixed_50 = arith.muli %offset_k_fixed_49, %cst_2 : tensor<128xi32, #ttg.slice<{dim = 1, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc196)
    %offset_k_fixed_51 = arith.addi %offset_k_fixed_48, %offset_k_fixed_50 : tensor<128xi32, #ttg.slice<{dim = 1, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc197)
    %offset_k_fixed_52 = tt.expand_dims %offset_k_fixed_51 {axis = 1 : i32} : tensor<128xi32, #ttg.slice<{dim = 1, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> -> tensor<128x1xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc198)
    %offset_k_fixed_53 = arith.remsi %mask_kv_next_39, %cst : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc199)
    %offset_k_fixed_54 = arith.muli %offset_k_fixed_53, %cst : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc200)
    %offset_k_fixed_55 = tt.expand_dims %offset_k_fixed_54 {axis = 0 : i32} : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> -> tensor<1x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc201)
    %offset_k_fixed_56 = tt.broadcast %offset_k_fixed_52 : tensor<128x1xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<128x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc202)
    %offset_k_fixed_57 = tt.broadcast %offset_k_fixed_55 : tensor<1x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<128x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc202)
    %offset_k_fixed_58 = arith.addi %offset_k_fixed_56, %offset_k_fixed_57 : tensor<128x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc202)
    %context_kv_idx_next_59 = arith.select %mask_kv_next_43, %context_kv_idx_next_47, %cst_0 : tensor<256xi1, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>>, tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc203)
    %k_next = tt.expand_dims %context_kv_idx_next_59 {axis = 0 : i32} : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> -> tensor<1x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc204)
    %k_next_60 = tt.splat %stride_k_seq : i32 -> tensor<1x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc205)
    %k_next_61 = arith.muli %k_next, %k_next_60 : tensor<1x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc205)
    %k_next_62 = tt.broadcast %k_next_61 : tensor<1x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<128x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc206)
    %k_next_63 = arith.addi %offset_k_fixed_58, %k_next_62 : tensor<128x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc206)
    %k_next_64 = amdgpu.buffer_load %KV_buffer[%k_next_63] : tensor<128x256xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc207)
    %k_scale_f_next = tt.splat %stride_scale_seq : i32 -> tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc208)
    %k_scale_f_next_65 = arith.muli %context_kv_idx_next_59, %k_scale_f_next : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc208)
    %k_scale_f_next_66 = arith.addi %k_scale_f_next_65, %offset_k_fixed_53 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc209)
    %k_scale_f_next_67 = amdgpu.buffer_load %scale_buffer[%k_scale_f_next_66] : tensor<256xf32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc210)
    %mfma_q = ttg.convert_layout %q_32 : tensor<64x128xf8E4M3FNUZ, #blocked> -> tensor<64x128xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc211)
    %5 = arith.addi %split_context_start_11, %split_context_length_15 : i32 loc(#loc73)
    %6 = arith.subi %5, %c256_i32 : i32 loc(#loc74)
    %k_scale_f_next_68:2 = scf.for %k_scale_f_next_83 = %mask_kv_next to %6 step %c256_i32 iter_args(%k_next_84 = %k_next_64, %k_scale_f_next_85 = %k_scale_f_next_67) -> (tensor<128x256xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>>, tensor<256xf32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>>)  : i32 {
      rocdl.sched.barrier 0 loc(#loc76)
      %context_kv_idx_next_86 = arith.addi %k_scale_f_next_83, %c256_i32 : i32 loc(#loc213)
      %context_kv_idx_next_87 = arith.divsi %context_kv_idx_next_86, %c16_i32 : i32 loc(#loc214)
      %context_kv_idx_next_88 = arith.addi %context_kv_idx_next, %context_kv_idx_next_87 : i32 loc(#loc215)
      %context_kv_idx_next_89 = tt.splat %context_kv_idx_next_88 : i32 -> tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc216)
      %context_kv_idx_next_90 = arith.addi %context_kv_idx_next_89, %mask_kv_next_40 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc216)
      %context_kv_idx_next_91 = amdgpu.buffer_load %kv_indices[%context_kv_idx_next_90] : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc217)
      rocdl.sched.barrier 0 loc(#loc82)
      %mfma_k_92 = ttg.convert_layout %k_next_84 : tensor<128x256xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<128x256xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc218)
      %o_93 = tt.dot %mfma_q, %mfma_k_92, %cst_3 : tensor<64x128xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<128x256xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<64x256xf32, #mma> loc(#loc219)
      %k_next_94 = tt.expand_dims %context_kv_idx_next_91 {axis = 0 : i32} : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> -> tensor<1x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc220)
      %k_next_95 = arith.muli %k_next_94, %k_next_60 : tensor<1x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc221)
      %k_next_96 = tt.broadcast %k_next_95 : tensor<1x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<128x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc222)
      %k_next_97 = arith.addi %offset_k_fixed_58, %k_next_96 : tensor<128x256xi32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc222)
      %k_next_98 = amdgpu.buffer_load %KV_buffer[%k_next_97] : tensor<128x256xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc223)
      rocdl.sched.barrier 0 loc(#loc89)
      %k_scale_f_99 = ttg.convert_layout %k_scale_f_next_85 : tensor<256xf32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> -> tensor<256xf32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc224)
      %o_100 = tt.expand_dims %k_scale_f_99 {axis = 0 : i32} : tensor<256xf32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x256xf32, #mma> loc(#loc225)
      %o_101 = tt.broadcast %o_100 : tensor<1x256xf32, #mma> -> tensor<64x256xf32, #mma> loc(#loc226)
      %o_102 = arith.mulf %o_93, %o_101 : tensor<64x256xf32, #mma> loc(#loc226)
      %o_103 = arith.maxnumf %o_102, %cst_3 : tensor<64x256xf32, #mma> loc(#loc227)
      rocdl.sched.barrier 0 loc(#loc94)
      %k_scale_f_next_104 = arith.muli %context_kv_idx_next_91, %k_scale_f_next : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc228)
      %k_scale_f_next_105 = arith.addi %k_scale_f_next_104, %offset_k_fixed_53 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc229)
      %k_scale_f_next_106 = amdgpu.buffer_load %scale_buffer[%k_scale_f_next_105] : tensor<256xf32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc230)
      %o_107 = tt.expand_dims %scale_weight_37 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc231)
      %o_108 = tt.broadcast %o_107 : tensor<64x1xf32, #mma> -> tensor<64x256xf32, #mma> loc(#loc232)
      %o_109 = arith.mulf %o_103, %o_108 : tensor<64x256xf32, #mma> loc(#loc232)
      %mask_110 = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc233)
      %mask_111 = tt.splat %k_scale_f_next_83 : i32 -> tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc234)
      %mask_112 = arith.addi %mask_111, %mask_110 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc234)
      %mask_113 = tt.splat %context_length_7 : i32 -> tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc235)
      %mask_114 = arith.cmpi sle, %mask_112, %mask_113 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc235)
      %o_115 = tt.expand_dims %mask_114 {axis = 0 : i32} : tensor<256xi1, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x256xi1, #mma> loc(#loc236)
      %o_116 = tt.broadcast %o_115 : tensor<1x256xi1, #mma> -> tensor<64x256xi1, #mma> loc(#loc237)
      %o_117 = arith.select %o_116, %o_109, %cst_4 : tensor<64x256xi1, #mma>, tensor<64x256xf32, #mma> loc(#loc237)
      %logits_118 = "tt.reduce"(%o_117) <{axis = 0 : i32}> ({
      ^bb0(%arg22: f32 loc(unknown), %arg23: f32 loc(unknown)):
        %logits_119 = arith.addf %arg22, %arg23 : f32 loc(#loc263)
        tt.reduce.return %logits_119 : f32 loc(#loc238)
      }) : (tensor<64x256xf32, #mma>) -> tensor<256xf32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc238)
      %11 = arith.muli %0, %stride_out_batch : i32 loc(#loc107)
      %12 = tt.splat %11 : i32 -> tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc108)
      %13 = arith.addi %12, %mask_112 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc108)
      %14 = arith.cmpi sge, %mask_112, %cst_5 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc109)
      amdgpu.buffer_store %logits_118, %OutLogits_buffer[%13], %14 : tensor<256xf32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc110)
      scf.yield %k_next_98, %k_scale_f_next_106 : tensor<128x256xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>>, tensor<256xf32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> loc(#loc111)
    } loc(#loc265)
    %mfma_k = ttg.convert_layout %k_scale_f_next_68#0 : tensor<128x256xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<128x256xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc239)
    %o = tt.dot %mfma_q, %mfma_k, %cst_3 : tensor<64x128xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<128x256xf8E4M3FNUZ, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<64x256xf32, #mma> loc(#loc240)
    %k_scale_f = ttg.convert_layout %k_scale_f_next_68#1 : tensor<256xf32, #ttg.slice<{dim = 0, parent = #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>}>> -> tensor<256xf32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc241)
    %o_69 = tt.expand_dims %k_scale_f {axis = 0 : i32} : tensor<256xf32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x256xf32, #mma> loc(#loc242)
    %o_70 = tt.broadcast %o_69 : tensor<1x256xf32, #mma> -> tensor<64x256xf32, #mma> loc(#loc243)
    %o_71 = arith.mulf %o, %o_70 : tensor<64x256xf32, #mma> loc(#loc243)
    %o_72 = arith.maxnumf %o_71, %cst_3 : tensor<64x256xf32, #mma> loc(#loc244)
    %o_73 = tt.expand_dims %scale_weight_37 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc245)
    %o_74 = tt.broadcast %o_73 : tensor<64x1xf32, #mma> -> tensor<64x256xf32, #mma> loc(#loc246)
    %o_75 = arith.mulf %o_72, %o_74 : tensor<64x256xf32, #mma> loc(#loc246)
    %mask = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc247)
    %mask_76 = tt.splat %6 : i32 -> tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc248)
    %mask_77 = arith.addi %mask_76, %mask : tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc248)
    %mask_78 = tt.splat %context_length_7 : i32 -> tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc249)
    %mask_79 = arith.cmpi sle, %mask_77, %mask_78 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc249)
    %o_80 = tt.expand_dims %mask_79 {axis = 0 : i32} : tensor<256xi1, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x256xi1, #mma> loc(#loc250)
    %o_81 = tt.broadcast %o_80 : tensor<1x256xi1, #mma> -> tensor<64x256xi1, #mma> loc(#loc251)
    %o_82 = arith.select %o_81, %o_75, %cst_4 : tensor<64x256xi1, #mma>, tensor<64x256xf32, #mma> loc(#loc251)
    %logits = "tt.reduce"(%o_82) <{axis = 0 : i32}> ({
    ^bb0(%arg19: f32 loc(unknown), %arg20: f32 loc(unknown)):
      %logits_83 = arith.addf %arg19, %arg20 : f32 loc(#loc264)
      tt.reduce.return %logits_83 : f32 loc(#loc252)
    }) : (tensor<64x256xf32, #mma>) -> tensor<256xf32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc252)
    %7 = arith.muli %0, %stride_out_batch : i32 loc(#loc126)
    %8 = tt.splat %7 : i32 -> tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc127)
    %9 = arith.addi %8, %mask_77 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc127)
    %10 = arith.cmpi sge, %mask_77, %cst_5 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc128)
    amdgpu.buffer_store %logits, %OutLogits_buffer[%9], %10 : tensor<256xf32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc129)
    tt.return loc(#loc130)
  } loc(#loc1)
} loc(#loc)
#loc2 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":720:24)
#loc3 = loc("/mnt/raid0/felix/triton/python/triton/language/standard.py":41:22)
#loc4 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":721:42)
#loc5 = loc("/mnt/raid0/felix/triton/python/triton/language/standard.py":41:28)
#loc6 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":723:34)
#loc7 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":723:53)
#loc8 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":725:21)
#loc9 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":726:22)
#loc10 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":730:47)
#loc11 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":730:29)
#loc12 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":732:48)
#loc13 = loc("/mnt/raid0/felix/triton/python/triton/language/standard.py":41:16)
#loc14 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":733:57)
#loc15 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":735:42)
#loc16 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":735:69)
#loc17 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":737:25)
#loc18 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":737:72)
#loc19 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":737:46)
#loc20 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":740:31)
#loc21 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":741:8)
#loc22 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":743:56)
#loc23 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":744:49)
#loc24 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":747:54)
#loc25 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":747:32)
#loc26 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":748:8)
#loc27 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":749:49)
#loc28 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":756:28)
#loc29 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":760:29)
#loc30 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":761:31)
#loc31 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":761:18)
#loc32 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":763:14)
#loc33 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":764:10)
#loc34 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":758:10)
#loc35 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":765:23)
#loc36 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":765:70)
#loc37 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":765:10)
#loc38 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":756:8)
#loc39 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":769:52)
#loc40 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":770:10)
#loc41 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":771:23)
#loc42 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":771:10)
#loc43 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":769:8)
#loc44 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":775:31)
#loc45 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":775:52)
#loc46 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":776:23)
#loc47 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":776:75)
#loc48 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":776:10)
#loc49 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":777:9)
#loc50 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":780:28)
#loc51 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":781:10)
#loc52 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":782:10)
#loc53 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":783:8)
#loc54 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":787:21)
#loc55 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":787:75)
#loc56 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":788:78)
#loc57 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":788:83)
#loc58 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":788:10)
#loc59 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":789:6)
#loc60 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":790:72)
#loc61 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":790:77)
#loc62 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":792:8)
#loc63 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":789:17)
#loc64 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":799:70)
#loc65 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":802:53)
#loc66 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":802:64)
#loc67 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":802:33)
#loc68 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":802:8)
#loc69 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":806:38)
#loc70 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":807:10)
#loc71 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":806:8)
#loc72 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":809:34)
#loc73 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":814:30)
#loc74 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":814:53)
#loc75 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":815:8)
#loc76 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":821:35)
#loc77 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":827:29)
#loc78 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":827:40)
#loc79 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":827:14)
#loc80 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":828:14)
#loc81 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":826:12)
#loc82 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":833:35)
#loc83 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":836:38)
#loc84 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":837:46)
#loc85 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":842:57)
#loc86 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":842:68)
#loc87 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":842:37)
#loc88 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":842:12)
#loc89 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":849:35)
#loc90 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":851:49)
#loc91 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":852:26)
#loc92 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":852:16)
#loc93 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":853:26)
#loc94 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":856:35)
#loc95 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":860:42)
#loc96 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":861:14)
#loc97 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":860:12)
#loc98 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":864:29)
#loc99 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":864:16)
#loc100 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":867:39)
#loc101 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":867:26)
#loc102 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":868:15)
#loc103 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":870:26)
#loc104 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":870:39)
#loc105 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":872:27)
#loc106 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":15:15)
#loc107 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":876:56)
#loc108 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":878:16)
#loc109 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":883:15)
#loc110 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":874:12)
#loc111 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":873:8)
#loc112 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":890:34)
#loc113 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":891:42)
#loc114 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":893:45)
#loc115 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":894:22)
#loc116 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":894:12)
#loc117 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":895:22)
#loc118 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":896:25)
#loc119 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":896:12)
#loc120 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":899:35)
#loc121 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":899:22)
#loc122 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":900:11)
#loc123 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":902:22)
#loc124 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":902:35)
#loc125 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":904:23)
#loc126 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":908:52)
#loc127 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":909:11)
#loc128 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":911:11)
#loc129 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":906:8)
#loc130 = loc("/mnt/raid0/felix/aiter/aiter/ops/triton/_triton_kernels/pa_mqa_logits.py":905:4)
#loc150 = loc("pid"(#loc2))
#loc151 = loc("num_block_q_head"(#loc4))
#loc152 = loc("context_length"(#loc10))
#loc153 = loc("context_length"(#loc11))
#loc154 = loc("context_chunk_num"(#loc12))
#loc155 = loc("split_context_chunk_num"(#loc14))
#loc156 = loc("split_context_start"(#loc15))
#loc157 = loc("split_context_start"(#loc16))
#loc158 = loc("split_context_length"(#loc17))
#loc159 = loc("split_context_length"(#loc18))
#loc160 = loc("split_context_length"(#loc19))
#loc161 = loc("split_context_block"(#loc22))
#loc162 = loc("split_context_length"(#loc23))
#loc163 = loc("residual_context_blocks"(#loc24))
#loc164 = loc("residual_context_blocks"(#loc25))
#loc165 = loc("residual_context_blocks"(#loc26))
#loc166 = loc("residual_context"(#loc27))
#loc167 = loc("q"(#loc28))
#loc168 = loc("q"(#loc29))
#loc169 = loc("q"(#loc30))
#loc170 = loc("q"(#loc31))
#loc171 = loc("q"(#loc32))
#loc172 = loc("q"(#loc33))
#loc173 = loc("q"(#loc34))
#loc174 = loc("q"(#loc35))
#loc175 = loc("q"(#loc36))
#loc176 = loc("q"(#loc37))
#loc177 = loc("q"(#loc38))
#loc178 = loc("scale_weight"(#loc39))
#loc179 = loc("scale_weight"(#loc40))
#loc180 = loc("scale_weight"(#loc41))
#loc181 = loc("scale_weight"(#loc42))
#loc182 = loc("scale_weight"(#loc43))
#loc183 = loc("mask_kv_next"(#loc44))
#loc184 = loc("mask_kv_next"(#loc45))
#loc185 = loc("mask_kv_next"(#loc46))
#loc186 = loc("mask_kv_next"(#loc47))
#loc187 = loc("mask_kv_next"(#loc48))
#loc188 = loc("mask_kv_next"(#loc49))
#loc189 = loc("context_kv_idx_next"(#loc50))
#loc190 = loc("context_kv_idx_next"(#loc51))
#loc191 = loc("context_kv_idx_next"(#loc52))
#loc192 = loc("context_kv_idx_next"(#loc53))
#loc193 = loc("offset_k_fixed"(#loc54))
#loc194 = loc("offset_k_fixed"(#loc55))
#loc195 = loc("offset_k_fixed"(#loc56))
#loc196 = loc("offset_k_fixed"(#loc57))
#loc197 = loc("offset_k_fixed"(#loc58))
#loc198 = loc("offset_k_fixed"(#loc59))
#loc199 = loc("offset_k_fixed"(#loc60))
#loc200 = loc("offset_k_fixed"(#loc61))
#loc201 = loc("offset_k_fixed"(#loc62))
#loc202 = loc("offset_k_fixed"(#loc63))
#loc203 = loc("context_kv_idx_next"(#loc64))
#loc204 = loc("k_next"(#loc65))
#loc205 = loc("k_next"(#loc66))
#loc206 = loc("k_next"(#loc67))
#loc207 = loc("k_next"(#loc68))
#loc208 = loc("k_scale_f_next"(#loc69))
#loc209 = loc("k_scale_f_next"(#loc70))
#loc210 = loc("k_scale_f_next"(#loc71))
#loc211 = loc("mfma_q"(#loc72))
#loc212 = loc("context_kv_idx_next"(#loc75))
#loc213 = loc("context_kv_idx_next"(#loc77))
#loc214 = loc("context_kv_idx_next"(#loc78))
#loc215 = loc("context_kv_idx_next"(#loc79))
#loc216 = loc("context_kv_idx_next"(#loc80))
#loc217 = loc("context_kv_idx_next"(#loc81))
#loc218 = loc("mfma_k"(#loc83))
#loc219 = loc("o"(#loc84))
#loc220 = loc("k_next"(#loc85))
#loc221 = loc("k_next"(#loc86))
#loc222 = loc("k_next"(#loc87))
#loc223 = loc("k_next"(#loc88))
#loc224 = loc("k_scale_f"(#loc90))
#loc225 = loc("o"(#loc91))
#loc226 = loc("o"(#loc92))
#loc227 = loc("o"(#loc93))
#loc228 = loc("k_scale_f_next"(#loc95))
#loc229 = loc("k_scale_f_next"(#loc96))
#loc230 = loc("k_scale_f_next"(#loc97))
#loc231 = loc("o"(#loc98))
#loc232 = loc("o"(#loc99))
#loc233 = loc("mask"(#loc100))
#loc234 = loc("mask"(#loc101))
#loc235 = loc("mask"(#loc102))
#loc236 = loc("o"(#loc103))
#loc237 = loc("o"(#loc104))
#loc238 = loc("logits"(#loc105))
#loc239 = loc("mfma_k"(#loc112))
#loc240 = loc("o"(#loc113))
#loc241 = loc("k_scale_f"(#loc114))
#loc242 = loc("o"(#loc115))
#loc243 = loc("o"(#loc116))
#loc244 = loc("o"(#loc117))
#loc245 = loc("o"(#loc118))
#loc246 = loc("o"(#loc119))
#loc247 = loc("mask"(#loc120))
#loc248 = loc("mask"(#loc121))
#loc249 = loc("mask"(#loc122))
#loc250 = loc("o"(#loc123))
#loc251 = loc("o"(#loc124))
#loc252 = loc("logits"(#loc125))
#loc253 = loc(callsite(#loc3 at #loc151))
#loc254 = loc(callsite(#loc5 at #loc151))
#loc255 = loc(callsite(#loc3 at #loc154))
#loc256 = loc(callsite(#loc5 at #loc154))
#loc257 = loc(callsite(#loc13 at #loc155))
#loc258 = loc(callsite(#loc3 at #loc155))
#loc259 = loc(callsite(#loc5 at #loc155))
#loc260 = loc(callsite(#loc3 at #loc161))
#loc261 = loc(callsite(#loc5 at #loc161))
#loc262 = loc("k_next"(#loc212))
#loc263 = loc(callsite(#loc106 at #loc238))
#loc264 = loc(callsite(#loc106 at #loc252))
#loc265 = loc("k_scale_f_next"(#loc262))
