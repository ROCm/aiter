{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76aefa7d",
   "metadata": {},
   "source": [
    "# MoE Kernel Benchmark Analysis\n",
    "\n",
    "This notebook analyzes benchmark results\n",
    "\n",
    "## Hypotheses to Test:\n",
    "1. **Does the activation affect the time and kernel selection? (why?)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89f6f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Imports (if not already run)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Comparison Table for Jupyter Notebook\n",
    "# Copy these cells into moe_kernel_analysis.ipynb\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 1: Load Data\n",
    "# ============================================================================\n",
    "\n",
    "# Load activation comparison results\n",
    "act_df = pd.read_csv('../results_activation_comparison.csv')\n",
    "\n",
    "# Filter valid results\n",
    "valid_df = act_df[act_df['error'] != 'failed'].copy()\n",
    "valid_df['error_pct'] = valid_df['error'].str.rstrip('%').astype(float)\n",
    "valid_df = valid_df[valid_df['error_pct'] < 50.0]\n",
    "\n",
    "print(f\"Loaded {len(valid_df)} valid kernel results\")\n",
    "print(f\"  Silu: {len(valid_df[valid_df['act_type'] == 'ActivationType.Silu'])}\")\n",
    "print(f\"  Gelu: {len(valid_df[valid_df['act_type'] == 'ActivationType.Gelu'])}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 2: Create Comparison Table\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nCreating Silu vs Gelu comparison table...\")\n",
    "\n",
    "# Normalize kernel names (remove activation)\n",
    "def normalize_kernel_name(kernel_name):\n",
    "    base = kernel_name\n",
    "    if '_silu_' in base.lower():\n",
    "        base = base.replace('_silu_', '_ACT_').replace('_Silu_', '_ACT_')\n",
    "    elif '_gelu_' in base.lower():\n",
    "        base = base.replace('_gelu_', '_ACT_').replace('_Gelu_', '_ACT_')\n",
    "    return base\n",
    "\n",
    "valid_df['kernel_base_name'] = valid_df['kernel_name'].apply(normalize_kernel_name)\n",
    "\n",
    "\n",
    "# Define matching columns\n",
    "match_cols = [\n",
    "    'token', 'model_dim', 'inter_dim', 'expert', 'topk',\n",
    "    'dtype', 'q_dtype_a', 'q_dtype_w', 'q_type',\n",
    "    'use_g1u1', 'doweight_stage1',\n",
    "    'stage', 'block_m', 'kernel_type', 'tile_m', 'tile_n',\n",
    "    'kernel_base_name'\n",
    "]\n",
    "\n",
    "# Separate Silu and Gelu\n",
    "silu_df = valid_df[valid_df['act_type'] == 'ActivationType.Silu'].copy()\n",
    "gelu_df = valid_df[valid_df['act_type'] == 'ActivationType.Gelu'].copy()\n",
    "\n",
    "# Merge on matching columns\n",
    "comparison = silu_df.merge(\n",
    "    gelu_df,\n",
    "    on=match_cols,\n",
    "    how='inner',\n",
    "    suffixes=('_silu', '_gelu')\n",
    ")\n",
    "\n",
    "# Calculate differences\n",
    "comparison['time_diff_us'] = comparison['time_us_gelu'] - comparison['time_us_silu']\n",
    "comparison['time_diff_pct'] = (comparison['time_diff_us'] / comparison['time_us_silu']) * 100\n",
    "comparison['faster'] = comparison.apply(\n",
    "    lambda row: 'Silu' if row['time_us_silu'] < row['time_us_gelu'] else 'Gelu',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Select display columns\n",
    "display_cols = [\n",
    "    'config_idx_silu', 'token', 'model_dim', 'expert', 'topk', \n",
    "    'stage', 'kernel_type', 'block_m',  # Added kernel_type and block_m\n",
    "    'kernel_name_silu', 'kernel_name_gelu',\n",
    "    'time_us_silu', 'time_us_gelu', \n",
    "    'time_diff_pct', 'faster',\n",
    "    'error_silu', 'error_gelu'\n",
    "]\n",
    "\n",
    "result = comparison[display_cols].copy()\n",
    "result = result.rename(columns={'config_idx_silu': 'config_idx'})\n",
    "\n",
    "# Sort by absolute difference\n",
    "result = result.sort_values('time_diff_pct', key=abs, ascending=False)\n",
    "\n",
    "print(f\"Matched kernel pairs: {len(result)}\")\n",
    "print(f\"Silu faster: {(result['faster'] == 'Silu').sum()} ({(result['faster'] == 'Silu').sum()/len(result)*100:.1f}%)\")\n",
    "print(f\"Gelu faster: {(result['faster'] == 'Gelu').sum()} ({(result['faster'] == 'Gelu').sum()/len(result)*100:.1f}%)\")\n",
    "print(f\"Average difference: {result['time_diff_pct'].abs().mean():.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 3: Display Table\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nComparison Table (sorted by largest performance difference):\")\n",
    "print(\"=\"*80)\n",
    "display(result.head(20))\n",
    "\n",
    "print(\"\\n**Table Columns:**\")\n",
    "print(\"- time_us_silu: Kernel execution time with Silu activation\")\n",
    "print(\"- time_us_gelu: Kernel execution time with Gelu activation\")\n",
    "print(\"- time_diff_pct: Percentage difference (Gelu relative to Silu)\")\n",
    "print(\"  - Negative = Silu faster\")\n",
    "print(\"  - Positive = Gelu faster\")\n",
    "print(\"- faster: Which activation is faster for this kernel\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 4: Summary Statistics\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nOverall:\")\n",
    "print(f\"  Matched pairs: {len(result)}\")\n",
    "print(f\"  Average |difference|: {result['time_diff_pct'].abs().mean():.2f}%\")\n",
    "print(f\"  Median |difference|: {result['time_diff_pct'].abs().median():.2f}%\")\n",
    "print(f\"  Max |difference|: {result['time_diff_pct'].abs().max():.2f}%\")\n",
    "\n",
    "print(f\"\\nBy Stage:\")\n",
    "for stage in result['stage'].unique():\n",
    "    stage_data = result[result['stage'] == stage]\n",
    "    print(f\"  {stage}: {len(stage_data)} kernels, avg diff = {stage_data['time_diff_pct'].abs().mean():.2f}%\")\n",
    "\n",
    "if 'kernel_type' in result.columns:\n",
    "    print(f\"\\nBy Kernel Type:\")\n",
    "    for ktype in result['kernel_type'].unique():\n",
    "        ktype_data = result[result['kernel_type'] == ktype]\n",
    "        silu_wins = (ktype_data['faster'] == 'Silu').sum()\n",
    "        print(f\"  {ktype}: Silu wins {silu_wins}/{len(ktype_data)} ({silu_wins/len(ktype_data)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cell 5: Interactive Visualization (2x2 Grid with Plotly)\n",
    "# ============================================================================\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create plot groups (stage1-asm, stage1-ck, stage2, asm_1stage)\n",
    "plot_groups = []\n",
    "\n",
    "stage1_data = result[result['stage'] == 'stage1']\n",
    "for ktype in sorted(stage1_data['kernel_type'].unique()):\n",
    "    data = stage1_data[stage1_data['kernel_type'] == ktype]\n",
    "    plot_groups.append((f'Stage1-{ktype.upper()}', data))\n",
    "\n",
    "for stage in ['stage2', 'asm_1stage']:\n",
    "    stage_data = result[result['stage'] == stage]\n",
    "    if len(stage_data) > 0:\n",
    "        plot_groups.append((stage, stage_data))\n",
    "\n",
    "# Create 2x2 subplot grid\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[f'{label} ({len(data)} kernels)' for label, data in plot_groups],\n",
    "    horizontal_spacing=0.12,\n",
    "    vertical_spacing=0.15\n",
    ")\n",
    "\n",
    "for idx, (label, data) in enumerate(plot_groups):\n",
    "    row = (idx // 2) + 1\n",
    "    col = (idx % 2) + 1\n",
    "    \n",
    "    # Create hover text with kernel details\n",
    "    hover_text = []\n",
    "    for _, r in data.iterrows():\n",
    "        block_m_info = f\"block_m={r['block_m']}<br>\" if 'block_m' in data.columns else \"\"\n",
    "        text = (f\"<b>Config #{r['config_idx']}</b><br>\"\n",
    "                f\"Token={r['token']}, Model={r['model_dim']}, Expert={r['expert']}, TopK={r['topk']}<br>\"\n",
    "                f\"{block_m_info}\"\n",
    "                f\"<br><b>Silu Kernel:</b><br>{r['kernel_name_silu'][:80]}<br>\"\n",
    "                f\"Time: {r['time_us_silu']:.2f} us (err={r['error_silu']})<br>\"\n",
    "                f\"<br><b>Gelu Kernel:</b><br>{r['kernel_name_gelu'][:80]}<br>\"\n",
    "                f\"Time: {r['time_us_gelu']:.2f} us (err={r['error_gelu']})<br>\"\n",
    "                f\"<br><b>Performance:</b> {r['time_diff_pct']:.2f}% ({r['faster']} faster)\")\n",
    "        hover_text.append(text)\n",
    "    \n",
    "    # Add scatter trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=data['time_us_silu'],\n",
    "            y=data['time_us_gelu'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=8,\n",
    "                color=data['time_diff_pct'],\n",
    "                colorscale='RdYlGn_r',\n",
    "                cmin=-10,\n",
    "                cmax=10,\n",
    "                showscale=False,  # Remove colorbar\n",
    "                line=dict(width=1, color='DarkSlateGray')\n",
    "            ),\n",
    "            hovertext=hover_text,\n",
    "            hoverinfo='text',\n",
    "            name=label,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "    \n",
    "    # Add diagonal line (equal performance)\n",
    "    if len(data) > 0:\n",
    "        max_val = max(data['time_us_silu'].max(), data['time_us_gelu'].max())\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[0, max_val],\n",
    "                y=[0, max_val],\n",
    "                mode='lines',\n",
    "                line=dict(color='red', dash='dash', width=2),\n",
    "                name='Equal Performance',\n",
    "                showlegend=(idx == 0),\n",
    "                hoverinfo='skip'\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "    \n",
    "    # Update axes\n",
    "    fig.update_xaxes(title_text='Silu Time (us)', row=row, col=col)\n",
    "    fig.update_yaxes(title_text='Gelu Time (us)', row=row, col=col)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=900,\n",
    "    width=1400,\n",
    "    title_text='Interactive Kernel Performance: Silu vs Gelu<br><sub>Hover over points for details</sub>',\n",
    "    title_font_size=18,\n",
    "    showlegend=True,\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nâœ… Interactive Features:\")\n",
    "print(\"  - Hover over any point to see full kernel details\")\n",
    "print(\"  - Zoom: Click and drag to select area\")\n",
    "print(\"  - Pan: Hold shift and drag\")\n",
    "print(\"  - Reset: Double-click\")\n",
    "print(\"\\nðŸ“Š Color Legend:\")\n",
    "print(\"  - Red (above diagonal) = Gelu is SLOWER\")\n",
    "print(\"  - Green (below diagonal) = Gelu is FASTER\")\n",
    "print(\"  - White (on diagonal) = Equal performance\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
