#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•æµ‹è¯• AIter Causal Conv1D
"""

import torch
import torch.nn.functional as F
import aiter
import time

def causal_conv1d_ref(
    x,
    weight,
    bias=None,
    initial_states=None,
    return_final_states=False,
    final_states_out=None,
    activation=None,
):
    """
    x: (batch, dim, seqlen)
    weight: (dim, width)
    bias: (dim,)
    initial_states: (batch, dim, width - 1)
    final_states_out: (batch, dim, width - 1)

    out: (batch, dim, seqlen)
    """
    if activation not in [None, "silu", "swish"]:
        raise NotImplementedError("activation must be None, silu, or swish")
    dtype_in = x.dtype
    x = x.to(weight.dtype)
    seqlen = x.shape[-1]
    dim, width = weight.shape
    if initial_states is None:
        out = F.conv1d(x, weight.unsqueeze(1), bias, padding=width - 1, groups=dim)
    else:
        x = torch.cat([initial_states, x], dim=-1)
        out = F.conv1d(x, weight.unsqueeze(1), bias, padding=0, groups=dim)
    out = out[..., :seqlen]
    if return_final_states:
        final_states = F.pad(x, (width - 1 - x.shape[-1], 0)).to(
            dtype_in
        )  # (batch, dim, width - 1)
        if final_states_out is not None:
            final_states_out.copy_(final_states)
        else:
            final_states_out = final_states
    out = (out if activation is None else F.silu(out)).to(dtype=dtype_in)
    return out if not return_final_states else (out, final_states_out)

print("=" * 80)
print("AIter Causal Conv1D ç®€å•æµ‹è¯•")
print("=" * 80)

# æµ‹è¯•é…ç½®
batch = 2
dim = 256
seqlen = 1024
width = 4
dtype = torch.float16

print(f"\nğŸ“Š æµ‹è¯•é…ç½®:")
print(f"   Batch: {batch}")
print(f"   Dim: {dim}")
print(f"   Seqlen: {seqlen}")
print(f"   Width: {width}")
print(f"   Dtype: {dtype}")

# åˆ›å»ºè¾“å…¥å¼ é‡
print("\nğŸ”§ åˆ›å»ºè¾“å…¥å¼ é‡...")
x = torch.randn(batch, dim, seqlen, dtype=dtype, device="cuda")
weight = torch.randn(dim, width, dtype=dtype, device="cuda")
bias = torch.randn(dim, dtype=dtype, device="cuda")
out = torch.empty_like(x)

print(f"   x shape: {x.shape}, dtype: {x.dtype}")
print(f"   weight shape: {weight.shape}, dtype: {weight.dtype}")
print(f"   bias shape: {bias.shape}, dtype: {bias.dtype}")

# æµ‹è¯• 1: åŸºç¡€è°ƒç”¨ï¼ˆæ— æ¿€æ´»ï¼‰+ å‡†ç¡®ç‡éªŒè¯
print("\n" + "=" * 80)
print("æµ‹è¯• 1: åŸºç¡€ Causal Conv1D (æ— æ¿€æ´») + å‡†ç¡®ç‡éªŒè¯")
print("=" * 80)
try:
    # è¿è¡Œ AIter å®ç°
    # æ­£ç¡®çš„ç­¾åï¼šcausal_conv1d_fwd(x, weight, bias, seq_idx, initial_states, out, final_states_out, silu_activation)
    aiter.causal_conv1d_fwd(x, weight, bias, None, None, out, None, False)
    
    # è®¡ç®— CPU å‚è€ƒç»“æœ
    print("   è®¡ç®— CPU å‚è€ƒç»“æœ...")
    x_cpu = x.cpu().float()
    weight_cpu = weight.cpu().float()
    bias_cpu = bias.cpu().float()
    ref_cpu = causal_conv1d_ref(x_cpu, weight_cpu, bias_cpu, activation=None)
    ref_gpu = ref_cpu.to(dtype).cuda()
    
    # è®¡ç®—è¯¯å·®
    max_error = (out - ref_gpu).abs().max().item()
    mean_error = (out - ref_gpu).abs().mean().item()
    
    print("âœ… è°ƒç”¨æˆåŠŸï¼")
    print(f"   out shape: {out.shape}")
    print(f"   out min: {out.min().item():.4f}, max: {out.max().item():.4f}, mean: {out.mean().item():.4f}")
    print(f"   ğŸ“Š å‡†ç¡®ç‡:")
    print(f"      æœ€å¤§è¯¯å·®: {max_error:.2e}")
    print(f"      å¹³å‡è¯¯å·®: {mean_error:.2e}")
    
    if max_error < 1e-2:  # fp16 ç²¾åº¦é˜ˆå€¼
        print(f"      âœ… å‡†ç¡®ç‡éªŒè¯é€šè¿‡ï¼")
    else:
        print(f"      âš ï¸  è¯¯å·®è¾ƒå¤§ï¼Œå¯èƒ½æœ‰é—®é¢˜")
        
except Exception as e:
    print(f"âŒ è°ƒç”¨å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# æµ‹è¯• 2: å¸¦ SiLU æ¿€æ´» + å‡†ç¡®ç‡éªŒè¯
print("\n" + "=" * 80)
print("æµ‹è¯• 2: Causal Conv1D + SiLU æ¿€æ´» + å‡†ç¡®ç‡éªŒè¯")
print("=" * 80)
out_silu = torch.empty_like(x)
try:
    # è¿è¡Œ AIter å®ç°
    aiter.causal_conv1d_fwd(x, weight, bias, None, None, out_silu, None, True)
    
    # è®¡ç®— CPU å‚è€ƒç»“æœ
    print("   è®¡ç®— CPU å‚è€ƒç»“æœ...")
    ref_silu_cpu = causal_conv1d_ref(x_cpu, weight_cpu, bias_cpu, activation="silu")
    ref_silu_gpu = ref_silu_cpu.to(dtype).cuda()
    
    # è®¡ç®—è¯¯å·®
    max_error_silu = (out_silu - ref_silu_gpu).abs().max().item()
    mean_error_silu = (out_silu - ref_silu_gpu).abs().mean().item()
    
    print("âœ… SiLU æµ‹è¯•æˆåŠŸï¼")
    print(f"   out_silu min: {out_silu.min().item():.4f}, max: {out_silu.max().item():.4f}")
    print(f"   ğŸ“Š å‡†ç¡®ç‡:")
    print(f"      æœ€å¤§è¯¯å·®: {max_error_silu:.2e}")
    print(f"      å¹³å‡è¯¯å·®: {mean_error_silu:.2e}")
    
    # éªŒè¯ SiLU çš„æ•ˆæœï¼ˆè¾“å‡ºåº”è¯¥ä¸åŒï¼‰
    diff = (out - out_silu).abs().max().item()
    print(f"   ä¸æ— æ¿€æ´»ç‰ˆæœ¬çš„æœ€å¤§å·®å¼‚: {diff:.4f}")
    if diff > 0.01:
        print("   âœ… SiLU æ¿€æ´»ç”Ÿæ•ˆ")
    
    if max_error_silu < 1e-2:
        print(f"   âœ… SiLU å‡†ç¡®ç‡éªŒè¯é€šè¿‡ï¼")
    else:
        print(f"   âš ï¸  SiLU è¯¯å·®è¾ƒå¤§")
        
except Exception as e:
    print(f"âŒ SiLU æµ‹è¯•å¤±è´¥: {e}")

# æµ‹è¯• 3: æ—  bias + å‡†ç¡®ç‡éªŒè¯
print("\n" + "=" * 80)
print("æµ‹è¯• 3: Causal Conv1D (æ—  bias) + å‡†ç¡®ç‡éªŒè¯")
print("=" * 80)
# AIter éœ€è¦ä¼ é€’å½¢çŠ¶ä¸º (dim,) çš„é›¶ tensorï¼Œè€Œä¸æ˜¯ç©º tensor
bias_empty = torch.zeros(dim, dtype=dtype, device="cuda")
out_no_bias = torch.empty_like(x)
try:
    # è¿è¡Œ AIter å®ç°
    aiter.causal_conv1d_fwd(x, weight, bias_empty, None, None, out_no_bias, None, False)
    
    # è®¡ç®— CPU å‚è€ƒç»“æœ
    print("   è®¡ç®— CPU å‚è€ƒç»“æœ...")
    ref_no_bias_cpu = causal_conv1d_ref(x_cpu, weight_cpu, None, activation=None)
    ref_no_bias_gpu = ref_no_bias_cpu.to(dtype).cuda()
    
    # è®¡ç®—è¯¯å·®
    max_error_no_bias = (out_no_bias - ref_no_bias_gpu).abs().max().item()
    mean_error_no_bias = (out_no_bias - ref_no_bias_gpu).abs().mean().item()
    
    print("âœ… æ—  bias æµ‹è¯•æˆåŠŸï¼")
    print(f"   out_no_bias mean: {out_no_bias.mean().item():.4f}")
    print(f"   ğŸ“Š å‡†ç¡®ç‡:")
    print(f"      æœ€å¤§è¯¯å·®: {max_error_no_bias:.2e}")
    print(f"      å¹³å‡è¯¯å·®: {mean_error_no_bias:.2e}")
    
    if max_error_no_bias < 1e-2:
        print(f"      âœ… æ—  bias å‡†ç¡®ç‡éªŒè¯é€šè¿‡ï¼")
    else:
        print(f"      âš ï¸  è¯¯å·®è¾ƒå¤§")
        
except Exception as e:
    print(f"âŒ æ—  bias æµ‹è¯•å¤±è´¥: {e}")

# æµ‹è¯• 4: ä¸åŒæ•°æ®ç±»å‹ + å‡†ç¡®ç‡éªŒè¯
print("\n" + "=" * 80)
print("æµ‹è¯• 4: ä¸åŒæ•°æ®ç±»å‹ + å‡†ç¡®ç‡éªŒè¯")
print("=" * 80)

for test_dtype in [torch.float16, torch.bfloat16, torch.float32]:
    dtype_name = str(test_dtype).split('.')[-1]
    try:
        x_test = torch.randn(2, 128, 512, dtype=test_dtype, device="cuda")
        weight_test = torch.randn(128, 4, dtype=test_dtype, device="cuda")
        bias_test = torch.randn(128, dtype=test_dtype, device="cuda")
        out_test = torch.empty_like(x_test)
        
        # è¿è¡Œ AIter å®ç°
        aiter.causal_conv1d_fwd(x_test, weight_test, bias_test, None, None, out_test, None, False)
        
        # è®¡ç®— CPU å‚è€ƒç»“æœ
        x_test_cpu = x_test.cpu().float()
        weight_test_cpu = weight_test.cpu().float()
        bias_test_cpu = bias_test.cpu().float()
        ref_test_cpu = causal_conv1d_ref(x_test_cpu, weight_test_cpu, bias_test_cpu, activation=None)
        ref_test_gpu = ref_test_cpu.to(test_dtype).cuda()
        
        # è®¡ç®—è¯¯å·®
        max_error_test = (out_test - ref_test_gpu).abs().max().item()
        
        # æ ¹æ®æ•°æ®ç±»å‹è®¾ç½®ä¸åŒçš„é˜ˆå€¼
        threshold = 1e-2 if test_dtype in [torch.float16, torch.bfloat16] else 1e-4
        
        if max_error_test < threshold:
            print(f"   âœ… {dtype_name}: æˆåŠŸ (æœ€å¤§è¯¯å·®: {max_error_test:.2e})")
        else:
            print(f"   âš ï¸  {dtype_name}: æˆåŠŸä½†è¯¯å·®è¾ƒå¤§ (æœ€å¤§è¯¯å·®: {max_error_test:.2e})")
            
    except Exception as e:
        print(f"   âŒ {dtype_name}: å¤±è´¥ - {e}")

# æµ‹è¯• 5: æ€§èƒ½æµ‹è¯•
print("\n" + "=" * 80)
print("æµ‹è¯• 5: æ€§èƒ½æµ‹è¯•")
print("=" * 80)

# Warmup
print("   é¢„çƒ­ä¸­...")
for _ in range(10):
    aiter.causal_conv1d_fwd(x, weight, bias, None, None, out, None, True)

# Benchmark
print("   æ€§èƒ½æµ‹è¯•ä¸­...")
torch.cuda.synchronize()
start = time.time()
num_iters = 100
for _ in range(num_iters):
    aiter.causal_conv1d_fwd(x, weight, bias, None, None, out, None, True)
torch.cuda.synchronize()
elapsed = time.time() - start

avg_time_ms = elapsed * 1000 / num_iters
total_elements = batch * dim * seqlen
throughput = total_elements * num_iters / elapsed / 1e9

# è®¡ç®—å¸¦å®½
bytes_read = x.nbytes + weight.nbytes + bias.nbytes
bytes_write = out.nbytes
total_bytes = bytes_read + bytes_write
bandwidth_gb_s = total_bytes * num_iters / elapsed / 1e9

print(f"   âœ… å¹³å‡æ—¶é—´: {avg_time_ms:.3f} ms")
print(f"   âœ… ååé‡: {throughput:.2f} G elements/s")
print(f"   âœ… å¸¦å®½: {bandwidth_gb_s:.2f} GB/s")

# æµ‹è¯• 6: éªŒè¯å› æœæ€§
print("\n" + "=" * 80)
print("æµ‹è¯• 6: éªŒè¯å› æœæ€§ï¼ˆè¾“å‡ºä¸ä¾èµ–æœªæ¥è¾“å…¥ï¼‰")
print("=" * 80)

# åˆ›å»ºä¸¤ä¸ªè¾“å…¥ï¼Œåªåœ¨æœªæ¥ä½ç½®ä¸åŒ
x1 = torch.randn(1, 4, 10, dtype=torch.float32, device="cuda")
x2 = x1.clone()
x2[:, :, -1] = 999.0  # ä¿®æ”¹æœ€åä¸€ä¸ªä½ç½®ï¼ˆæœªæ¥ï¼‰

out1 = torch.empty_like(x1)
out2 = torch.empty_like(x2)

weight_test = torch.randn(4, 4, dtype=torch.float32, device="cuda")
bias_test = torch.randn(4, dtype=torch.float32, device="cuda")

aiter.causal_conv1d_fwd(x1, weight_test, bias_test, None, None, out1, None, False)
aiter.causal_conv1d_fwd(x2, weight_test, bias_test, None, None, out2, None, False)

# æ£€æŸ¥å‰ 9 ä¸ªä½ç½®æ˜¯å¦ç›¸åŒï¼ˆä¸åº”è¯¥å—æœªæ¥å½±å“ï¼‰
diff_past = (out1[:, :, :-1] - out2[:, :, :-1]).abs().max().item()
print(f"   å‰ 9 ä¸ªä½ç½®çš„æœ€å¤§å·®å¼‚: {diff_past:.6f}")
if diff_past < 1e-5:
    print("   âœ… å› æœæ€§éªŒè¯é€šè¿‡ï¼è¾“å‡ºä¸ä¾èµ–æœªæ¥è¾“å…¥")
else:
    print("   âš ï¸  å› æœæ€§å¯èƒ½æœ‰é—®é¢˜")

# æœ€åä¸€ä¸ªä½ç½®åº”è¯¥ä¸åŒï¼ˆå—å½“å‰è¾“å…¥å½±å“ï¼‰
diff_current = (out1[:, :, -1] - out2[:, :, -1]).abs().max().item()
print(f"   æœ€åä½ç½®çš„æœ€å¤§å·®å¼‚: {diff_current:.6f}")
if diff_current > 0.1:
    print("   âœ… å½“å‰ä½ç½®æ­£ç¡®å“åº”è¾“å…¥å˜åŒ–")

# æ€»ç»“
print("\n" + "=" * 80)
print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
print("=" * 80)
print("\nğŸ“– æ›´å¤šæµ‹è¯•:")
print("   python op_tests/test_causal_conv1d.py")
print("\nğŸ“š æŸ¥çœ‹æ–‡æ¡£:")
print("   cat csrc/kernels/CAUSAL_CONV1D_INTEGRATION.md")

