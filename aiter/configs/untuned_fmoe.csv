token,model_dim,inter_dim,expert,topk,act_type,dtype,q_dtype_a,q_dtype_w,q_type,use_g1u1,doweight_stage1
128,7168,512,8,2,ActivationType.Silu,torch.bfloat16,fp8,fp8,QuantType.per_Token,1,0