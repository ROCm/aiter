#blocked = #ttg.blocked<{sizePerThread = [2, 8], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [16, 4], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [4, 8], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [32, 2], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [2, 1, 8], threadsPerWarp = [8, 1, 8], warpsPerCTA = [1, 1, 4], order = [2, 1, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [2, 8, 1], threadsPerWarp = [8, 8, 1], warpsPerCTA = [1, 4, 1], order = [1, 2, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [8, 4], threadsPerWarp = [8, 8], warpsPerCTA = [4, 1], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [0, 1]}>
#linear = #ttg.linear<{register = [[0, 0, 1], [0, 1, 0], [0, 2, 0], [0, 64, 0], [0, 128, 0]], lane = [[1, 0, 0], [2, 0, 0], [4, 0, 0], [8, 0, 0], [0, 4, 0], [0, 8, 0]], warp = [[0, 16, 0], [0, 32, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1, 0], [0, 0, 1], [0, 0, 2], [0, 0, 64], [0, 0, 128]], lane = [[1, 0, 0], [2, 0, 0], [4, 0, 0], [8, 0, 0], [0, 0, 4], [0, 0, 8]], warp = [[0, 0, 16], [0, 0, 32]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 256], [0, 1], [0, 2], [0, 64], [0, 128]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [0, 4], [0, 8]], warp = [[0, 16], [0, 32]], block = []}>
#loc = loc(unknown)
#loc1 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":534:0)
#loc182 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":952:47)
#loc205 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":975:45)
#loc238 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1016:43)
#loc254 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1026:41)
#mma = #ttg.amd_mfma<{version = 3, warpsPerCTA = [1, 4], instrShape = [16, 16], isTransposed = true}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 8, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 16, order = [1, 0]}>
#shared2 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 16, order = [0, 1]}>
#shared3 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 8, order = [0, 1]}>
#smem = #ttg.shared_memory
#loc289 = loc("Q"(#loc1))
#loc290 = loc("K_Buffer"(#loc1))
#loc291 = loc("V_buffer"(#loc1))
#loc292 = loc("sm_scale"(#loc1))
#loc293 = loc("kv_indptr"(#loc1))
#loc294 = loc("kv_indices"(#loc1))
#loc295 = loc("Att_Out"(#loc1))
#loc296 = loc("Att_Lse"(#loc1))
#loc297 = loc("stride_qb"(#loc1))
#loc298 = loc("stride_qh"(#loc1))
#loc299 = loc("stride_buf_kbs"(#loc1))
#loc300 = loc("stride_buf_kh"(#loc1))
#loc301 = loc("stride_mid_ob"(#loc1))
#loc302 = loc("stride_mid_oh"(#loc1))
#loc303 = loc("stride_mid_os"(#loc1))
#loc304 = loc("stride_mid_lse_b"(#loc1))
#loc305 = loc("stride_mid_lse_h"(#loc1))
#loc306 = loc("stride_mid_lse_s"(#loc1))
#loc307 = loc("stride_b_block_table"(#loc1))
#loc458 = loc("n_e_max"(#loc182))
#loc475 = loc("e_sum"(#loc205))
#loc500 = loc("n_e_max"(#loc238))
#loc514 = loc("e_sum"(#loc254))
#loc554 = loc(callsite(#loc at #loc458))
#loc556 = loc(callsite(#loc at #loc475))
#loc558 = loc(callsite(#loc at #loc500))
#loc560 = loc(callsite(#loc at #loc514))
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx942", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_fwd_grouped_kernel_stage1_n16x2_prefetch_k_paged_64(%Q: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("Q"(#loc1)), %K_Buffer: !tt.ptr<bf16> {tt.divisibility = 16 : i32} loc("K_Buffer"(#loc1)), %V_buffer: !tt.ptr<bf16> {tt.divisibility = 16 : i32} loc("V_buffer"(#loc1)), %sm_scale: f32 {tt.divisibility = 16 : i32} loc("sm_scale"(#loc1)), %kv_indptr: !tt.ptr<i32> {tt.divisibility = 16 : i32} loc("kv_indptr"(#loc1)), %kv_indices: !tt.ptr<i32> {tt.divisibility = 16 : i32} loc("kv_indices"(#loc1)), %Att_Out: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("Att_Out"(#loc1)), %Att_Lse: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("Att_Lse"(#loc1)), %stride_qb: i32 {tt.divisibility = 16 : i32} loc("stride_qb"(#loc1)), %stride_qh: i32 {tt.divisibility = 16 : i32} loc("stride_qh"(#loc1)), %stride_buf_kbs: i32 {tt.divisibility = 16 : i32} loc("stride_buf_kbs"(#loc1)), %stride_buf_kh: i32 {tt.divisibility = 16 : i32} loc("stride_buf_kh"(#loc1)), %stride_mid_ob: i32 {tt.divisibility = 16 : i32} loc("stride_mid_ob"(#loc1)), %stride_mid_oh: i32 {tt.divisibility = 16 : i32} loc("stride_mid_oh"(#loc1)), %stride_mid_os: i32 {tt.divisibility = 16 : i32} loc("stride_mid_os"(#loc1)), %stride_mid_lse_b: i32 loc("stride_mid_lse_b"(#loc1)), %stride_mid_lse_h: i32 loc("stride_mid_lse_h"(#loc1)), %stride_mid_lse_s: i32 loc("stride_mid_lse_s"(#loc1)), %stride_b_block_table: i32 loc("stride_b_block_table"(#loc1))) attributes {noinline = false} {
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %c2_i32 = arith.constant 2 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c1_i32 = arith.constant 1 : i32 loc(#loc)
    %cst = arith.constant dense<8> : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc)
    %cst_0 = arith.constant dense<8> : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc)
    %cst_1 = arith.constant dense<512> : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %cst_2 = arith.constant dense<512> : tensor<256xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc)
    %cst_3 = arith.constant dense<576> : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc)
    %cst_4 = arith.constant dense<576> : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %false = arith.constant false loc(#loc)
    %true = arith.constant true loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %cst_5 = arith.constant dense<256> : tensor<32x256xi32, #blocked2> loc(#loc)
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_7 = arith.constant dense<1.44269502> : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_8 = arith.constant dense<1.44269502> : tensor<16x32xf32, #mma> loc(#loc)
    %cst_9 = arith.constant dense<0> : tensor<16x1xi32, #mma> loc(#loc)
    %cst_10 = arith.constant dense<0xFF800000> : tensor<16x32xf32, #mma> loc(#loc)
    %cst_11 = arith.constant dense<1.000000e+00> : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_12 = arith.constant dense<0xFF800000> : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %c-1_i32 = arith.constant -1 : i32 loc(#loc)
    %c7_i32 = arith.constant 7 : i32 loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %cst_13 = arith.constant dense<0.000000e+00> : tensor<16x256xf32, #mma> loc(#loc)
    %cst_14 = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #mma> loc(#loc)
    %cst_15 = arith.constant dense<8> : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %pid = tt.get_program_id x : i32 loc(#loc308)
    %pid_head_kv_split = arith.remsi %pid, %c8_i32 : i32 loc(#loc309)
    %xcd = arith.remsi %pid_head_kv_split, %c8_i32 : i32 loc(#loc538)
    %local_pid = arith.divsi %pid_head_kv_split, %c8_i32 : i32 loc(#loc539)
    %pid_head_kv_split_16 = arith.cmpi slt, %xcd, %c8_i32 : i32 loc(#loc540)
    %pid_head_kv_split_17 = scf.if %pid_head_kv_split_16 -> (i32) {
      %pid_145 = arith.addi %xcd, %local_pid : i32 loc(#loc561)
      scf.yield %pid_145 : i32 loc(#loc561)
    } else {
      %pid_145 = arith.addi %local_pid, %c8_i32 : i32 loc(#loc562)
      scf.yield %pid_145 : i32 loc(#loc544)
    } loc(#loc541)
    %split_kv_id = arith.remsi %pid_head_kv_split_17, %c8_i32 : i32 loc(#loc315)
    %cur_batch = arith.divsi %pid, %c8_i32 : i32 loc(#loc316)
    %cur_batch_18 = arith.remsi %cur_batch, %c256_i32 : i32 loc(#loc317)
    %cur_batch_kv_start_idx = tt.addptr %kv_indptr, %cur_batch_18 : !tt.ptr<i32>, i32 loc(#loc318)
    %cur_batch_kv_start_idx_19 = tt.load %cur_batch_kv_start_idx : !tt.ptr<i32> loc(#loc319)
    %cur_batch_kv_end_idx = tt.addptr %cur_batch_kv_start_idx, %c1_i32 : !tt.ptr<i32>, i32 loc(#loc320)
    %cur_batch_kv_end_idx_20 = tt.load %cur_batch_kv_end_idx : !tt.ptr<i32> loc(#loc321)
    %smem_q0_nope = ttg.local_alloc : () -> !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc322)
    %smem_q1_nope = ttg.local_alloc : () -> !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc323)
    %smem_q_rope = ttg.local_alloc : () -> !ttg.memdesc<16x64xbf16, #shared, #smem, mutable> loc(#loc324)
    %smem_p = ttg.local_alloc : () -> !ttg.memdesc<16x32xbf16, #shared1, #smem, mutable> loc(#loc325)
    %cur_head = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc326)
    %mask_h = arith.cmpi slt, %cur_head, %cst : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc327)
    %cur_N = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc328)
    %cur_N_pe = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc329)
    %cur_head_pe = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc330)
    %mask_h_pe = arith.cmpi slt, %cur_head_pe, %cst_0 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc331)
    %offs_c = tt.make_range {end = 512 : i32, start = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc332)
    %offs_om = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc333)
    %offs_qk_r = tt.make_range {end = 576 : i32, start = 512 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc334)
    %offs_k_c = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc335)
    %offs_k_r = tt.make_range {end = 576 : i32, start = 512 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc336)
    %cur_batch_seq_len = arith.subi %cur_batch_kv_end_idx_20, %cur_batch_kv_start_idx_19 : i32 loc(#loc337)
    %cur_batch_block_nums = arith.addi %cur_batch_seq_len, %c63_i32 : i32 loc(#loc545)
    %cur_batch_block_nums_21 = arith.divsi %cur_batch_block_nums, %c64_i32 : i32 loc(#loc546)
    %off_q_pe = arith.muli %cur_batch_18, %stride_qb : i32 loc(#loc339)
    %off_q_pe_22 = tt.expand_dims %cur_head_pe {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<16x1xi32, #blocked1> loc(#loc340)
    %off_q_pe_23 = tt.splat %stride_qh : i32 -> tensor<16x1xi32, #blocked1> loc(#loc341)
    %off_q_pe_24 = arith.muli %off_q_pe_22, %off_q_pe_23 : tensor<16x1xi32, #blocked1> loc(#loc341)
    %off_q_pe_25 = tt.splat %off_q_pe : i32 -> tensor<16x1xi32, #blocked1> loc(#loc342)
    %off_q_pe_26 = arith.addi %off_q_pe_25, %off_q_pe_24 : tensor<16x1xi32, #blocked1> loc(#loc342)
    %off_q_pe_27 = tt.expand_dims %offs_qk_r {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x64xi32, #blocked1> loc(#loc343)
    %off_q_pe_28 = tt.broadcast %off_q_pe_26 : tensor<16x1xi32, #blocked1> -> tensor<16x64xi32, #blocked1> loc(#loc344)
    %off_q_pe_29 = tt.broadcast %off_q_pe_27 : tensor<1x64xi32, #blocked1> -> tensor<16x64xi32, #blocked1> loc(#loc344)
    %off_q_pe_30 = arith.addi %off_q_pe_28, %off_q_pe_29 : tensor<16x64xi32, #blocked1> loc(#loc344)
    %offs_q = tt.expand_dims %cur_head {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc345)
    %offs_q_31 = tt.splat %stride_qh : i32 -> tensor<16x1xi32, #blocked> loc(#loc346)
    %offs_q_32 = arith.muli %offs_q, %offs_q_31 : tensor<16x1xi32, #blocked> loc(#loc346)
    %offs_q_33 = tt.splat %off_q_pe : i32 -> tensor<16x1xi32, #blocked> loc(#loc347)
    %offs_q_34 = arith.addi %offs_q_33, %offs_q_32 : tensor<16x1xi32, #blocked> loc(#loc347)
    %offs_q_35 = tt.expand_dims %offs_c {axis = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x512xi32, #blocked> loc(#loc348)
    %offs_q_36 = tt.broadcast %offs_q_34 : tensor<16x1xi32, #blocked> -> tensor<16x512xi32, #blocked> loc(#loc349)
    %offs_q_37 = tt.broadcast %offs_q_35 : tensor<1x512xi32, #blocked> -> tensor<16x512xi32, #blocked> loc(#loc349)
    %offs_q_38 = arith.addi %offs_q_36, %offs_q_37 : tensor<16x512xi32, #blocked> loc(#loc349)
    %mask_c = arith.cmpi slt, %offs_c, %cst_1 : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc350)
    %mask_k_c = arith.cmpi slt, %offs_k_c, %cst_2 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc351)
    %mask_qk_r = arith.cmpi slt, %offs_qk_r, %cst_3 : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc352)
    %mask_k_r = arith.cmpi slt, %offs_k_r, %cst_4 : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc353)
    %blocks_per_split = arith.addi %cur_batch_block_nums_21, %c7_i32 : i32 loc(#loc547)
    %blocks_per_split_39 = arith.divsi %blocks_per_split, %c8_i32 : i32 loc(#loc548)
    %split_kv_start = arith.muli %blocks_per_split_39, %split_kv_id : i32 loc(#loc355)
    %0 = arith.muli %split_kv_start, %c64_i32 : i32 loc(#loc54)
    %1 = arith.cmpi sgt, %0, %cur_batch_seq_len : i32 loc(#loc55)
    cf.cond_br %1, ^bb1, ^bb2 loc(#loc55)
  ^bb1:  // pred: ^bb0
    tt.return loc(#loc56)
  ^bb2:  // pred: ^bb0
    cf.br ^bb3 loc(#loc)
  ^bb3:  // pred: ^bb2
    %2 = arith.addi %split_kv_start, %blocks_per_split_39 : i32 loc(#loc57)
    %3 = arith.muli %2, %c64_i32 : i32 loc(#loc58)
    %4 = arith.cmpi sgt, %3, %cur_batch_seq_len : i32 loc(#loc59)
    %5 = scf.if %4 -> (i1) {
      scf.yield %true : i1 loc(#loc549)
    } else {
      scf.yield %false : i1 loc(#loc)
    } loc(#loc60)
    %split_kv_end = arith.minsi %2, %cur_batch_block_nums_21 : i32 loc(#loc357)
    %block_tail = arith.subi %cur_batch_seq_len, %c1_i32 : i32 loc(#loc358)
    %block_tail_40 = arith.remsi %block_tail, %c64_i32 : i32 loc(#loc359)
    %block_tail_41 = arith.divsi %block_tail_40, %c32_i32 : i32 loc(#loc360)
    %q = tt.expand_dims %mask_h {axis = 1 : i32} : tensor<16xi1, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi1, #blocked> loc(#loc361)
    %q_42 = tt.expand_dims %mask_c {axis = 0 : i32} : tensor<512xi1, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x512xi1, #blocked> loc(#loc362)
    %q_43 = tt.broadcast %q : tensor<16x1xi1, #blocked> -> tensor<16x512xi1, #blocked> loc(#loc363)
    %q_44 = tt.broadcast %q_42 : tensor<1x512xi1, #blocked> -> tensor<16x512xi1, #blocked> loc(#loc363)
    %q_45 = arith.andi %q_43, %q_44 : tensor<16x512xi1, #blocked> loc(#loc363)
    %q_46 = amdgpu.buffer_load %Q[%offs_q_38], %q_45 : tensor<16x512xbf16, #blocked> loc(#loc364)
    %q_pe = tt.expand_dims %mask_h_pe {axis = 1 : i32} : tensor<16xi1, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<16x1xi1, #blocked1> loc(#loc365)
    %q_pe_47 = tt.expand_dims %mask_qk_r {axis = 0 : i32} : tensor<64xi1, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x64xi1, #blocked1> loc(#loc366)
    %q_pe_48 = tt.broadcast %q_pe : tensor<16x1xi1, #blocked1> -> tensor<16x64xi1, #blocked1> loc(#loc367)
    %q_pe_49 = tt.broadcast %q_pe_47 : tensor<1x64xi1, #blocked1> -> tensor<16x64xi1, #blocked1> loc(#loc367)
    %q_pe_50 = arith.andi %q_pe_48, %q_pe_49 : tensor<16x64xi1, #blocked1> loc(#loc367)
    %q_pe_51 = amdgpu.buffer_load %Q[%off_q_pe_30], %q_pe_50 : tensor<16x64xbf16, #blocked1> loc(#loc368)
    %kv_loc = tt.addptr %kv_indices, %split_kv_start : !tt.ptr<i32>, i32 loc(#loc369)
    %kv_loc_52 = arith.muli %cur_batch_18, %stride_b_block_table : i32 loc(#loc370)
    %kv_loc_53 = tt.addptr %kv_loc, %kv_loc_52 : !tt.ptr<i32>, i32 loc(#loc371)
    %kv_loc_54 = tt.load %kv_loc_53 : !tt.ptr<i32> loc(#loc372)
    %q_55 = tt.reshape %q_46 : tensor<16x512xbf16, #blocked> -> tensor<16x2x256xbf16, #blocked4> loc(#loc373)
    %q_56 = tt.trans %q_55 {order = array<i32: 0, 2, 1>} : tensor<16x2x256xbf16, #blocked4> -> tensor<16x256x2xbf16, #blocked5> loc(#loc374)
    %outLHS, %outRHS = tt.split %q_56 : tensor<16x256x2xbf16, #blocked5> -> tensor<16x256xbf16, #ttg.slice<{dim = 2, parent = #blocked5}>> loc(#loc80)
    ttg.local_store %outLHS, %smem_q0_nope : tensor<16x256xbf16, #ttg.slice<{dim = 2, parent = #blocked5}>> -> !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc81)
    ttg.local_store %outRHS, %smem_q1_nope : tensor<16x256xbf16, #ttg.slice<{dim = 2, parent = #blocked5}>> -> !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc82)
    %q0 = ttg.local_load %smem_q0_nope : !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> -> tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc375)
    %q1 = ttg.local_load %smem_q1_nope : !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> -> tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc376)
    ttg.local_store %q_pe_51, %smem_q_rope : tensor<16x64xbf16, #blocked1> -> !ttg.memdesc<16x64xbf16, #shared, #smem, mutable> loc(#loc85)
    %q_pe_57 = ttg.local_load %smem_q_rope : !ttg.memdesc<16x64xbf16, #shared, #smem, mutable> -> tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc377)
    ttg.local_dealloc %smem_q0_nope : !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc87)
    ttg.local_dealloc %smem_q1_nope : !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc88)
    ttg.local_dealloc %smem_q_rope : !ttg.memdesc<16x64xbf16, #shared, #smem, mutable> loc(#loc89)
    %smem_k_rope = ttg.local_alloc : () -> !ttg.memdesc<64x32xbf16, #shared2, #smem, mutable> loc(#loc378)
    %k_id = arith.muli %kv_loc_54, %c64_i32 : i32 loc(#loc379)
    %k_id_58 = tt.splat %k_id : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc380)
    %k_id_59 = arith.addi %k_id_58, %cur_N : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc380)
    %mask_k_id = tt.splat %0 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc381)
    %mask_k_id_60 = arith.addi %mask_k_id, %cur_N : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc381)
    %mask_k = tt.splat %cur_batch_seq_len : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc382)
    %mask_k_61 = arith.cmpi slt, %mask_k_id_60, %mask_k : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc382)
    %offs_buf_kv = tt.expand_dims %k_id_59 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc383)
    %offs_buf_kv_62 = tt.splat %stride_buf_kh : i32 -> tensor<32x1xi32, #blocked2> loc(#loc384)
    %offs_buf_kv_63 = arith.muli %offs_buf_kv, %offs_buf_kv_62 : tensor<32x1xi32, #blocked2> loc(#loc384)
    %offs_buf_kv_64 = tt.expand_dims %offs_k_c {axis = 0 : i32} : tensor<256xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x256xi32, #blocked2> loc(#loc385)
    %offs_buf_kv_65 = tt.broadcast %offs_buf_kv_63 : tensor<32x1xi32, #blocked2> -> tensor<32x256xi32, #blocked2> loc(#loc386)
    %offs_buf_kv_66 = tt.broadcast %offs_buf_kv_64 : tensor<1x256xi32, #blocked2> -> tensor<32x256xi32, #blocked2> loc(#loc386)
    %offs_buf_kv_67 = arith.addi %offs_buf_kv_65, %offs_buf_kv_66 : tensor<32x256xi32, #blocked2> loc(#loc386)
    %kv1 = tt.expand_dims %mask_k_61 {axis = 1 : i32} : tensor<32xi1, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi1, #blocked2> loc(#loc387)
    %kv1_68 = tt.expand_dims %mask_k_c {axis = 0 : i32} : tensor<256xi1, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x256xi1, #blocked2> loc(#loc388)
    %kv1_69 = tt.broadcast %kv1 : tensor<32x1xi1, #blocked2> -> tensor<32x256xi1, #blocked2> loc(#loc389)
    %kv1_70 = tt.broadcast %kv1_68 : tensor<1x256xi1, #blocked2> -> tensor<32x256xi1, #blocked2> loc(#loc389)
    %kv1_71 = arith.andi %kv1_69, %kv1_70 : tensor<32x256xi1, #blocked2> loc(#loc389)
    %kv1_72 = amdgpu.buffer_load %K_Buffer[%offs_buf_kv_67], %kv1_71 : tensor<32x256xbf16, #blocked2> loc(#loc390)
    %kv2 = arith.addi %offs_buf_kv_67, %cst_5 : tensor<32x256xi32, #blocked2> loc(#loc391)
    %kv2_73 = amdgpu.buffer_load %K_Buffer[%kv2], %kv1_71 : tensor<32x256xbf16, #blocked2> loc(#loc392)
    %smem_kv1 = ttg.local_alloc : () -> !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> loc(#loc393)
    %smem_kv2 = ttg.local_alloc : () -> !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> loc(#loc394)
    rocdl.sched.barrier 0 loc(#loc107)
    %6 = tt.trans %kv1_72 {order = array<i32: 1, 0>} : tensor<32x256xbf16, #blocked2> -> tensor<256x32xbf16, #blocked6> loc(#loc108)
    ttg.local_store %6, %smem_kv1 : tensor<256x32xbf16, #blocked6> -> !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> loc(#loc108)
    %7 = tt.trans %kv2_73 {order = array<i32: 1, 0>} : tensor<32x256xbf16, #blocked2> -> tensor<256x32xbf16, #blocked6> loc(#loc109)
    ttg.local_store %7, %smem_kv2 : tensor<256x32xbf16, #blocked6> -> !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> loc(#loc109)
    %k_id_pe = tt.splat %k_id : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc395)
    %k_id_pe_74 = arith.addi %k_id_pe, %cur_N_pe : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc395)
    %offs_buf_k_pe = tt.expand_dims %k_id_pe_74 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc396)
    %offs_buf_k_pe_75 = tt.splat %stride_buf_kh : i32 -> tensor<32x1xi32, #blocked3> loc(#loc397)
    %offs_buf_k_pe_76 = arith.muli %offs_buf_k_pe, %offs_buf_k_pe_75 : tensor<32x1xi32, #blocked3> loc(#loc397)
    %offs_buf_k_pe_77 = tt.expand_dims %offs_k_r {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x64xi32, #blocked3> loc(#loc398)
    %offs_buf_k_pe_78 = tt.broadcast %offs_buf_k_pe_76 : tensor<32x1xi32, #blocked3> -> tensor<32x64xi32, #blocked3> loc(#loc399)
    %offs_buf_k_pe_79 = tt.broadcast %offs_buf_k_pe_77 : tensor<1x64xi32, #blocked3> -> tensor<32x64xi32, #blocked3> loc(#loc399)
    %offs_buf_k_pe_80 = arith.addi %offs_buf_k_pe_78, %offs_buf_k_pe_79 : tensor<32x64xi32, #blocked3> loc(#loc399)
    %mask_k_id_81 = tt.splat %0 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc400)
    %mask_k_id_82 = arith.addi %mask_k_id_81, %cur_N_pe : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc400)
    %mask_k_pe = tt.splat %cur_batch_seq_len : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc401)
    %mask_k_pe_83 = arith.cmpi slt, %mask_k_id_82, %mask_k_pe : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc401)
    %k_pe = tt.expand_dims %mask_k_pe_83 {axis = 1 : i32} : tensor<32xi1, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi1, #blocked3> loc(#loc402)
    %k_pe_84 = tt.expand_dims %mask_k_r {axis = 0 : i32} : tensor<64xi1, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x64xi1, #blocked3> loc(#loc403)
    %k_pe_85 = tt.broadcast %k_pe : tensor<32x1xi1, #blocked3> -> tensor<32x64xi1, #blocked3> loc(#loc404)
    %k_pe_86 = tt.broadcast %k_pe_84 : tensor<1x64xi1, #blocked3> -> tensor<32x64xi1, #blocked3> loc(#loc404)
    %k_pe_87 = arith.andi %k_pe_85, %k_pe_86 : tensor<32x64xi1, #blocked3> loc(#loc404)
    %k_pe_88 = amdgpu.buffer_load %K_Buffer[%offs_buf_k_pe_80], %k_pe_87 : tensor<32x64xbf16, #blocked3> loc(#loc405)
    %cur_k1 = ttg.local_load %smem_kv1 : !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> -> tensor<256x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc406)
    %cur_k2 = ttg.local_load %smem_kv2 : !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> -> tensor<256x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc407)
    %smem_kv1_89 = ttg.memdesc_reinterpret %smem_kv1 : !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> loc(#loc408)
    ttg.local_store %kv1_72, %smem_kv1_89 : tensor<32x256xbf16, #blocked2> -> !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> loc(#loc124)
    %smem_kv2_90 = ttg.memdesc_reinterpret %smem_kv2 : !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> loc(#loc409)
    ttg.local_store %kv2_73, %smem_kv2_90 : tensor<32x256xbf16, #blocked2> -> !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> loc(#loc126)
    %8 = tt.trans %k_pe_88 {order = array<i32: 1, 0>} : tensor<32x64xbf16, #blocked3> -> tensor<64x32xbf16, #blocked7> loc(#loc127)
    ttg.local_store %8, %smem_k_rope : tensor<64x32xbf16, #blocked7> -> !ttg.memdesc<64x32xbf16, #shared2, #smem, mutable> loc(#loc127)
    rocdl.sched.barrier 0 loc(#loc128)
    %loop_begin = arith.muli %split_kv_start, %c2_i32 : i32 loc(#loc410)
    %loop_begin_91 = arith.addi %loop_begin, %c1_i32 : i32 loc(#loc550)
    %loop_end = scf.if %5 -> (i32) {
      %loop_end_145 = arith.muli %split_kv_end, %c2_i32 : i32 loc(#loc414)
      %loop_end_146 = arith.addi %loop_end_145, %c-1_i32 : i32 loc(#loc551)
      %loop_end_147 = arith.addi %loop_end_146, %block_tail_41 : i32 loc(#loc416)
      scf.yield %loop_end_147 : i32 loc(#loc416)
    } else {
      %loop_end_145 = arith.muli %split_kv_end, %c2_i32 : i32 loc(#loc417)
      scf.yield %loop_end_145 : i32 loc(#loc417)
    } loc(#loc413)
    %kv2_transpose:8 = scf.for %kv2_transpose_145 = %loop_begin_91 to %loop_end step %c1_i32 iter_args(%arg20 = %cst_13, %arg21 = %cst_13, %smem_kv1_146 = %smem_kv1_89, %smem_kv2_147 = %smem_kv2_90, %arg24 = %cst_6, %arg25 = %cst_12, %cur_k1_148 = %cur_k1, %cur_k2_149 = %cur_k2) -> (tensor<16x256xf32, #mma>, tensor<16x256xf32, #mma>, !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable>, !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable>, tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<256x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>>, tensor<256x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>>)  : i32 {
      %start_n_block = arith.divsi %kv2_transpose_145, %c2_i32 : i32 loc(#loc419)
      %start_n_inner = arith.remsi %kv2_transpose_145, %c2_i32 : i32 loc(#loc420)
      %kv_loc_150 = tt.addptr %kv_indices, %start_n_block : !tt.ptr<i32>, i32 loc(#loc421)
      %kv_loc_151 = tt.addptr %kv_loc_150, %kv_loc_52 : !tt.ptr<i32>, i32 loc(#loc422)
      %kv_loc_152 = tt.load %kv_loc_151 : !tt.ptr<i32> loc(#loc423)
      %cur_k_pe_153 = ttg.local_load %smem_k_rope : !ttg.memdesc<64x32xbf16, #shared2, #smem, mutable> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc424)
      rocdl.sched.barrier 0 loc(#loc144)
      %k_id_154 = arith.muli %kv_loc_152, %c64_i32 : i32 loc(#loc425)
      %k_id_155 = tt.splat %k_id_154 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc426)
      %k_id_156 = arith.addi %k_id_155, %cur_N : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc426)
      %k_id_157 = arith.muli %start_n_inner, %c32_i32 : i32 loc(#loc427)
      %k_id_158 = tt.splat %k_id_157 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc428)
      %k_id_159 = arith.addi %k_id_156, %k_id_158 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc428)
      %offs_buf_kv_160 = tt.expand_dims %k_id_159 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc429)
      %offs_buf_kv_161 = arith.muli %offs_buf_kv_160, %offs_buf_kv_62 : tensor<32x1xi32, #blocked2> loc(#loc430)
      %offs_buf_kv_162 = tt.broadcast %offs_buf_kv_161 : tensor<32x1xi32, #blocked2> -> tensor<32x256xi32, #blocked2> loc(#loc431)
      %offs_buf_kv_163 = arith.addi %offs_buf_kv_162, %offs_buf_kv_66 : tensor<32x256xi32, #blocked2> loc(#loc431)
      %mask_k_id_164 = arith.muli %start_n_block, %c64_i32 : i32 loc(#loc432)
      %mask_k_id_165 = tt.splat %mask_k_id_164 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc433)
      %mask_k_id_166 = arith.addi %mask_k_id_165, %cur_N : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc433)
      %mask_k_id_167 = arith.addi %mask_k_id_166, %k_id_158 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc434)
      %mask_k_168 = arith.cmpi slt, %mask_k_id_167, %mask_k : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc435)
      rocdl.sched.barrier 0 loc(#loc156)
      %qk_169 = tt.dot %q0, %cur_k1_148, %cst_14 : tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<256x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x32xf32, #mma> loc(#loc436)
      %kv1_170 = tt.expand_dims %mask_k_168 {axis = 1 : i32} : tensor<32xi1, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi1, #blocked2> loc(#loc437)
      %kv1_171 = tt.broadcast %kv1_170 : tensor<32x1xi1, #blocked2> -> tensor<32x256xi1, #blocked2> loc(#loc438)
      %kv1_172 = arith.andi %kv1_171, %kv1_70 : tensor<32x256xi1, #blocked2> loc(#loc438)
      %kv1_173 = amdgpu.buffer_load %K_Buffer[%offs_buf_kv_163], %kv1_172 : tensor<32x256xbf16, #blocked2> loc(#loc439)
      rocdl.sched.barrier 0 loc(#loc161)
      %qk_174 = tt.dot %q1, %cur_k2_149, %qk_169 : tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<256x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x32xf32, #mma> loc(#loc440)
      %kv2_175 = arith.addi %offs_buf_kv_163, %cst_5 : tensor<32x256xi32, #blocked2> loc(#loc441)
      %kv2_176 = amdgpu.buffer_load %K_Buffer[%kv2_175], %kv1_172 : tensor<32x256xbf16, #blocked2> loc(#loc442)
      %cur_k1_177 = ttg.local_load %smem_kv1_146 : !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> -> tensor<32x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc443)
      %cur_k2_178 = ttg.local_load %smem_kv2_147 : !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> -> tensor<32x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc444)
      %qk_179 = tt.dot %q_pe_57, %cur_k_pe_153, %qk_174 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x32xf32, #mma> loc(#loc445)
      %qk_180 = tt.splat %sm_scale : f32 -> tensor<16x32xf32, #mma> loc(#loc446)
      %qk_181 = arith.mulf %qk_179, %qk_180 : tensor<16x32xf32, #mma> loc(#loc446)
      %k_id_pe_182 = tt.splat %k_id_154 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc447)
      %k_id_pe_183 = arith.addi %k_id_pe_182, %cur_N_pe : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc447)
      %k_id_pe_184 = tt.splat %k_id_157 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc448)
      %k_id_pe_185 = arith.addi %k_id_pe_183, %k_id_pe_184 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc448)
      %offs_buf_k_pe_186 = tt.expand_dims %k_id_pe_185 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc449)
      %offs_buf_k_pe_187 = arith.muli %offs_buf_k_pe_186, %offs_buf_k_pe_75 : tensor<32x1xi32, #blocked3> loc(#loc450)
      %offs_buf_k_pe_188 = tt.broadcast %offs_buf_k_pe_187 : tensor<32x1xi32, #blocked3> -> tensor<32x64xi32, #blocked3> loc(#loc451)
      %offs_buf_k_pe_189 = arith.addi %offs_buf_k_pe_188, %offs_buf_k_pe_79 : tensor<32x64xi32, #blocked3> loc(#loc451)
      %mask_k_id_190 = tt.splat %mask_k_id_164 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc452)
      %mask_k_id_191 = arith.addi %mask_k_id_190, %cur_N_pe : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc452)
      %mask_k_id_192 = arith.addi %mask_k_id_191, %k_id_pe_184 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc453)
      %mask_k_pe_193 = arith.cmpi slt, %mask_k_id_192, %mask_k_pe : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc454)
      rocdl.sched.barrier 0 loc(#loc177)
      %k_pe_194 = tt.expand_dims %mask_k_pe_193 {axis = 1 : i32} : tensor<32xi1, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi1, #blocked3> loc(#loc455)
      %k_pe_195 = tt.broadcast %k_pe_194 : tensor<32x1xi1, #blocked3> -> tensor<32x64xi1, #blocked3> loc(#loc456)
      %k_pe_196 = arith.andi %k_pe_195, %k_pe_86 : tensor<32x64xi1, #blocked3> loc(#loc456)
      %k_pe_197 = amdgpu.buffer_load %K_Buffer[%offs_buf_k_pe_189], %k_pe_196 : tensor<32x64xbf16, #blocked3> loc(#loc457)
      %n_e_max_198 = "tt.reduce"(%qk_181) <{axis = 1 : i32}> ({
      ^bb0(%n_e_max_225: f32 loc(callsite(#loc at #loc458)), %n_e_max_226: f32 loc(callsite(#loc at #loc458))):
        %n_e_max_227 = arith.maxnumf %n_e_max_225, %n_e_max_226 : f32 loc(#loc564)
        tt.reduce.return %n_e_max_227 : f32 loc(#loc553)
      }) : (tensor<16x32xf32, #mma>) -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc553)
      %n_e_max_199 = ttg.convert_layout %n_e_max_198 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc459)
      %n_e_max_200 = arith.maxnumf %n_e_max_199, %arg25 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc460)
      %re_scale_201 = arith.subf %arg25, %n_e_max_200 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc461)
      %re_scale_202 = arith.mulf %re_scale_201, %cst_7 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc462)
      %re_scale_203 = math.exp2 %re_scale_202 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc463)
      %p_204 = tt.expand_dims %n_e_max_200 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc464)
      %p_205 = tt.broadcast %p_204 : tensor<16x1xf32, #mma> -> tensor<16x32xf32, #mma> loc(#loc465)
      %p_206 = arith.subf %qk_181, %p_205 : tensor<16x32xf32, #mma> loc(#loc465)
      %p_207 = arith.mulf %p_206, %cst_8 : tensor<16x32xf32, #mma> loc(#loc466)
      %p_208 = math.exp2 %p_207 : tensor<16x32xf32, #mma> loc(#loc467)
      %15 = arith.truncf %p_208 : tensor<16x32xf32, #mma> to tensor<16x32xbf16, #mma> loc(#loc193)
      ttg.local_store %15, %smem_p : tensor<16x32xbf16, #mma> -> !ttg.memdesc<16x32xbf16, #shared1, #smem, mutable> loc(#loc194)
      rocdl.sched.barrier 0 loc(#loc195)
      %cur_p_209 = ttg.local_load %smem_p : !ttg.memdesc<16x32xbf16, #shared1, #smem, mutable> -> tensor<16x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> loc(#loc468)
      %smem_kv1_210 = ttg.memdesc_reinterpret %smem_kv1_146 : !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> -> !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> loc(#loc469)
      %smem_kv2_211 = ttg.memdesc_reinterpret %smem_kv2_147 : !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> -> !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> loc(#loc470)
      %16 = tt.trans %kv1_173 {order = array<i32: 1, 0>} : tensor<32x256xbf16, #blocked2> -> tensor<256x32xbf16, #blocked6> loc(#loc199)
      ttg.local_store %16, %smem_kv1_210 : tensor<256x32xbf16, #blocked6> -> !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> loc(#loc199)
      %acc1_212 = tt.expand_dims %re_scale_203 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc471)
      %acc1_213 = tt.broadcast %acc1_212 : tensor<16x1xf32, #mma> -> tensor<16x256xf32, #mma> loc(#loc472)
      %acc1_214 = arith.mulf %arg20, %acc1_213 : tensor<16x256xf32, #mma> loc(#loc472)
      %acc1_215 = tt.dot %cur_p_209, %cur_k1_177, %acc1_214 : tensor<16x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<32x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<16x256xf32, #mma> loc(#loc473)
      %e_sum_216 = arith.mulf %arg24, %re_scale_203 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc474)
      %e_sum_217 = "tt.reduce"(%p_208) <{axis = 1 : i32}> ({
      ^bb0(%e_sum_225: f32 loc(callsite(#loc at #loc475)), %e_sum_226: f32 loc(callsite(#loc at #loc475))):
        %e_sum_227 = arith.addf %e_sum_225, %e_sum_226 : f32 loc(#loc565)
        tt.reduce.return %e_sum_227 : f32 loc(#loc555)
      }) : (tensor<16x32xf32, #mma>) -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc555)
      %e_sum_218 = arith.addf %e_sum_216, %e_sum_217 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc476)
      %17 = tt.trans %kv2_176 {order = array<i32: 1, 0>} : tensor<32x256xbf16, #blocked2> -> tensor<256x32xbf16, #blocked6> loc(#loc208)
      ttg.local_store %17, %smem_kv2_211 : tensor<256x32xbf16, #blocked6> -> !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> loc(#loc208)
      %acc2_219 = arith.mulf %arg21, %acc1_213 : tensor<16x256xf32, #mma> loc(#loc477)
      %acc2_220 = tt.dot %cur_p_209, %cur_k2_178, %acc2_219 : tensor<16x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<32x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<16x256xf32, #mma> loc(#loc478)
      %18 = tt.trans %k_pe_197 {order = array<i32: 1, 0>} : tensor<32x64xbf16, #blocked3> -> tensor<64x32xbf16, #blocked7> loc(#loc211)
      ttg.local_store %18, %smem_k_rope : tensor<64x32xbf16, #blocked7> -> !ttg.memdesc<64x32xbf16, #shared2, #smem, mutable> loc(#loc211)
      %cur_k1_221 = ttg.local_load %smem_kv1_210 : !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> -> tensor<256x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc479)
      rocdl.sched.barrier 0 loc(#loc213)
      %smem_kv1_222 = ttg.memdesc_reinterpret %smem_kv1_210 : !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> loc(#loc480)
      ttg.local_store %kv1_173, %smem_kv1_222 : tensor<32x256xbf16, #blocked2> -> !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> loc(#loc215)
      %cur_k2_223 = ttg.local_load %smem_kv2_211 : !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> -> tensor<256x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc481)
      rocdl.sched.barrier 0 loc(#loc217)
      %smem_kv2_224 = ttg.memdesc_reinterpret %smem_kv2_211 : !ttg.memdesc<256x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> loc(#loc482)
      ttg.local_store %kv2_176, %smem_kv2_224 : tensor<32x256xbf16, #blocked2> -> !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> loc(#loc219)
      scf.yield %acc1_215, %acc2_220, %smem_kv1_222, %smem_kv2_224, %e_sum_218, %n_e_max_200, %cur_k1_221, %cur_k2_223 : tensor<16x256xf32, #mma>, tensor<16x256xf32, #mma>, !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable>, !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable>, tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<256x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>>, tensor<256x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc220)
    } loc(#loc585)
    %qk = tt.dot %q0, %kv2_transpose#6, %cst_14 : tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<256x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x32xf32, #mma> loc(#loc483)
    %qk_92 = tt.dot %q1, %kv2_transpose#7, %qk : tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<256x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x32xf32, #mma> loc(#loc484)
    %cur_k_pe = ttg.local_load %smem_k_rope : !ttg.memdesc<64x32xbf16, #shared2, #smem, mutable> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc485)
    %qk_93 = tt.dot %q_pe_57, %cur_k_pe, %qk_92 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x32xf32, #mma> loc(#loc486)
    %cur_k1_94 = ttg.local_load %kv2_transpose#2 : !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> -> tensor<32x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc487)
    %cur_k2_95 = ttg.local_load %kv2_transpose#3 : !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> -> tensor<32x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc488)
    %qk_96 = tt.splat %sm_scale : f32 -> tensor<16x32xf32, #mma> loc(#loc489)
    %qk_97 = arith.mulf %qk_93, %qk_96 : tensor<16x32xf32, #mma> loc(#loc489)
    %mask_qk_n = arith.subi %split_kv_end, %c1_i32 : i32 loc(#loc490)
    %mask_qk_n_98 = arith.muli %mask_qk_n, %c64_i32 : i32 loc(#loc491)
    %mask_qk_n_99 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc492)
    %mask_qk_n_100 = tt.splat %mask_qk_n_98 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc493)
    %mask_qk_n_101 = arith.addi %mask_qk_n_100, %mask_qk_n_99 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc493)
    %qk_102 = tt.expand_dims %mask_qk_n_101 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x32xi32, #mma> loc(#loc494)
    %qk_103 = tt.splat %cur_batch_seq_len : i32 -> tensor<1x32xi32, #mma> loc(#loc495)
    %qk_104 = arith.cmpi slt, %qk_102, %qk_103 : tensor<1x32xi32, #mma> loc(#loc495)
    %qk_105 = tt.expand_dims %offs_om {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xi32, #mma> loc(#loc496)
    %qk_106 = arith.cmpi sge, %qk_105, %cst_9 : tensor<16x1xi32, #mma> loc(#loc497)
    %qk_107 = tt.broadcast %qk_104 : tensor<1x32xi1, #mma> -> tensor<16x32xi1, #mma> loc(#loc498)
    %qk_108 = tt.broadcast %qk_106 : tensor<16x1xi1, #mma> -> tensor<16x32xi1, #mma> loc(#loc498)
    %qk_109 = arith.andi %qk_107, %qk_108 : tensor<16x32xi1, #mma> loc(#loc498)
    %qk_110 = arith.select %qk_109, %qk_97, %cst_10 : tensor<16x32xi1, #mma>, tensor<16x32xf32, #mma> loc(#loc499)
    %n_e_max = "tt.reduce"(%qk_110) <{axis = 1 : i32}> ({
    ^bb0(%n_e_max_145: f32 loc(callsite(#loc at #loc500)), %n_e_max_146: f32 loc(callsite(#loc at #loc500))):
      %n_e_max_147 = arith.maxnumf %n_e_max_145, %n_e_max_146 : f32 loc(#loc566)
      tt.reduce.return %n_e_max_147 : f32 loc(#loc557)
    }) : (tensor<16x32xf32, #mma>) -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc557)
    %n_e_max_111 = ttg.convert_layout %n_e_max : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc501)
    %n_e_max_112 = arith.maxnumf %n_e_max_111, %kv2_transpose#5 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc502)
    %re_scale = arith.subf %kv2_transpose#5, %n_e_max_112 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc503)
    %re_scale_113 = arith.mulf %re_scale, %cst_7 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc504)
    %re_scale_114 = math.exp2 %re_scale_113 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc505)
    %p = tt.expand_dims %n_e_max_112 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc506)
    %p_115 = tt.broadcast %p : tensor<16x1xf32, #mma> -> tensor<16x32xf32, #mma> loc(#loc507)
    %p_116 = arith.subf %qk_110, %p_115 : tensor<16x32xf32, #mma> loc(#loc507)
    %p_117 = arith.mulf %p_116, %cst_8 : tensor<16x32xf32, #mma> loc(#loc508)
    %p_118 = math.exp2 %p_117 : tensor<16x32xf32, #mma> loc(#loc509)
    %9 = arith.truncf %p_118 : tensor<16x32xf32, #mma> to tensor<16x32xbf16, #mma> loc(#loc248)
    ttg.local_store %9, %smem_p : tensor<16x32xbf16, #mma> -> !ttg.memdesc<16x32xbf16, #shared1, #smem, mutable> loc(#loc249)
    %acc1 = tt.expand_dims %re_scale_114 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc510)
    %acc1_119 = tt.broadcast %acc1 : tensor<16x1xf32, #mma> -> tensor<16x256xf32, #mma> loc(#loc511)
    %acc1_120 = arith.mulf %kv2_transpose#0, %acc1_119 : tensor<16x256xf32, #mma> loc(#loc511)
    %acc2 = arith.mulf %kv2_transpose#1, %acc1_119 : tensor<16x256xf32, #mma> loc(#loc512)
    %e_sum = arith.mulf %kv2_transpose#4, %re_scale_114 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc513)
    %e_sum_121 = "tt.reduce"(%p_118) <{axis = 1 : i32}> ({
    ^bb0(%e_sum_145: f32 loc(callsite(#loc at #loc514)), %e_sum_146: f32 loc(callsite(#loc at #loc514))):
      %e_sum_147 = arith.addf %e_sum_145, %e_sum_146 : f32 loc(#loc567)
      tt.reduce.return %e_sum_147 : f32 loc(#loc559)
    }) : (tensor<16x32xf32, #mma>) -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc559)
    %e_sum_122 = arith.addf %e_sum, %e_sum_121 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc515)
    rocdl.sched.barrier 0 loc(#loc256)
    %cur_p = ttg.local_load %smem_p : !ttg.memdesc<16x32xbf16, #shared1, #smem, mutable> -> tensor<16x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> loc(#loc516)
    %acc1_123 = tt.dot %cur_p, %cur_k1_94, %acc1_120 : tensor<16x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<32x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<16x256xf32, #mma> loc(#loc517)
    %acc2_124 = tt.dot %cur_p, %cur_k2_95, %acc2 : tensor<16x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<32x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<16x256xf32, #mma> loc(#loc518)
    ttg.local_dealloc %kv2_transpose#2 : !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> loc(#loc260)
    ttg.local_dealloc %kv2_transpose#3 : !ttg.memdesc<32x256xbf16, #shared3, #smem, mutable> loc(#loc261)
    %acc = tt.join %acc1_123, %acc2_124 : tensor<16x256xf32, #mma> -> tensor<16x256x2xf32, #linear> loc(#loc519)
    %acc_125 = tt.trans %acc {order = array<i32: 0, 2, 1>} : tensor<16x256x2xf32, #linear> -> tensor<16x2x256xf32, #linear1> loc(#loc520)
    %acc_126 = tt.reshape %acc_125 : tensor<16x2x256xf32, #linear1> -> tensor<16x512xf32, #linear2> loc(#loc521)
    %acc_127 = ttg.convert_layout %acc_126 : tensor<16x512xf32, #linear2> -> tensor<16x512xf32, #mma> loc(#loc522)
    %smem_o = ttg.local_alloc : () -> !ttg.memdesc<16x512xf32, #shared, #smem, mutable> loc(#loc523)
    %e_sum_128 = arith.divf %cst_11, %e_sum_122 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc524)
    %10 = tt.expand_dims %e_sum_128 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc268)
    %11 = tt.broadcast %10 : tensor<16x1xf32, #mma> -> tensor<16x512xf32, #mma> loc(#loc269)
    %12 = arith.mulf %acc_127, %11 : tensor<16x512xf32, #mma> loc(#loc269)
    ttg.local_store %12, %smem_o : tensor<16x512xf32, #mma> -> !ttg.memdesc<16x512xf32, #shared, #smem, mutable> loc(#loc270)
    %cur_o = ttg.local_load %smem_o : !ttg.memdesc<16x512xf32, #shared, #smem, mutable> -> tensor<16x512xf32, #blocked> loc(#loc525)
    %offs_mid_o = arith.muli %cur_batch_18, %stride_mid_ob : i32 loc(#loc526)
    %offs_mid_o_129 = tt.splat %stride_mid_oh : i32 -> tensor<16x1xi32, #blocked> loc(#loc527)
    %offs_mid_o_130 = arith.muli %offs_q, %offs_mid_o_129 : tensor<16x1xi32, #blocked> loc(#loc527)
    %offs_mid_o_131 = tt.splat %offs_mid_o : i32 -> tensor<16x1xi32, #blocked> loc(#loc528)
    %offs_mid_o_132 = arith.addi %offs_mid_o_131, %offs_mid_o_130 : tensor<16x1xi32, #blocked> loc(#loc528)
    %offs_mid_o_133 = arith.muli %split_kv_id, %stride_mid_os : i32 loc(#loc529)
    %offs_mid_o_134 = tt.splat %offs_mid_o_133 : i32 -> tensor<16x1xi32, #blocked> loc(#loc530)
    %offs_mid_o_135 = arith.addi %offs_mid_o_132, %offs_mid_o_134 : tensor<16x1xi32, #blocked> loc(#loc530)
    %offs_mid_o_136 = tt.broadcast %offs_mid_o_135 : tensor<16x1xi32, #blocked> -> tensor<16x512xi32, #blocked> loc(#loc531)
    %offs_mid_o_137 = arith.addi %offs_mid_o_136, %offs_q_37 : tensor<16x512xi32, #blocked> loc(#loc531)
    amdgpu.buffer_store %cur_o, %Att_Out[%offs_mid_o_137], %q_45 : tensor<16x512xf32, #blocked> loc(#loc278)
    %offs_mid_lse = arith.muli %cur_batch_18, %stride_mid_lse_b : i32 loc(#loc532)
    %offs_mid_lse_138 = tt.splat %stride_mid_lse_h : i32 -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc533)
    %offs_mid_lse_139 = arith.muli %offs_om, %offs_mid_lse_138 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc533)
    %offs_mid_lse_140 = tt.splat %offs_mid_lse : i32 -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc534)
    %offs_mid_lse_141 = arith.addi %offs_mid_lse_140, %offs_mid_lse_139 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc534)
    %offs_mid_lse_142 = arith.muli %split_kv_id, %stride_mid_lse_s : i32 loc(#loc535)
    %offs_mid_lse_143 = tt.splat %offs_mid_lse_142 : i32 -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc536)
    %offs_mid_lse_144 = arith.addi %offs_mid_lse_141, %offs_mid_lse_143 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc536)
    %mask_lse = arith.cmpi slt, %offs_om, %cst_15 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc537)
    %13 = math.log %e_sum_128 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc285)
    %14 = arith.subf %n_e_max_112, %13 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc286)
    amdgpu.buffer_store %14, %Att_Lse[%offs_mid_lse_144], %mask_lse : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc287)
    tt.return loc(#loc288)
  } loc(#loc1)
} loc(#loc)
#loc2 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":568:24)
#loc3 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":571:31)
#loc4 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":39:16)
#loc5 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":572:54)
#loc6 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":40:23)
#loc7 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":45:13)
#loc8 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":45:7)
#loc9 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":46:35)
#loc10 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":51:14)
#loc11 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":575:58)
#loc12 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":580:25)
#loc13 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":580:60)
#loc14 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":583:49)
#loc15 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":583:37)
#loc16 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":584:62)
#loc17 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":584:35)
#loc18 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":630:27)
#loc19 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":633:27)
#loc20 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":636:27)
#loc21 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":640:27)
#loc22 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":670:11)
#loc23 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":672:24)
#loc24 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":676:11)
#loc25 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":680:11)
#loc26 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":684:11)
#loc27 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":686:30)
#loc28 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":690:11)
#loc29 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":694:11)
#loc30 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":705:8)
#loc31 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":713:11)
#loc32 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":717:8)
#loc33 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":721:47)
#loc34 = loc("/workspace/triton/python/triton/language/standard.py":41:22)
#loc35 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":722:54)
#loc36 = loc("/workspace/triton/python/triton/language/standard.py":41:28)
#loc37 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":725:20)
#loc38 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":725:44)
#loc39 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":725:55)
#loc40 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":725:32)
#loc41 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":725:77)
#loc42 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":725:67)
#loc43 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":727:46)
#loc44 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":727:57)
#loc45 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":727:37)
#loc46 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":727:76)
#loc47 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":727:69)
#loc48 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":729:22)
#loc49 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":730:26)
#loc50 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":731:29)
#loc51 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":732:27)
#loc52 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":734:53)
#loc53 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":735:40)
#loc54 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":741:24)
#loc55 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":741:42)
#loc56 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":742:8)
#loc57 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":745:25)
#loc58 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":745:45)
#loc59 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":745:63)
#loc60 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":745:7)
#loc61 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":746:21)
#loc62 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":748:65)
#loc63 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":750:38)
#loc64 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":750:43)
#loc65 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":750:62)
#loc66 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":755:21)
#loc67 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":755:41)
#loc68 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":755:34)
#loc69 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":755:8)
#loc70 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":760:24)
#loc71 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":760:47)
#loc72 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":760:37)
#loc73 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":760:8)
#loc74 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":763:21)
#loc75 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":763:50)
#loc76 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":763:38)
#loc77 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":763:8)
#loc78 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":769:22)
#loc79 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":770:22)
#loc80 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":771:22)
#loc81 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":773:23)
#loc82 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":774:23)
#loc83 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":775:27)
#loc84 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":776:27)
#loc85 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":778:22)
#loc86 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":779:28)
#loc87 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":781:4)
#loc88 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":782:4)
#loc89 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":783:4)
#loc90 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":789:34)
#loc91 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":802:20)
#loc92 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":802:38)
#loc93 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":803:51)
#loc94 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":804:25)
#loc95 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":805:23)
#loc96 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":805:34)
#loc97 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":805:59)
#loc98 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":805:50)
#loc99 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":813:20)
#loc100 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":813:40)
#loc101 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":813:31)
#loc102 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":813:8)
#loc103 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":818:30)
#loc104 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":819:8)
#loc105 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":826:34)
#loc106 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":829:34)
#loc107 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":832:31)
#loc108 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":834:19)
#loc109 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":835:19)
#loc110 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":837:41)
#loc111 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":838:28)
#loc112 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":838:39)
#loc113 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":838:64)
#loc114 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":838:55)
#loc115 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":839:51)
#loc116 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":840:28)
#loc117 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":848:23)
#loc118 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":848:43)
#loc119 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":848:34)
#loc120 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":848:8)
#loc121 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":861:27)
#loc122 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":862:27)
#loc123 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":865:34)
#loc124 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":868:19)
#loc125 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":870:34)
#loc126 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":873:19)
#loc127 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":875:22)
#loc128 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":876:31)
#loc129 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":880:42)
#loc130 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":880:84)
#loc131 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":578:29)
#loc132 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":881:98)
#loc133 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":881:40)
#loc134 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":881:80)
#loc135 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":881:84)
#loc136 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":881:139)
#loc137 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":887:37)
#loc138 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":888:35)
#loc139 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":889:34)
#loc140 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":896:25)
#loc141 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":896:41)
#loc142 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":896:12)
#loc143 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":899:36)
#loc144 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":901:35)
#loc145 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":902:24)
#loc146 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":902:42)
#loc147 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":902:66)
#loc148 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":902:50)
#loc149 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":903:27)
#loc150 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":903:38)
#loc151 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":903:54)
#loc152 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":904:36)
#loc153 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":904:54)
#loc154 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":904:62)
#loc155 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":905:29)
#loc156 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":906:35)
#loc157 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":911:43)
#loc158 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":915:24)
#loc159 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":915:35)
#loc160 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":915:12)
#loc161 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":918:35)
#loc162 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":920:43)
#loc163 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":923:34)
#loc164 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":924:12)
#loc165 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":930:31)
#loc166 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":931:31)
#loc167 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":933:47)
#loc168 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":935:14)
#loc169 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":937:45)
#loc170 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":937:56)
#loc171 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":938:32)
#loc172 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":938:43)
#loc173 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":938:59)
#loc174 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":939:54)
#loc175 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":939:65)
#loc176 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":940:32)
#loc177 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":942:35)
#loc178 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":946:27)
#loc179 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":946:38)
#loc180 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":946:12)
#loc181 = loc("/workspace/triton/python/triton/language/standard.py":189:40)
#loc183 = loc("/workspace/triton/python/triton/language/standard.py":168:27)
#loc184 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":952:51)
#loc185 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":953:38)
#loc186 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":957:41)
#loc187 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":957:52)
#loc188 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":957:32)
#loc189 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":958:39)
#loc190 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":958:31)
#loc191 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":958:51)
#loc192 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":958:25)
#loc193 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":959:26)
#loc194 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":959:21)
#loc195 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":960:35)
#loc196 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":962:28)
#loc197 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":964:38)
#loc198 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":966:38)
#loc199 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":968:23)
#loc200 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":969:31)
#loc201 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":969:22)
#loc202 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":974:48)
#loc203 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":975:24)
#loc204 = loc("/workspace/triton/python/triton/language/standard.py":291:36)
#loc206 = loc("/workspace/triton/python/triton/language/standard.py":261:15)
#loc207 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":975:35)
#loc208 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":977:23)
#loc209 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":978:22)
#loc210 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":979:48)
#loc211 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":980:26)
#loc212 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":983:31)
#loc213 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":985:35)
#loc214 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":987:38)
#loc215 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":989:23)
#loc216 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":990:31)
#loc217 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":993:35)
#loc218 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":995:38)
#loc219 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":996:23)
#loc220 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":996:8)
#loc221 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":998:39)
#loc222 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":999:39)
#loc223 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1001:32)
#loc224 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1003:43)
#loc225 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1005:27)
#loc226 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1006:27)
#loc227 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1008:10)
#loc228 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1010:32)
#loc229 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1010:37)
#loc230 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1010:77)
#loc231 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1010:55)
#loc232 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1013:19)
#loc233 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1013:30)
#loc234 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1013:62)
#loc235 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1013:74)
#loc236 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1013:52)
#loc237 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1013:82)
#loc239 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1016:47)
#loc240 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1018:34)
#loc241 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1019:37)
#loc242 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1019:48)
#loc243 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1019:28)
#loc244 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1020:35)
#loc245 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1020:27)
#loc246 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1020:47)
#loc247 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1020:21)
#loc248 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1022:22)
#loc249 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1022:17)
#loc250 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1024:27)
#loc251 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1024:18)
#loc252 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1025:18)
#loc253 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1026:20)
#loc255 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1026:31)
#loc256 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1027:31)
#loc257 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1028:24)
#loc258 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1031:44)
#loc259 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1034:44)
#loc260 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1036:4)
#loc261 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1037:4)
#loc262 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1039:24)
#loc263 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1040:27)
#loc264 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1041:26)
#loc265 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1042:33)
#loc266 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1045:33)
#loc267 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1048:16)
#loc268 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1049:29)
#loc269 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1049:23)
#loc270 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1049:17)
#loc271 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1051:24)
#loc272 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1054:20)
#loc273 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1055:30)
#loc274 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1055:10)
#loc275 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1056:24)
#loc276 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1056:10)
#loc277 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1057:10)
#loc278 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1070:8)
#loc279 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1074:20)
#loc280 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1075:20)
#loc281 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1075:10)
#loc282 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1076:24)
#loc283 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1076:10)
#loc284 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1079:25)
#loc285 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1081:36)
#loc286 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1081:29)
#loc287 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1085:8)
#loc288 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode.py":1080:4)
#loc308 = loc("pid"(#loc2))
#loc309 = loc("pid_head_kv_split"(#loc3))
#loc310 = loc("xcd"(#loc4))
#loc311 = loc("pid_head_kv_split"(#loc5))
#loc312 = loc("local_pid"(#loc6))
#loc313 = loc("pid"(#loc9))
#loc314 = loc("pid"(#loc10))
#loc315 = loc("split_kv_id"(#loc11))
#loc316 = loc("cur_batch"(#loc12))
#loc317 = loc("cur_batch"(#loc13))
#loc318 = loc("cur_batch_kv_start_idx"(#loc14))
#loc319 = loc("cur_batch_kv_start_idx"(#loc15))
#loc320 = loc("cur_batch_kv_end_idx"(#loc16))
#loc321 = loc("cur_batch_kv_end_idx"(#loc17))
#loc322 = loc("smem_q0_nope"(#loc18))
#loc323 = loc("smem_q1_nope"(#loc19))
#loc324 = loc("smem_q_rope"(#loc20))
#loc325 = loc("smem_p"(#loc21))
#loc326 = loc("cur_head"(#loc22))
#loc327 = loc("mask_h"(#loc23))
#loc328 = loc("cur_N"(#loc24))
#loc329 = loc("cur_N_pe"(#loc25))
#loc330 = loc("cur_head_pe"(#loc26))
#loc331 = loc("mask_h_pe"(#loc27))
#loc332 = loc("offs_c"(#loc28))
#loc333 = loc("offs_om"(#loc29))
#loc334 = loc("offs_qk_r"(#loc30))
#loc335 = loc("offs_k_c"(#loc31))
#loc336 = loc("offs_k_r"(#loc32))
#loc337 = loc("cur_batch_seq_len"(#loc33))
#loc338 = loc("cur_batch_block_nums"(#loc35))
#loc339 = loc("off_q_pe"(#loc37))
#loc340 = loc("off_q_pe"(#loc38))
#loc341 = loc("off_q_pe"(#loc39))
#loc342 = loc("off_q_pe"(#loc40))
#loc343 = loc("off_q_pe"(#loc41))
#loc344 = loc("off_q_pe"(#loc42))
#loc345 = loc("offs_q"(#loc43))
#loc346 = loc("offs_q"(#loc44))
#loc347 = loc("offs_q"(#loc45))
#loc348 = loc("offs_q"(#loc46))
#loc349 = loc("offs_q"(#loc47))
#loc350 = loc("mask_c"(#loc48))
#loc351 = loc("mask_k_c"(#loc49))
#loc352 = loc("mask_qk_r"(#loc50))
#loc353 = loc("mask_k_r"(#loc51))
#loc354 = loc("blocks_per_split"(#loc52))
#loc355 = loc("split_kv_start"(#loc53))
#loc356 = loc("tail_block"(#loc61))
#loc357 = loc("split_kv_end"(#loc62))
#loc358 = loc("block_tail"(#loc63))
#loc359 = loc("block_tail"(#loc64))
#loc360 = loc("block_tail"(#loc65))
#loc361 = loc("q"(#loc66))
#loc362 = loc("q"(#loc67))
#loc363 = loc("q"(#loc68))
#loc364 = loc("q"(#loc69))
#loc365 = loc("q_pe"(#loc70))
#loc366 = loc("q_pe"(#loc71))
#loc367 = loc("q_pe"(#loc72))
#loc368 = loc("q_pe"(#loc73))
#loc369 = loc("kv_loc"(#loc74))
#loc370 = loc("kv_loc"(#loc75))
#loc371 = loc("kv_loc"(#loc76))
#loc372 = loc("kv_loc"(#loc77))
#loc373 = loc("q"(#loc78))
#loc374 = loc("q"(#loc79))
#loc375 = loc("q0"(#loc83))
#loc376 = loc("q1"(#loc84))
#loc377 = loc("q_pe"(#loc86))
#loc378 = loc("smem_k_rope"(#loc90))
#loc379 = loc("k_id"(#loc91))
#loc380 = loc("k_id"(#loc92))
#loc381 = loc("mask_k_id"(#loc93))
#loc382 = loc("mask_k"(#loc94))
#loc383 = loc("offs_buf_kv"(#loc95))
#loc384 = loc("offs_buf_kv"(#loc96))
#loc385 = loc("offs_buf_kv"(#loc97))
#loc386 = loc("offs_buf_kv"(#loc98))
#loc387 = loc("kv1"(#loc99))
#loc388 = loc("kv1"(#loc100))
#loc389 = loc("kv1"(#loc101))
#loc390 = loc("kv1"(#loc102))
#loc391 = loc("kv2"(#loc103))
#loc392 = loc("kv2"(#loc104))
#loc393 = loc("smem_kv1"(#loc105))
#loc394 = loc("smem_kv2"(#loc106))
#loc395 = loc("k_id_pe"(#loc110))
#loc396 = loc("offs_buf_k_pe"(#loc111))
#loc397 = loc("offs_buf_k_pe"(#loc112))
#loc398 = loc("offs_buf_k_pe"(#loc113))
#loc399 = loc("offs_buf_k_pe"(#loc114))
#loc400 = loc("mask_k_id"(#loc115))
#loc401 = loc("mask_k_pe"(#loc116))
#loc402 = loc("k_pe"(#loc117))
#loc403 = loc("k_pe"(#loc118))
#loc404 = loc("k_pe"(#loc119))
#loc405 = loc("k_pe"(#loc120))
#loc406 = loc("cur_k1"(#loc121))
#loc407 = loc("cur_k2"(#loc122))
#loc408 = loc("smem_kv1"(#loc123))
#loc409 = loc("smem_kv2"(#loc125))
#loc410 = loc("loop_begin"(#loc129))
#loc411 = loc("loop_begin"(#loc130))
#loc412 = loc("page_block_per_block_N"(#loc131))
#loc413 = loc("loop_end"(#loc132))
#loc414 = loc("loop_end"(#loc133))
#loc415 = loc("loop_end"(#loc134))
#loc416 = loc("loop_end"(#loc135))
#loc417 = loc("loop_end"(#loc136))
#loc418 = loc("kv_loc"(#loc137))
#loc419 = loc("start_n_block"(#loc138))
#loc420 = loc("start_n_inner"(#loc139))
#loc421 = loc("kv_loc"(#loc140))
#loc422 = loc("kv_loc"(#loc141))
#loc423 = loc("kv_loc"(#loc142))
#loc424 = loc("cur_k_pe"(#loc143))
#loc425 = loc("k_id"(#loc145))
#loc426 = loc("k_id"(#loc146))
#loc427 = loc("k_id"(#loc147))
#loc428 = loc("k_id"(#loc148))
#loc429 = loc("offs_buf_kv"(#loc149))
#loc430 = loc("offs_buf_kv"(#loc150))
#loc431 = loc("offs_buf_kv"(#loc151))
#loc432 = loc("mask_k_id"(#loc152))
#loc433 = loc("mask_k_id"(#loc153))
#loc434 = loc("mask_k_id"(#loc154))
#loc435 = loc("mask_k"(#loc155))
#loc436 = loc("qk"(#loc157))
#loc437 = loc("kv1"(#loc158))
#loc438 = loc("kv1"(#loc159))
#loc439 = loc("kv1"(#loc160))
#loc440 = loc("qk"(#loc162))
#loc441 = loc("kv2"(#loc163))
#loc442 = loc("kv2"(#loc164))
#loc443 = loc("cur_k1"(#loc165))
#loc444 = loc("cur_k2"(#loc166))
#loc445 = loc("qk"(#loc167))
#loc446 = loc("qk"(#loc168))
#loc447 = loc("k_id_pe"(#loc169))
#loc448 = loc("k_id_pe"(#loc170))
#loc449 = loc("offs_buf_k_pe"(#loc171))
#loc450 = loc("offs_buf_k_pe"(#loc172))
#loc451 = loc("offs_buf_k_pe"(#loc173))
#loc452 = loc("mask_k_id"(#loc174))
#loc453 = loc("mask_k_id"(#loc175))
#loc454 = loc("mask_k_pe"(#loc176))
#loc455 = loc("k_pe"(#loc178))
#loc456 = loc("k_pe"(#loc179))
#loc457 = loc("k_pe"(#loc180))
#loc459 = loc("n_e_max"(#loc184))
#loc460 = loc("n_e_max"(#loc185))
#loc461 = loc("re_scale"(#loc186))
#loc462 = loc("re_scale"(#loc187))
#loc463 = loc("re_scale"(#loc188))
#loc464 = loc("p"(#loc189))
#loc465 = loc("p"(#loc190))
#loc466 = loc("p"(#loc191))
#loc467 = loc("p"(#loc192))
#loc468 = loc("cur_p"(#loc196))
#loc469 = loc("smem_kv1"(#loc197))
#loc470 = loc("smem_kv2"(#loc198))
#loc471 = loc("acc1"(#loc200))
#loc472 = loc("acc1"(#loc201))
#loc473 = loc("acc1"(#loc202))
#loc474 = loc("e_sum"(#loc203))
#loc476 = loc("e_sum"(#loc207))
#loc477 = loc("acc2"(#loc209))
#loc478 = loc("acc2"(#loc210))
#loc479 = loc("cur_k1"(#loc212))
#loc480 = loc("smem_kv1"(#loc214))
#loc481 = loc("cur_k2"(#loc216))
#loc482 = loc("smem_kv2"(#loc218))
#loc483 = loc("qk"(#loc221))
#loc484 = loc("qk"(#loc222))
#loc485 = loc("cur_k_pe"(#loc223))
#loc486 = loc("qk"(#loc224))
#loc487 = loc("cur_k1"(#loc225))
#loc488 = loc("cur_k2"(#loc226))
#loc489 = loc("qk"(#loc227))
#loc490 = loc("mask_qk_n"(#loc228))
#loc491 = loc("mask_qk_n"(#loc229))
#loc492 = loc("mask_qk_n"(#loc230))
#loc493 = loc("mask_qk_n"(#loc231))
#loc494 = loc("qk"(#loc232))
#loc495 = loc("qk"(#loc233))
#loc496 = loc("qk"(#loc234))
#loc497 = loc("qk"(#loc235))
#loc498 = loc("qk"(#loc236))
#loc499 = loc("qk"(#loc237))
#loc501 = loc("n_e_max"(#loc239))
#loc502 = loc("n_e_max"(#loc240))
#loc503 = loc("re_scale"(#loc241))
#loc504 = loc("re_scale"(#loc242))
#loc505 = loc("re_scale"(#loc243))
#loc506 = loc("p"(#loc244))
#loc507 = loc("p"(#loc245))
#loc508 = loc("p"(#loc246))
#loc509 = loc("p"(#loc247))
#loc510 = loc("acc1"(#loc250))
#loc511 = loc("acc1"(#loc251))
#loc512 = loc("acc2"(#loc252))
#loc513 = loc("e_sum"(#loc253))
#loc515 = loc("e_sum"(#loc255))
#loc516 = loc("cur_p"(#loc257))
#loc517 = loc("acc1"(#loc258))
#loc518 = loc("acc2"(#loc259))
#loc519 = loc("acc"(#loc262))
#loc520 = loc("acc"(#loc263))
#loc521 = loc("acc"(#loc264))
#loc522 = loc("acc"(#loc265))
#loc523 = loc("smem_o"(#loc266))
#loc524 = loc("e_sum"(#loc267))
#loc525 = loc("cur_o"(#loc271))
#loc526 = loc("offs_mid_o"(#loc272))
#loc527 = loc("offs_mid_o"(#loc273))
#loc528 = loc("offs_mid_o"(#loc274))
#loc529 = loc("offs_mid_o"(#loc275))
#loc530 = loc("offs_mid_o"(#loc276))
#loc531 = loc("offs_mid_o"(#loc277))
#loc532 = loc("offs_mid_lse"(#loc279))
#loc533 = loc("offs_mid_lse"(#loc280))
#loc534 = loc("offs_mid_lse"(#loc281))
#loc535 = loc("offs_mid_lse"(#loc282))
#loc536 = loc("offs_mid_lse"(#loc283))
#loc537 = loc("mask_lse"(#loc284))
#loc538 = loc(callsite(#loc310 at #loc311))
#loc539 = loc(callsite(#loc312 at #loc311))
#loc540 = loc(callsite(#loc7 at #loc311))
#loc541 = loc(callsite(#loc8 at #loc311))
#loc542 = loc("pid"(#loc313))
#loc543 = loc("pid"(#loc314))
#loc544 = loc(callsite(#loc314 at #loc311))
#loc545 = loc(callsite(#loc34 at #loc338))
#loc546 = loc(callsite(#loc36 at #loc338))
#loc547 = loc(callsite(#loc34 at #loc354))
#loc548 = loc(callsite(#loc36 at #loc354))
#loc549 = loc("tail_block"(#loc356))
#loc550 = loc(fused[#loc411, #loc412])
#loc551 = loc(fused[#loc415, #loc412])
#loc552 = loc("acc1"(#loc418))
#loc553 = loc(callsite(#loc181 at #loc458))
#loc555 = loc(callsite(#loc204 at #loc475))
#loc557 = loc(callsite(#loc181 at #loc500))
#loc559 = loc(callsite(#loc204 at #loc514))
#loc561 = loc(callsite(#loc542 at #loc311))
#loc562 = loc(callsite(#loc543 at #loc311))
#loc563 = loc("acc2"(#loc552))
#loc564 = loc(callsite(#loc183 at #loc553))
#loc565 = loc(callsite(#loc206 at #loc555))
#loc566 = loc(callsite(#loc183 at #loc557))
#loc567 = loc(callsite(#loc206 at #loc559))
#loc568 = loc("k_id"(#loc563))
#loc569 = loc("mask_k_id"(#loc568))
#loc570 = loc("mask_k"(#loc569))
#loc571 = loc("offs_buf_kv"(#loc570))
#loc572 = loc("kv1"(#loc571))
#loc573 = loc("kv2"(#loc572))
#loc574 = loc("smem_kv1"(#loc573))
#loc575 = loc("smem_kv2"(#loc574))
#loc576 = loc("k_id_pe"(#loc575))
#loc577 = loc("offs_buf_k_pe"(#loc576))
#loc578 = loc("mask_k_pe"(#loc577))
#loc579 = loc("k_pe"(#loc578))
#loc580 = loc("e_sum"(#loc579))
#loc581 = loc("e_max"(#loc580))
#loc582 = loc("cur_k1"(#loc581))
#loc583 = loc("cur_k2"(#loc582))
#loc584 = loc("kv1_transpose"(#loc583))
#loc585 = loc("kv2_transpose"(#loc584))
