#blocked = #ttg.blocked<{sizePerThread = [4, 16], threadsPerWarp = [16, 4], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 16], threadsPerWarp = [64, 1], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [16, 4], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 16], threadsPerWarp = [16, 4], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1, 16], threadsPerWarp = [16, 1, 4], warpsPerCTA = [1, 1, 4], order = [2, 1, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [1, 16, 1], threadsPerWarp = [16, 4, 1], warpsPerCTA = [1, 4, 1], order = [1, 2, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [16, 4], threadsPerWarp = [4, 16], warpsPerCTA = [4, 1], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [16, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [0, 1]}>
#linear = #ttg.linear<{register = [[0, 0, 1], [0, 1, 0], [0, 2, 0], [0, 64, 0], [0, 128, 0]], lane = [[1, 0, 0], [2, 0, 0], [4, 0, 0], [8, 0, 0], [0, 4, 0], [0, 8, 0]], warp = [[0, 16, 0], [0, 32, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1, 0], [0, 0, 1], [0, 0, 2], [0, 0, 64], [0, 0, 128]], lane = [[1, 0, 0], [2, 0, 0], [4, 0, 0], [8, 0, 0], [0, 0, 4], [0, 0, 8]], warp = [[0, 0, 16], [0, 0, 32]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 256], [0, 1], [0, 2], [0, 64], [0, 128]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [0, 4], [0, 8]], warp = [[0, 16], [0, 32]], block = []}>
#loc = loc(unknown)
#loc1 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":41:0)
#loc167 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":451:47)
#loc190 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":468:45)
#loc223 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":525:43)
#loc239 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":538:41)
#mma = #ttg.amd_mfma<{version = 3, warpsPerCTA = [1, 4], instrShape = [16, 16, 16], isTransposed = true}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 8, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 16, order = [1, 0]}>
#shared2 = #ttg.swizzled_shared<{vec = 16, perPhase = 1, maxPhase = 16, order = [0, 1]}>
#smem = #ttg.shared_memory
#loc274 = loc("Q"(#loc1))
#loc275 = loc("K_Buffer"(#loc1))
#loc276 = loc("V_buffer"(#loc1))
#loc277 = loc("sm_scale"(#loc1))
#loc278 = loc("kv_indptr"(#loc1))
#loc279 = loc("kv_indices"(#loc1))
#loc280 = loc("Att_Out"(#loc1))
#loc281 = loc("Att_Lse"(#loc1))
#loc282 = loc("stride_qb"(#loc1))
#loc283 = loc("stride_qh"(#loc1))
#loc284 = loc("stride_buf_kbs"(#loc1))
#loc285 = loc("stride_buf_kh"(#loc1))
#loc286 = loc("stride_mid_ob"(#loc1))
#loc287 = loc("stride_mid_oh"(#loc1))
#loc288 = loc("stride_mid_os"(#loc1))
#loc289 = loc("stride_mid_lse_b"(#loc1))
#loc290 = loc("stride_mid_lse_h"(#loc1))
#loc291 = loc("stride_mid_lse_s"(#loc1))
#loc292 = loc("stride_b_block_table"(#loc1))
#loc429 = loc("n_e_max"(#loc167))
#loc446 = loc("e_sum"(#loc190))
#loc471 = loc("n_e_max"(#loc223))
#loc485 = loc("e_sum"(#loc239))
#loc522 = loc(callsite(#loc at #loc429))
#loc524 = loc(callsite(#loc at #loc446))
#loc526 = loc(callsite(#loc at #loc471))
#loc528 = loc(callsite(#loc at #loc485))
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_fwd_grouped_kernel_stage1_n16x4_prefetch_k_paged_64(%Q: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("Q"(#loc1)), %K_Buffer: !tt.ptr<bf16> {tt.divisibility = 16 : i32} loc("K_Buffer"(#loc1)), %V_buffer: !tt.ptr<bf16> {tt.divisibility = 16 : i32} loc("V_buffer"(#loc1)), %sm_scale: f32 {tt.divisibility = 16 : i32} loc("sm_scale"(#loc1)), %kv_indptr: !tt.ptr<i32> {tt.divisibility = 16 : i32} loc("kv_indptr"(#loc1)), %kv_indices: !tt.ptr<i32> {tt.divisibility = 16 : i32} loc("kv_indices"(#loc1)), %Att_Out: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("Att_Out"(#loc1)), %Att_Lse: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("Att_Lse"(#loc1)), %stride_qb: i32 {tt.divisibility = 16 : i32} loc("stride_qb"(#loc1)), %stride_qh: i32 {tt.divisibility = 16 : i32} loc("stride_qh"(#loc1)), %stride_buf_kbs: i32 {tt.divisibility = 16 : i32} loc("stride_buf_kbs"(#loc1)), %stride_buf_kh: i32 {tt.divisibility = 16 : i32} loc("stride_buf_kh"(#loc1)), %stride_mid_ob: i32 {tt.divisibility = 16 : i32} loc("stride_mid_ob"(#loc1)), %stride_mid_oh: i32 {tt.divisibility = 16 : i32} loc("stride_mid_oh"(#loc1)), %stride_mid_os: i32 {tt.divisibility = 16 : i32} loc("stride_mid_os"(#loc1)), %stride_mid_lse_b: i32 loc("stride_mid_lse_b"(#loc1)), %stride_mid_lse_h: i32 loc("stride_mid_lse_h"(#loc1)), %stride_mid_lse_s: i32 loc("stride_mid_lse_s"(#loc1)), %stride_b_block_table: i32 loc("stride_b_block_table"(#loc1))) attributes {noinline = false} {
    %blocks_per_split = arith.constant 7 : i32 loc(#loc509)
    %cur_batch_block_nums = arith.constant 63 : i32 loc(#loc510)
    %cst = arith.constant dense<8> : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_0 = arith.constant dense<1.000000e+00> : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_1 = arith.constant dense<1.44269502> : tensor<16x64xf32, #mma> loc(#loc)
    %cst_2 = arith.constant dense<1.44269502> : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_3 = arith.constant dense<0xFF800000> : tensor<16x64xf32, #mma> loc(#loc)
    %cst_4 = arith.constant dense<0> : tensor<16x1xi32, #mma> loc(#loc)
    %cst_5 = arith.constant dense<0x7F800000> : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_7 = arith.constant dense<256> : tensor<64x256xi32, #blocked> loc(#loc)
    %cst_8 = arith.constant dense<0.000000e+00> : tensor<16x64xf32, #mma> loc(#loc)
    %cst_9 = arith.constant dense<0.000000e+00> : tensor<16x256xf32, #mma> loc(#loc)
    %cst_10 = arith.constant dense<576> : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc)
    %cst_11 = arith.constant dense<576> : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc)
    %cst_12 = arith.constant dense<512> : tensor<256xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %cst_13 = arith.constant dense<512> : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %cst_14 = arith.constant dense<8> : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc)
    %cst_15 = arith.constant dense<8> : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc)
    %c1_i32 = arith.constant 1 : i32 loc(#loc)
    %c512_i32 = arith.constant 512 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %pid = tt.get_program_id x : i32 loc(#loc295)
    %pid_head_kv_split = arith.remsi %pid, %c8_i32 : i32 loc(#loc296)
    %xcd = arith.remsi %pid_head_kv_split, %c8_i32 : i32 loc(#loc511)
    %local_pid = arith.divsi %pid_head_kv_split, %c8_i32 : i32 loc(#loc512)
    %pid_head_kv_split_16 = arith.cmpi slt, %xcd, %c8_i32 : i32 loc(#loc513)
    %pid_head_kv_split_17 = scf.if %pid_head_kv_split_16 -> (i32) {
      %pid_148 = arith.addi %xcd, %local_pid : i32 loc(#loc529)
      scf.yield %pid_148 : i32 loc(#loc529)
    } else {
      %pid_148 = arith.addi %local_pid, %c8_i32 : i32 loc(#loc530)
      scf.yield %pid_148 : i32 loc(#loc517)
    } loc(#loc514)
    %split_kv_id = arith.remsi %pid_head_kv_split_17, %c8_i32 : i32 loc(#loc302)
    %cur_batch = arith.divsi %pid, %c8_i32 : i32 loc(#loc303)
    %cur_batch_18 = arith.remsi %cur_batch, %c512_i32 : i32 loc(#loc304)
    %cur_batch_kv_start_idx = tt.addptr %kv_indptr, %cur_batch_18 : !tt.ptr<i32>, i32 loc(#loc305)
    %cur_batch_kv_start_idx_19 = tt.load %cur_batch_kv_start_idx : !tt.ptr<i32> loc(#loc306)
    %cur_batch_kv_end_idx = tt.addptr %cur_batch_kv_start_idx, %c1_i32 : !tt.ptr<i32>, i32 loc(#loc307)
    %cur_batch_kv_end_idx_20 = tt.load %cur_batch_kv_end_idx : !tt.ptr<i32> loc(#loc308)
    %smem_q0_nope = ttg.local_alloc : () -> !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc309)
    %smem_q1_nope = ttg.local_alloc : () -> !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc310)
    %smem_q_rope = ttg.local_alloc : () -> !ttg.memdesc<16x64xbf16, #shared, #smem, mutable> loc(#loc311)
    %smem_p = ttg.local_alloc : () -> !ttg.memdesc<16x64xbf16, #shared1, #smem, mutable> loc(#loc312)
    %cur_head = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc313)
    %mask_h = arith.cmpi slt, %cur_head, %cst_15 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc314)
    %cur_N = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc315)
    %cur_N_pe = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc316)
    %cur_head_pe = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc317)
    %mask_h_pe = arith.cmpi slt, %cur_head_pe, %cst_14 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc318)
    %offs_c = tt.make_range {end = 512 : i32, start = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc319)
    %offs_om = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc320)
    %offs_qk_r = tt.make_range {end = 576 : i32, start = 512 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc321)
    %offs_k_c = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc322)
    %offs_k_r = tt.make_range {end = 576 : i32, start = 512 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc323)
    %cur_batch_seq_len = arith.subi %cur_batch_kv_end_idx_20, %cur_batch_kv_start_idx_19 : i32 loc(#loc324)
    %cur_batch_block_nums_21 = arith.addi %cur_batch_seq_len, %cur_batch_block_nums : i32 loc(#loc510)
    %cur_batch_block_nums_22 = arith.divsi %cur_batch_block_nums_21, %c64_i32 : i32 loc(#loc518)
    %off_q_pe = arith.muli %cur_batch_18, %stride_qb : i32 loc(#loc325)
    %off_q_pe_23 = tt.expand_dims %cur_head_pe {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<16x1xi32, #blocked2> loc(#loc326)
    %off_q_pe_24 = tt.splat %stride_qh : i32 -> tensor<16x1xi32, #blocked2> loc(#loc327)
    %off_q_pe_25 = arith.muli %off_q_pe_23, %off_q_pe_24 : tensor<16x1xi32, #blocked2> loc(#loc327)
    %off_q_pe_26 = tt.splat %off_q_pe : i32 -> tensor<16x1xi32, #blocked2> loc(#loc328)
    %off_q_pe_27 = arith.addi %off_q_pe_26, %off_q_pe_25 : tensor<16x1xi32, #blocked2> loc(#loc328)
    %off_q_pe_28 = tt.expand_dims %offs_qk_r {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x64xi32, #blocked2> loc(#loc329)
    %off_q_pe_29 = tt.broadcast %off_q_pe_27 : tensor<16x1xi32, #blocked2> -> tensor<16x64xi32, #blocked2> loc(#loc330)
    %off_q_pe_30 = tt.broadcast %off_q_pe_28 : tensor<1x64xi32, #blocked2> -> tensor<16x64xi32, #blocked2> loc(#loc330)
    %off_q_pe_31 = arith.addi %off_q_pe_29, %off_q_pe_30 : tensor<16x64xi32, #blocked2> loc(#loc330)
    %offs_q = tt.expand_dims %cur_head {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<16x1xi32, #blocked3> loc(#loc331)
    %offs_q_32 = tt.splat %stride_qh : i32 -> tensor<16x1xi32, #blocked3> loc(#loc332)
    %offs_q_33 = arith.muli %offs_q, %offs_q_32 : tensor<16x1xi32, #blocked3> loc(#loc332)
    %offs_q_34 = tt.splat %off_q_pe : i32 -> tensor<16x1xi32, #blocked3> loc(#loc333)
    %offs_q_35 = arith.addi %offs_q_34, %offs_q_33 : tensor<16x1xi32, #blocked3> loc(#loc333)
    %offs_q_36 = tt.expand_dims %offs_c {axis = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x512xi32, #blocked3> loc(#loc334)
    %offs_q_37 = tt.broadcast %offs_q_35 : tensor<16x1xi32, #blocked3> -> tensor<16x512xi32, #blocked3> loc(#loc335)
    %offs_q_38 = tt.broadcast %offs_q_36 : tensor<1x512xi32, #blocked3> -> tensor<16x512xi32, #blocked3> loc(#loc335)
    %offs_q_39 = arith.addi %offs_q_37, %offs_q_38 : tensor<16x512xi32, #blocked3> loc(#loc335)
    %mask_c = arith.cmpi slt, %offs_c, %cst_13 : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc336)
    %mask_k_c = arith.cmpi slt, %offs_k_c, %cst_12 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc337)
    %mask_qk_r = arith.cmpi slt, %offs_qk_r, %cst_11 : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc338)
    %mask_k_r = arith.cmpi slt, %offs_k_r, %cst_10 : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc339)
    %blocks_per_split_40 = arith.addi %cur_batch_block_nums_22, %blocks_per_split : i32 loc(#loc509)
    %blocks_per_split_41 = arith.divsi %blocks_per_split_40, %c8_i32 : i32 loc(#loc519)
    %split_kv_start = arith.muli %blocks_per_split_41, %split_kv_id : i32 loc(#loc340)
    %0 = arith.muli %split_kv_start, %c64_i32 : i32 loc(#loc54)
    %1 = arith.cmpi sgt, %0, %cur_batch_seq_len : i32 loc(#loc55)
    cf.cond_br %1, ^bb1, ^bb2 loc(#loc55)
  ^bb1:  // pred: ^bb0
    tt.return loc(#loc56)
  ^bb2:  // pred: ^bb0
    cf.br ^bb3 loc(#loc)
  ^bb3:  // pred: ^bb2
    %split_kv_end = arith.addi %split_kv_start, %blocks_per_split_41 : i32 loc(#loc341)
    %split_kv_end_42 = arith.minsi %split_kv_end, %cur_batch_block_nums_22 : i32 loc(#loc342)
    %q = tt.expand_dims %mask_h {axis = 1 : i32} : tensor<16xi1, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<16x1xi1, #blocked3> loc(#loc343)
    %q_43 = tt.expand_dims %mask_c {axis = 0 : i32} : tensor<512xi1, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x512xi1, #blocked3> loc(#loc344)
    %q_44 = tt.broadcast %q : tensor<16x1xi1, #blocked3> -> tensor<16x512xi1, #blocked3> loc(#loc345)
    %q_45 = tt.broadcast %q_43 : tensor<1x512xi1, #blocked3> -> tensor<16x512xi1, #blocked3> loc(#loc345)
    %q_46 = arith.andi %q_44, %q_45 : tensor<16x512xi1, #blocked3> loc(#loc345)
    %q_47 = amdgpu.buffer_load %Q[%offs_q_39], %q_46 : tensor<16x512xbf16, #blocked3> loc(#loc346)
    %q_pe = tt.expand_dims %mask_h_pe {axis = 1 : i32} : tensor<16xi1, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<16x1xi1, #blocked2> loc(#loc347)
    %q_pe_48 = tt.expand_dims %mask_qk_r {axis = 0 : i32} : tensor<64xi1, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x64xi1, #blocked2> loc(#loc348)
    %q_pe_49 = tt.broadcast %q_pe : tensor<16x1xi1, #blocked2> -> tensor<16x64xi1, #blocked2> loc(#loc349)
    %q_pe_50 = tt.broadcast %q_pe_48 : tensor<1x64xi1, #blocked2> -> tensor<16x64xi1, #blocked2> loc(#loc349)
    %q_pe_51 = arith.andi %q_pe_49, %q_pe_50 : tensor<16x64xi1, #blocked2> loc(#loc349)
    %q_pe_52 = amdgpu.buffer_load %Q[%off_q_pe_31], %q_pe_51 : tensor<16x64xbf16, #blocked2> loc(#loc350)
    %kv_loc = tt.addptr %kv_indices, %split_kv_start : !tt.ptr<i32>, i32 loc(#loc351)
    %kv_loc_53 = arith.muli %cur_batch_18, %stride_b_block_table : i32 loc(#loc352)
    %kv_loc_54 = tt.addptr %kv_loc, %kv_loc_53 : !tt.ptr<i32>, i32 loc(#loc353)
    %kv_loc_55 = tt.load %kv_loc_54 : !tt.ptr<i32> loc(#loc354)
    %q_56 = tt.reshape %q_47 : tensor<16x512xbf16, #blocked3> -> tensor<16x2x256xbf16, #blocked4> loc(#loc355)
    %q_57 = tt.trans %q_56 {order = array<i32: 0, 2, 1>} : tensor<16x2x256xbf16, #blocked4> -> tensor<16x256x2xbf16, #blocked5> loc(#loc356)
    %outLHS, %outRHS = tt.split %q_57 : tensor<16x256x2xbf16, #blocked5> -> tensor<16x256xbf16, #ttg.slice<{dim = 2, parent = #blocked5}>> loc(#loc73)
    ttg.local_store %outLHS, %smem_q0_nope : tensor<16x256xbf16, #ttg.slice<{dim = 2, parent = #blocked5}>> -> !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc74)
    ttg.local_store %outRHS, %smem_q1_nope : tensor<16x256xbf16, #ttg.slice<{dim = 2, parent = #blocked5}>> -> !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc75)
    %q0 = ttg.local_load %smem_q0_nope : !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> -> tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc357)
    %q1 = ttg.local_load %smem_q1_nope : !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> -> tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc358)
    ttg.local_store %q_pe_52, %smem_q_rope : tensor<16x64xbf16, #blocked2> -> !ttg.memdesc<16x64xbf16, #shared, #smem, mutable> loc(#loc78)
    %q_pe_58 = ttg.local_load %smem_q_rope : !ttg.memdesc<16x64xbf16, #shared, #smem, mutable> -> tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc359)
    ttg.local_dealloc %smem_q0_nope : !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc80)
    ttg.local_dealloc %smem_q1_nope : !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc81)
    ttg.local_dealloc %smem_q_rope : !ttg.memdesc<16x64xbf16, #shared, #smem, mutable> loc(#loc82)
    %smem_k_rope = ttg.local_alloc : () -> !ttg.memdesc<64x64xbf16, #shared2, #smem, mutable> loc(#loc360)
    %k_id = arith.muli %kv_loc_55, %c64_i32 : i32 loc(#loc361)
    %k_id_59 = tt.splat %k_id : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc362)
    %k_id_60 = arith.addi %k_id_59, %cur_N : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc362)
    %mask_k_id = tt.splat %0 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc363)
    %mask_k_id_61 = arith.addi %mask_k_id, %cur_N : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc363)
    %mask_k = tt.splat %cur_batch_seq_len : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc364)
    %mask_k_62 = arith.cmpi slt, %mask_k_id_61, %mask_k : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc364)
    %offs_buf_kv = tt.expand_dims %k_id_60 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<64x1xi32, #blocked> loc(#loc365)
    %offs_buf_kv_63 = tt.splat %stride_buf_kh : i32 -> tensor<64x1xi32, #blocked> loc(#loc366)
    %offs_buf_kv_64 = arith.muli %offs_buf_kv, %offs_buf_kv_63 : tensor<64x1xi32, #blocked> loc(#loc366)
    %offs_buf_kv_65 = tt.expand_dims %offs_k_c {axis = 0 : i32} : tensor<256xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x256xi32, #blocked> loc(#loc367)
    %offs_buf_kv_66 = tt.broadcast %offs_buf_kv_64 : tensor<64x1xi32, #blocked> -> tensor<64x256xi32, #blocked> loc(#loc368)
    %offs_buf_kv_67 = tt.broadcast %offs_buf_kv_65 : tensor<1x256xi32, #blocked> -> tensor<64x256xi32, #blocked> loc(#loc368)
    %offs_buf_kv_68 = arith.addi %offs_buf_kv_66, %offs_buf_kv_67 : tensor<64x256xi32, #blocked> loc(#loc368)
    %kv1 = tt.expand_dims %mask_k_62 {axis = 1 : i32} : tensor<64xi1, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<64x1xi1, #blocked> loc(#loc369)
    %kv1_69 = tt.expand_dims %mask_k_c {axis = 0 : i32} : tensor<256xi1, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x256xi1, #blocked> loc(#loc370)
    %kv1_70 = tt.broadcast %kv1 : tensor<64x1xi1, #blocked> -> tensor<64x256xi1, #blocked> loc(#loc371)
    %kv1_71 = tt.broadcast %kv1_69 : tensor<1x256xi1, #blocked> -> tensor<64x256xi1, #blocked> loc(#loc371)
    %kv1_72 = arith.andi %kv1_70, %kv1_71 : tensor<64x256xi1, #blocked> loc(#loc371)
    %kv1_73 = amdgpu.buffer_load %K_Buffer[%offs_buf_kv_68], %kv1_72 : tensor<64x256xbf16, #blocked> loc(#loc372)
    %kv2 = arith.addi %offs_buf_kv_68, %cst_7 : tensor<64x256xi32, #blocked> loc(#loc373)
    %kv2_74 = amdgpu.buffer_load %K_Buffer[%kv2], %kv1_72 : tensor<64x256xbf16, #blocked> loc(#loc374)
    %smem_kv1 = ttg.local_alloc : () -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc375)
    %smem_kv2 = ttg.local_alloc : () -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc376)
    rocdl.sched.barrier 0 loc(#loc100)
    %2 = tt.trans %kv1_73 {order = array<i32: 1, 0>} : tensor<64x256xbf16, #blocked> -> tensor<256x64xbf16, #blocked6> loc(#loc101)
    ttg.local_store %2, %smem_kv1 : tensor<256x64xbf16, #blocked6> -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc101)
    %3 = tt.trans %kv2_74 {order = array<i32: 1, 0>} : tensor<64x256xbf16, #blocked> -> tensor<256x64xbf16, #blocked6> loc(#loc102)
    ttg.local_store %3, %smem_kv2 : tensor<256x64xbf16, #blocked6> -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc102)
    %k_id_pe = tt.splat %k_id : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc377)
    %k_id_pe_75 = arith.addi %k_id_pe, %cur_N_pe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc377)
    %offs_buf_k_pe = tt.expand_dims %k_id_pe_75 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<64x1xi32, #blocked1> loc(#loc378)
    %offs_buf_k_pe_76 = tt.splat %stride_buf_kh : i32 -> tensor<64x1xi32, #blocked1> loc(#loc379)
    %offs_buf_k_pe_77 = arith.muli %offs_buf_k_pe, %offs_buf_k_pe_76 : tensor<64x1xi32, #blocked1> loc(#loc379)
    %offs_buf_k_pe_78 = tt.expand_dims %offs_k_r {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x64xi32, #blocked1> loc(#loc380)
    %offs_buf_k_pe_79 = tt.broadcast %offs_buf_k_pe_77 : tensor<64x1xi32, #blocked1> -> tensor<64x64xi32, #blocked1> loc(#loc381)
    %offs_buf_k_pe_80 = tt.broadcast %offs_buf_k_pe_78 : tensor<1x64xi32, #blocked1> -> tensor<64x64xi32, #blocked1> loc(#loc381)
    %offs_buf_k_pe_81 = arith.addi %offs_buf_k_pe_79, %offs_buf_k_pe_80 : tensor<64x64xi32, #blocked1> loc(#loc381)
    %mask_k_id_82 = tt.splat %0 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc382)
    %mask_k_id_83 = arith.addi %mask_k_id_82, %cur_N_pe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc382)
    %mask_k_pe = tt.splat %cur_batch_seq_len : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc383)
    %mask_k_pe_84 = arith.cmpi slt, %mask_k_id_83, %mask_k_pe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc383)
    %k_pe = tt.expand_dims %mask_k_pe_84 {axis = 1 : i32} : tensor<64xi1, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<64x1xi1, #blocked1> loc(#loc384)
    %k_pe_85 = tt.expand_dims %mask_k_r {axis = 0 : i32} : tensor<64xi1, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x64xi1, #blocked1> loc(#loc385)
    %k_pe_86 = tt.broadcast %k_pe : tensor<64x1xi1, #blocked1> -> tensor<64x64xi1, #blocked1> loc(#loc386)
    %k_pe_87 = tt.broadcast %k_pe_85 : tensor<1x64xi1, #blocked1> -> tensor<64x64xi1, #blocked1> loc(#loc386)
    %k_pe_88 = arith.andi %k_pe_86, %k_pe_87 : tensor<64x64xi1, #blocked1> loc(#loc386)
    %k_pe_89 = amdgpu.buffer_load %K_Buffer[%offs_buf_k_pe_81], %k_pe_88 : tensor<64x64xbf16, #blocked1> loc(#loc387)
    %e_sum = arith.sitofp %offs_om : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> to tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc388)
    %e_sum_90 = arith.mulf %e_sum, %cst_6 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc389)
    %e_max = arith.subf %e_sum_90, %cst_5 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc390)
    %cur_k1 = ttg.local_load %smem_kv1 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc391)
    %cur_k2 = ttg.local_load %smem_kv2 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc392)
    rocdl.sched.barrier 0 loc(#loc119)
    %smem_kv1_91 = ttg.memdesc_reinterpret %smem_kv1 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc393)
    rocdl.sched.barrier 0 loc(#loc121)
    ttg.local_store %kv1_73, %smem_kv1_91 : tensor<64x256xbf16, #blocked> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc122)
    %smem_kv2_92 = ttg.memdesc_reinterpret %smem_kv2 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc394)
    rocdl.sched.barrier 0 loc(#loc124)
    ttg.local_store %kv2_74, %smem_kv2_92 : tensor<64x256xbf16, #blocked> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc125)
    %4 = tt.trans %k_pe_89 {order = array<i32: 1, 0>} : tensor<64x64xbf16, #blocked1> -> tensor<64x64xbf16, #blocked7> loc(#loc126)
    ttg.local_store %4, %smem_k_rope : tensor<64x64xbf16, #blocked7> -> !ttg.memdesc<64x64xbf16, #shared2, #smem, mutable> loc(#loc126)
    rocdl.sched.barrier 0 loc(#loc127)
    %split_kv_start_93 = arith.addi %split_kv_start, %c1_i32 : i32 loc(#loc395)
    %kv2_transpose:8 = scf.for %kv2_transpose_148 = %split_kv_start_93 to %split_kv_end_42 step %c1_i32 iter_args(%arg20 = %cst_9, %arg21 = %cst_9, %smem_kv1_149 = %smem_kv1_91, %smem_kv2_150 = %smem_kv2_92, %e_sum_151 = %e_sum_90, %e_max_152 = %e_max, %cur_k1_153 = %cur_k1, %cur_k2_154 = %cur_k2) -> (tensor<16x256xf32, #mma>, tensor<16x256xf32, #mma>, !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable>, !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable>, tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>>, tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>>)  : i32 {
      %kv_loc_155 = tt.addptr %kv_indices, %kv2_transpose_148 : !tt.ptr<i32>, i32 loc(#loc397)
      %kv_loc_156 = tt.addptr %kv_loc_155, %kv_loc_53 : !tt.ptr<i32>, i32 loc(#loc398)
      %kv_loc_157 = tt.load %kv_loc_156 : !tt.ptr<i32> loc(#loc399)
      %cur_k_pe_158 = ttg.local_load %smem_k_rope : !ttg.memdesc<64x64xbf16, #shared2, #smem, mutable> -> tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc400)
      rocdl.sched.barrier 0 loc(#loc134)
      %k_id_159 = arith.muli %kv_loc_157, %c64_i32 : i32 loc(#loc401)
      %k_id_160 = tt.splat %k_id_159 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc402)
      %k_id_161 = arith.addi %k_id_160, %cur_N : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc402)
      %offs_buf_kv_162 = tt.expand_dims %k_id_161 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<64x1xi32, #blocked> loc(#loc403)
      %offs_buf_kv_163 = arith.muli %offs_buf_kv_162, %offs_buf_kv_63 : tensor<64x1xi32, #blocked> loc(#loc404)
      %offs_buf_kv_164 = tt.broadcast %offs_buf_kv_163 : tensor<64x1xi32, #blocked> -> tensor<64x256xi32, #blocked> loc(#loc405)
      %offs_buf_kv_165 = arith.addi %offs_buf_kv_164, %offs_buf_kv_67 : tensor<64x256xi32, #blocked> loc(#loc405)
      %mask_k_id_166 = arith.muli %kv2_transpose_148, %c64_i32 : i32 loc(#loc406)
      %mask_k_id_167 = tt.splat %mask_k_id_166 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc407)
      %mask_k_id_168 = arith.addi %mask_k_id_167, %cur_N : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc407)
      %mask_k_169 = arith.cmpi slt, %mask_k_id_168, %mask_k : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc408)
      rocdl.sched.barrier 0 loc(#loc143)
      %qk_170 = tt.dot %q0, %cur_k1_153, %cst_8 : tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x64xf32, #mma> loc(#loc409)
      %kv1_171 = tt.expand_dims %mask_k_169 {axis = 1 : i32} : tensor<64xi1, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<64x1xi1, #blocked> loc(#loc410)
      %kv1_172 = tt.broadcast %kv1_171 : tensor<64x1xi1, #blocked> -> tensor<64x256xi1, #blocked> loc(#loc411)
      %kv1_173 = arith.andi %kv1_172, %kv1_71 : tensor<64x256xi1, #blocked> loc(#loc411)
      %kv1_174 = amdgpu.buffer_load %K_Buffer[%offs_buf_kv_165], %kv1_173 : tensor<64x256xbf16, #blocked> loc(#loc412)
      rocdl.sched.barrier 0 loc(#loc148)
      %qk_175 = tt.dot %q1, %cur_k2_154, %qk_170 : tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x64xf32, #mma> loc(#loc413)
      %kv2_176 = arith.addi %offs_buf_kv_165, %cst_7 : tensor<64x256xi32, #blocked> loc(#loc414)
      %kv2_177 = amdgpu.buffer_load %K_Buffer[%kv2_176], %kv1_173 : tensor<64x256xbf16, #blocked> loc(#loc415)
      %cur_k1_178 = ttg.local_load %smem_kv1_149 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> -> tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc416)
      %cur_k2_179 = ttg.local_load %smem_kv2_150 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> -> tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc417)
      %qk_180 = tt.dot %q_pe_58, %cur_k_pe_158, %qk_175 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x64xf32, #mma> loc(#loc418)
      %qk_181 = tt.splat %sm_scale : f32 -> tensor<16x64xf32, #mma> loc(#loc419)
      %qk_182 = arith.mulf %qk_180, %qk_181 : tensor<16x64xf32, #mma> loc(#loc419)
      %k_id_pe_183 = tt.splat %k_id_159 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc420)
      %k_id_pe_184 = arith.addi %k_id_pe_183, %cur_N_pe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc420)
      %offs_buf_k_pe_185 = tt.expand_dims %k_id_pe_184 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<64x1xi32, #blocked1> loc(#loc421)
      %offs_buf_k_pe_186 = arith.muli %offs_buf_k_pe_185, %offs_buf_k_pe_76 : tensor<64x1xi32, #blocked1> loc(#loc422)
      %offs_buf_k_pe_187 = tt.broadcast %offs_buf_k_pe_186 : tensor<64x1xi32, #blocked1> -> tensor<64x64xi32, #blocked1> loc(#loc423)
      %offs_buf_k_pe_188 = arith.addi %offs_buf_k_pe_187, %offs_buf_k_pe_80 : tensor<64x64xi32, #blocked1> loc(#loc423)
      %mask_k_id_189 = tt.splat %mask_k_id_166 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc424)
      %mask_k_id_190 = arith.addi %mask_k_id_189, %cur_N_pe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc424)
      %mask_k_pe_191 = arith.cmpi slt, %mask_k_id_190, %mask_k_pe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc425)
      rocdl.sched.barrier 0 loc(#loc162)
      %k_pe_192 = tt.expand_dims %mask_k_pe_191 {axis = 1 : i32} : tensor<64xi1, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<64x1xi1, #blocked1> loc(#loc426)
      %k_pe_193 = tt.broadcast %k_pe_192 : tensor<64x1xi1, #blocked1> -> tensor<64x64xi1, #blocked1> loc(#loc427)
      %k_pe_194 = arith.andi %k_pe_193, %k_pe_87 : tensor<64x64xi1, #blocked1> loc(#loc427)
      %k_pe_195 = amdgpu.buffer_load %K_Buffer[%offs_buf_k_pe_188], %k_pe_194 : tensor<64x64xbf16, #blocked1> loc(#loc428)
      %n_e_max_196 = "tt.reduce"(%qk_182) <{axis = 1 : i32}> ({
      ^bb0(%n_e_max_223: f32 loc(callsite(#loc at #loc429)), %n_e_max_224: f32 loc(callsite(#loc at #loc429))):
        %n_e_max_225 = arith.maxnumf %n_e_max_223, %n_e_max_224 : f32 loc(#loc532)
        tt.reduce.return %n_e_max_225 : f32 loc(#loc521)
      }) : (tensor<16x64xf32, #mma>) -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc521)
      %n_e_max_197 = ttg.convert_layout %n_e_max_196 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc430)
      %n_e_max_198 = arith.maxnumf %n_e_max_197, %e_max_152 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc431)
      %re_scale_199 = arith.subf %e_max_152, %n_e_max_198 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc432)
      %re_scale_200 = arith.mulf %re_scale_199, %cst_2 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc433)
      %re_scale_201 = math.exp2 %re_scale_200 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc434)
      %p_202 = tt.expand_dims %n_e_max_198 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc435)
      %p_203 = tt.broadcast %p_202 : tensor<16x1xf32, #mma> -> tensor<16x64xf32, #mma> loc(#loc436)
      %p_204 = arith.subf %qk_182, %p_203 : tensor<16x64xf32, #mma> loc(#loc436)
      %p_205 = arith.mulf %p_204, %cst_1 : tensor<16x64xf32, #mma> loc(#loc437)
      %p_206 = math.exp2 %p_205 : tensor<16x64xf32, #mma> loc(#loc438)
      %11 = arith.truncf %p_206 : tensor<16x64xf32, #mma> to tensor<16x64xbf16, #mma> loc(#loc178)
      ttg.local_store %11, %smem_p : tensor<16x64xbf16, #mma> -> !ttg.memdesc<16x64xbf16, #shared1, #smem, mutable> loc(#loc179)
      rocdl.sched.barrier 0 loc(#loc180)
      %cur_p_207 = ttg.local_load %smem_p : !ttg.memdesc<16x64xbf16, #shared1, #smem, mutable> -> tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc439)
      %smem_kv1_208 = ttg.memdesc_reinterpret %smem_kv1_149 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc440)
      %smem_kv2_209 = ttg.memdesc_reinterpret %smem_kv2_150 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc441)
      %12 = tt.trans %kv1_174 {order = array<i32: 1, 0>} : tensor<64x256xbf16, #blocked> -> tensor<256x64xbf16, #blocked6> loc(#loc184)
      ttg.local_store %12, %smem_kv1_208 : tensor<256x64xbf16, #blocked6> -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc184)
      %acc1_210 = tt.expand_dims %re_scale_201 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc442)
      %acc1_211 = tt.broadcast %acc1_210 : tensor<16x1xf32, #mma> -> tensor<16x256xf32, #mma> loc(#loc443)
      %acc1_212 = arith.mulf %arg20, %acc1_211 : tensor<16x256xf32, #mma> loc(#loc443)
      %acc1_213 = tt.dot %cur_p_207, %cur_k1_178, %acc1_212 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x256xf32, #mma> loc(#loc444)
      %e_sum_214 = arith.mulf %e_sum_151, %re_scale_201 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc445)
      %e_sum_215 = "tt.reduce"(%p_206) <{axis = 1 : i32}> ({
      ^bb0(%e_sum_223: f32 loc(callsite(#loc at #loc446)), %e_sum_224: f32 loc(callsite(#loc at #loc446))):
        %e_sum_225 = arith.addf %e_sum_223, %e_sum_224 : f32 loc(#loc533)
        tt.reduce.return %e_sum_225 : f32 loc(#loc523)
      }) : (tensor<16x64xf32, #mma>) -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc523)
      %e_sum_216 = arith.addf %e_sum_214, %e_sum_215 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc447)
      %13 = tt.trans %kv2_177 {order = array<i32: 1, 0>} : tensor<64x256xbf16, #blocked> -> tensor<256x64xbf16, #blocked6> loc(#loc193)
      ttg.local_store %13, %smem_kv2_209 : tensor<256x64xbf16, #blocked6> -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc193)
      %acc2_217 = arith.mulf %arg21, %acc1_211 : tensor<16x256xf32, #mma> loc(#loc448)
      %acc2_218 = tt.dot %cur_p_207, %cur_k2_179, %acc2_217 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x256xf32, #mma> loc(#loc449)
      %14 = tt.trans %k_pe_195 {order = array<i32: 1, 0>} : tensor<64x64xbf16, #blocked1> -> tensor<64x64xbf16, #blocked7> loc(#loc196)
      ttg.local_store %14, %smem_k_rope : tensor<64x64xbf16, #blocked7> -> !ttg.memdesc<64x64xbf16, #shared2, #smem, mutable> loc(#loc196)
      %cur_k1_219 = ttg.local_load %smem_kv1_208 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc450)
      rocdl.sched.barrier 0 loc(#loc198)
      %smem_kv1_220 = ttg.memdesc_reinterpret %smem_kv1_208 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc451)
      ttg.local_store %kv1_174, %smem_kv1_220 : tensor<64x256xbf16, #blocked> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc200)
      %cur_k2_221 = ttg.local_load %smem_kv2_209 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc452)
      rocdl.sched.barrier 0 loc(#loc202)
      %smem_kv2_222 = ttg.memdesc_reinterpret %smem_kv2_209 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc453)
      ttg.local_store %kv2_177, %smem_kv2_222 : tensor<64x256xbf16, #blocked> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc204)
      scf.yield %acc1_213, %acc2_218, %smem_kv1_220, %smem_kv2_222, %e_sum_216, %n_e_max_198, %cur_k1_219, %cur_k2_221 : tensor<16x256xf32, #mma>, tensor<16x256xf32, #mma>, !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable>, !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable>, tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>>, tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc205)
    } loc(#loc553)
    %qk = tt.dot %q0, %kv2_transpose#6, %cst_8 : tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x64xf32, #mma> loc(#loc454)
    %qk_94 = tt.dot %q1, %kv2_transpose#7, %qk : tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x64xf32, #mma> loc(#loc455)
    %cur_k_pe = ttg.local_load %smem_k_rope : !ttg.memdesc<64x64xbf16, #shared2, #smem, mutable> -> tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc456)
    %qk_95 = tt.dot %q_pe_58, %cur_k_pe, %qk_94 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x64xf32, #mma> loc(#loc457)
    %cur_k1_96 = ttg.local_load %kv2_transpose#2 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> -> tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc458)
    %cur_k2_97 = ttg.local_load %kv2_transpose#3 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> -> tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc459)
    %qk_98 = tt.splat %sm_scale : f32 -> tensor<16x64xf32, #mma> loc(#loc460)
    %qk_99 = arith.mulf %qk_95, %qk_98 : tensor<16x64xf32, #mma> loc(#loc460)
    %mask_qk_n = arith.subi %split_kv_end_42, %c1_i32 : i32 loc(#loc461)
    %mask_qk_n_100 = arith.muli %mask_qk_n, %c64_i32 : i32 loc(#loc462)
    %mask_qk_n_101 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc463)
    %mask_qk_n_102 = tt.splat %mask_qk_n_100 : i32 -> tensor<64xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc464)
    %mask_qk_n_103 = arith.addi %mask_qk_n_102, %mask_qk_n_101 : tensor<64xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc464)
    %qk_104 = tt.expand_dims %mask_qk_n_103 {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x64xi32, #mma> loc(#loc465)
    %qk_105 = tt.splat %cur_batch_seq_len : i32 -> tensor<1x64xi32, #mma> loc(#loc466)
    %qk_106 = arith.cmpi slt, %qk_104, %qk_105 : tensor<1x64xi32, #mma> loc(#loc466)
    %qk_107 = tt.expand_dims %offs_om {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xi32, #mma> loc(#loc467)
    %qk_108 = arith.cmpi sge, %qk_107, %cst_4 : tensor<16x1xi32, #mma> loc(#loc468)
    %qk_109 = tt.broadcast %qk_106 : tensor<1x64xi1, #mma> -> tensor<16x64xi1, #mma> loc(#loc469)
    %qk_110 = tt.broadcast %qk_108 : tensor<16x1xi1, #mma> -> tensor<16x64xi1, #mma> loc(#loc469)
    %qk_111 = arith.andi %qk_109, %qk_110 : tensor<16x64xi1, #mma> loc(#loc469)
    %qk_112 = arith.select %qk_111, %qk_99, %cst_3 : tensor<16x64xi1, #mma>, tensor<16x64xf32, #mma> loc(#loc470)
    %n_e_max = "tt.reduce"(%qk_112) <{axis = 1 : i32}> ({
    ^bb0(%n_e_max_148: f32 loc(callsite(#loc at #loc471)), %n_e_max_149: f32 loc(callsite(#loc at #loc471))):
      %n_e_max_150 = arith.maxnumf %n_e_max_148, %n_e_max_149 : f32 loc(#loc534)
      tt.reduce.return %n_e_max_150 : f32 loc(#loc525)
    }) : (tensor<16x64xf32, #mma>) -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc525)
    %n_e_max_113 = ttg.convert_layout %n_e_max : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc472)
    %n_e_max_114 = arith.maxnumf %n_e_max_113, %kv2_transpose#5 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc473)
    %re_scale = arith.subf %kv2_transpose#5, %n_e_max_114 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc474)
    %re_scale_115 = arith.mulf %re_scale, %cst_2 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc475)
    %re_scale_116 = math.exp2 %re_scale_115 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc476)
    %p = tt.expand_dims %n_e_max_114 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc477)
    %p_117 = tt.broadcast %p : tensor<16x1xf32, #mma> -> tensor<16x64xf32, #mma> loc(#loc478)
    %p_118 = arith.subf %qk_112, %p_117 : tensor<16x64xf32, #mma> loc(#loc478)
    %p_119 = arith.mulf %p_118, %cst_1 : tensor<16x64xf32, #mma> loc(#loc479)
    %p_120 = math.exp2 %p_119 : tensor<16x64xf32, #mma> loc(#loc480)
    %5 = arith.truncf %p_120 : tensor<16x64xf32, #mma> to tensor<16x64xbf16, #mma> loc(#loc233)
    ttg.local_store %5, %smem_p : tensor<16x64xbf16, #mma> -> !ttg.memdesc<16x64xbf16, #shared1, #smem, mutable> loc(#loc234)
    %acc1 = tt.expand_dims %re_scale_116 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc481)
    %acc1_121 = tt.broadcast %acc1 : tensor<16x1xf32, #mma> -> tensor<16x256xf32, #mma> loc(#loc482)
    %acc1_122 = arith.mulf %kv2_transpose#0, %acc1_121 : tensor<16x256xf32, #mma> loc(#loc482)
    %acc2 = arith.mulf %kv2_transpose#1, %acc1_121 : tensor<16x256xf32, #mma> loc(#loc483)
    %e_sum_123 = arith.mulf %kv2_transpose#4, %re_scale_116 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc484)
    %e_sum_124 = "tt.reduce"(%p_120) <{axis = 1 : i32}> ({
    ^bb0(%e_sum_148: f32 loc(callsite(#loc at #loc485)), %e_sum_149: f32 loc(callsite(#loc at #loc485))):
      %e_sum_150 = arith.addf %e_sum_148, %e_sum_149 : f32 loc(#loc535)
      tt.reduce.return %e_sum_150 : f32 loc(#loc527)
    }) : (tensor<16x64xf32, #mma>) -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc527)
    %e_sum_125 = arith.addf %e_sum_123, %e_sum_124 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc486)
    rocdl.sched.barrier 0 loc(#loc241)
    %cur_p = ttg.local_load %smem_p : !ttg.memdesc<16x64xbf16, #shared1, #smem, mutable> -> tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc487)
    %acc1_126 = tt.dot %cur_p, %cur_k1_96, %acc1_122 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x256xf32, #mma> loc(#loc488)
    %acc2_127 = tt.dot %cur_p, %cur_k2_97, %acc2 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x256xf32, #mma> loc(#loc489)
    ttg.local_dealloc %kv2_transpose#2 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc245)
    ttg.local_dealloc %kv2_transpose#3 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc246)
    %acc = tt.join %acc1_126, %acc2_127 : tensor<16x256xf32, #mma> -> tensor<16x256x2xf32, #linear> loc(#loc490)
    %acc_128 = tt.trans %acc {order = array<i32: 0, 2, 1>} : tensor<16x256x2xf32, #linear> -> tensor<16x2x256xf32, #linear1> loc(#loc491)
    %acc_129 = tt.reshape %acc_128 : tensor<16x2x256xf32, #linear1> -> tensor<16x512xf32, #linear2> loc(#loc492)
    %acc_130 = ttg.convert_layout %acc_129 : tensor<16x512xf32, #linear2> -> tensor<16x512xf32, #mma> loc(#loc493)
    %smem_o = ttg.local_alloc : () -> !ttg.memdesc<16x512xf32, #shared, #smem, mutable> loc(#loc494)
    %e_sum_131 = arith.divf %cst_0, %e_sum_125 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc495)
    %6 = tt.expand_dims %e_sum_131 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc253)
    %7 = tt.broadcast %6 : tensor<16x1xf32, #mma> -> tensor<16x512xf32, #mma> loc(#loc254)
    %8 = arith.mulf %acc_130, %7 : tensor<16x512xf32, #mma> loc(#loc254)
    ttg.local_store %8, %smem_o : tensor<16x512xf32, #mma> -> !ttg.memdesc<16x512xf32, #shared, #smem, mutable> loc(#loc255)
    %cur_o = ttg.local_load %smem_o : !ttg.memdesc<16x512xf32, #shared, #smem, mutable> -> tensor<16x512xf32, #blocked3> loc(#loc496)
    %offs_mid_o = arith.muli %cur_batch_18, %stride_mid_ob : i32 loc(#loc497)
    %offs_mid_o_132 = tt.splat %stride_mid_oh : i32 -> tensor<16x1xi32, #blocked3> loc(#loc498)
    %offs_mid_o_133 = arith.muli %offs_q, %offs_mid_o_132 : tensor<16x1xi32, #blocked3> loc(#loc498)
    %offs_mid_o_134 = tt.splat %offs_mid_o : i32 -> tensor<16x1xi32, #blocked3> loc(#loc499)
    %offs_mid_o_135 = arith.addi %offs_mid_o_134, %offs_mid_o_133 : tensor<16x1xi32, #blocked3> loc(#loc499)
    %offs_mid_o_136 = arith.muli %split_kv_id, %stride_mid_os : i32 loc(#loc500)
    %offs_mid_o_137 = tt.splat %offs_mid_o_136 : i32 -> tensor<16x1xi32, #blocked3> loc(#loc501)
    %offs_mid_o_138 = arith.addi %offs_mid_o_135, %offs_mid_o_137 : tensor<16x1xi32, #blocked3> loc(#loc501)
    %offs_mid_o_139 = tt.broadcast %offs_mid_o_138 : tensor<16x1xi32, #blocked3> -> tensor<16x512xi32, #blocked3> loc(#loc502)
    %offs_mid_o_140 = arith.addi %offs_mid_o_139, %offs_q_38 : tensor<16x512xi32, #blocked3> loc(#loc502)
    amdgpu.buffer_store %cur_o, %Att_Out[%offs_mid_o_140], %q_46 : tensor<16x512xf32, #blocked3> loc(#loc263)
    %offs_mid_lse = arith.muli %cur_batch_18, %stride_mid_lse_b : i32 loc(#loc503)
    %offs_mid_lse_141 = tt.splat %stride_mid_lse_h : i32 -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc504)
    %offs_mid_lse_142 = arith.muli %offs_om, %offs_mid_lse_141 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc504)
    %offs_mid_lse_143 = tt.splat %offs_mid_lse : i32 -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc505)
    %offs_mid_lse_144 = arith.addi %offs_mid_lse_143, %offs_mid_lse_142 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc505)
    %offs_mid_lse_145 = arith.muli %split_kv_id, %stride_mid_lse_s : i32 loc(#loc506)
    %offs_mid_lse_146 = tt.splat %offs_mid_lse_145 : i32 -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc507)
    %offs_mid_lse_147 = arith.addi %offs_mid_lse_144, %offs_mid_lse_146 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc507)
    %mask_lse = arith.cmpi slt, %offs_om, %cst : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc508)
    %9 = math.log %e_sum_131 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc270)
    %10 = arith.subf %n_e_max_114, %9 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc271)
    amdgpu.buffer_store %10, %Att_Lse[%offs_mid_lse_147], %mask_lse : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc272)
    tt.return loc(#loc273)
  } loc(#loc1)
} loc(#loc)
#loc2 = loc("/workspace/triton/python/triton/language/standard.py":41:22)
#loc3 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":240:53)
#loc4 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":228:54)
#loc5 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":75:24)
#loc6 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":78:31)
#loc7 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":39:16)
#loc8 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":79:54)
#loc9 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":40:23)
#loc10 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":45:13)
#loc11 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":45:7)
#loc12 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":46:35)
#loc13 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":51:14)
#loc14 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":82:58)
#loc15 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":86:25)
#loc16 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":86:60)
#loc17 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":89:49)
#loc18 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":89:37)
#loc19 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":90:62)
#loc20 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":90:35)
#loc21 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":136:27)
#loc22 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":139:27)
#loc23 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":142:27)
#loc24 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":146:27)
#loc25 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":176:11)
#loc26 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":178:24)
#loc27 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":182:11)
#loc28 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":186:11)
#loc29 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":190:11)
#loc30 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":192:30)
#loc31 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":196:11)
#loc32 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":200:11)
#loc33 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":211:8)
#loc34 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":219:11)
#loc35 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":223:8)
#loc36 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":227:47)
#loc37 = loc("/workspace/triton/python/triton/language/standard.py":41:28)
#loc38 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":231:20)
#loc39 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":231:44)
#loc40 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":231:55)
#loc41 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":231:32)
#loc42 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":231:77)
#loc43 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":231:67)
#loc44 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":233:46)
#loc45 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":233:57)
#loc46 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":233:37)
#loc47 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":233:76)
#loc48 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":233:69)
#loc49 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":235:22)
#loc50 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":236:26)
#loc51 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":237:29)
#loc52 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":238:27)
#loc53 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":241:40)
#loc54 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":247:24)
#loc55 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":247:42)
#loc56 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":248:8)
#loc57 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":250:47)
#loc58 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":250:65)
#loc59 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":255:21)
#loc60 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":255:41)
#loc61 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":255:34)
#loc62 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":255:8)
#loc63 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":260:24)
#loc64 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":260:47)
#loc65 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":260:37)
#loc66 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":260:8)
#loc67 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":263:21)
#loc68 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":263:50)
#loc69 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":263:38)
#loc70 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":263:8)
#loc71 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":269:22)
#loc72 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":270:22)
#loc73 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":271:22)
#loc74 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":273:23)
#loc75 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":274:23)
#loc76 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":275:27)
#loc77 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":276:27)
#loc78 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":278:22)
#loc79 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":279:28)
#loc80 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":281:4)
#loc81 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":282:4)
#loc82 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":283:4)
#loc83 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":289:34)
#loc84 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":302:20)
#loc85 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":302:38)
#loc86 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":303:51)
#loc87 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":304:25)
#loc88 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":305:24)
#loc89 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":305:36)
#loc90 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":305:61)
#loc91 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":305:52)
#loc92 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":313:20)
#loc93 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":313:40)
#loc94 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":313:31)
#loc95 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":313:8)
#loc96 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":318:30)
#loc97 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":319:8)
#loc98 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":326:34)
#loc99 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":329:34)
#loc100 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":332:31)
#loc101 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":334:19)
#loc102 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":335:19)
#loc103 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":337:41)
#loc104 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":338:28)
#loc105 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":338:39)
#loc106 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":338:64)
#loc107 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":338:55)
#loc108 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":339:51)
#loc109 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":340:28)
#loc110 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":348:23)
#loc111 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":348:43)
#loc112 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":348:34)
#loc113 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":348:8)
#loc114 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":354:81)
#loc115 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":354:95)
#loc116 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":355:20)
#loc117 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":360:27)
#loc118 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":361:27)
#loc119 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":363:31)
#loc120 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":365:34)
#loc121 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":367:31)
#loc122 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":369:19)
#loc123 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":371:34)
#loc124 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":373:31)
#loc125 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":375:19)
#loc126 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":377:22)
#loc127 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":378:31)
#loc128 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":379:22)
#loc129 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":386:41)
#loc130 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":388:25)
#loc131 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":388:35)
#loc132 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":388:12)
#loc133 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":391:36)
#loc134 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":393:35)
#loc135 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":394:24)
#loc136 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":394:42)
#loc137 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":395:27)
#loc138 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":395:38)
#loc139 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":395:54)
#loc140 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":396:30)
#loc141 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":396:48)
#loc142 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":397:29)
#loc143 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":398:35)
#loc144 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":400:43)
#loc145 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":404:24)
#loc146 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":404:35)
#loc147 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":404:12)
#loc148 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":407:35)
#loc149 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":409:43)
#loc150 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":412:34)
#loc151 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":413:12)
#loc152 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":419:31)
#loc153 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":420:31)
#loc154 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":422:47)
#loc155 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":424:14)
#loc156 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":435:45)
#loc157 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":436:32)
#loc158 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":436:43)
#loc159 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":436:59)
#loc160 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":437:48)
#loc161 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":438:32)
#loc162 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":440:35)
#loc163 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":444:27)
#loc164 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":444:38)
#loc165 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":444:12)
#loc166 = loc("/workspace/triton/python/triton/language/standard.py":189:40)
#loc168 = loc("/workspace/triton/python/triton/language/standard.py":168:27)
#loc169 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":451:51)
#loc170 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":452:38)
#loc171 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":454:41)
#loc172 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":454:52)
#loc173 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":454:32)
#loc174 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":455:39)
#loc175 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":455:31)
#loc176 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":455:51)
#loc177 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":455:25)
#loc178 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":456:26)
#loc179 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":456:21)
#loc180 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":457:35)
#loc181 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":459:28)
#loc182 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":461:38)
#loc183 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":463:38)
#loc184 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":465:23)
#loc185 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":466:31)
#loc186 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":466:22)
#loc187 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":467:48)
#loc188 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":468:24)
#loc189 = loc("/workspace/triton/python/triton/language/standard.py":291:36)
#loc191 = loc("/workspace/triton/python/triton/language/standard.py":261:15)
#loc192 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":468:35)
#loc193 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":470:23)
#loc194 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":471:22)
#loc195 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":472:48)
#loc196 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":473:26)
#loc197 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":476:31)
#loc198 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":478:35)
#loc199 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":480:38)
#loc200 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":482:23)
#loc201 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":483:31)
#loc202 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":486:35)
#loc203 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":488:38)
#loc204 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":489:23)
#loc205 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":489:8)
#loc206 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":501:39)
#loc207 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":502:39)
#loc208 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":504:32)
#loc209 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":506:43)
#loc210 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":511:27)
#loc211 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":512:27)
#loc212 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":514:10)
#loc213 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":517:32)
#loc214 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":517:37)
#loc215 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":517:77)
#loc216 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":517:55)
#loc217 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":520:19)
#loc218 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":520:30)
#loc219 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":520:62)
#loc220 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":520:74)
#loc221 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":520:52)
#loc222 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":520:82)
#loc224 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":525:47)
#loc225 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":527:34)
#loc226 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":528:37)
#loc227 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":528:48)
#loc228 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":528:28)
#loc229 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":529:35)
#loc230 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":529:27)
#loc231 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":529:47)
#loc232 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":529:21)
#loc233 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":534:22)
#loc234 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":534:17)
#loc235 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":536:27)
#loc236 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":536:18)
#loc237 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":537:18)
#loc238 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":538:20)
#loc240 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":538:31)
#loc241 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":539:31)
#loc242 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":540:24)
#loc243 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":543:44)
#loc244 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":544:44)
#loc245 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":546:4)
#loc246 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":547:4)
#loc247 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":549:24)
#loc248 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":550:27)
#loc249 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":551:26)
#loc250 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":552:33)
#loc251 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":558:33)
#loc252 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":561:16)
#loc253 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":562:29)
#loc254 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":562:23)
#loc255 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":562:17)
#loc256 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":564:24)
#loc257 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":567:20)
#loc258 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":568:30)
#loc259 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":568:10)
#loc260 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":569:24)
#loc261 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":569:10)
#loc262 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":570:10)
#loc263 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":583:8)
#loc264 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":587:20)
#loc265 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":588:20)
#loc266 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":588:10)
#loc267 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":589:24)
#loc268 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":589:10)
#loc269 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":592:25)
#loc270 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":594:36)
#loc271 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":594:29)
#loc272 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":597:8)
#loc273 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":593:4)
#loc293 = loc("blocks_per_split"(#loc3))
#loc294 = loc("cur_batch_block_nums"(#loc4))
#loc295 = loc("pid"(#loc5))
#loc296 = loc("pid_head_kv_split"(#loc6))
#loc297 = loc("xcd"(#loc7))
#loc298 = loc("pid_head_kv_split"(#loc8))
#loc299 = loc("local_pid"(#loc9))
#loc300 = loc("pid"(#loc12))
#loc301 = loc("pid"(#loc13))
#loc302 = loc("split_kv_id"(#loc14))
#loc303 = loc("cur_batch"(#loc15))
#loc304 = loc("cur_batch"(#loc16))
#loc305 = loc("cur_batch_kv_start_idx"(#loc17))
#loc306 = loc("cur_batch_kv_start_idx"(#loc18))
#loc307 = loc("cur_batch_kv_end_idx"(#loc19))
#loc308 = loc("cur_batch_kv_end_idx"(#loc20))
#loc309 = loc("smem_q0_nope"(#loc21))
#loc310 = loc("smem_q1_nope"(#loc22))
#loc311 = loc("smem_q_rope"(#loc23))
#loc312 = loc("smem_p"(#loc24))
#loc313 = loc("cur_head"(#loc25))
#loc314 = loc("mask_h"(#loc26))
#loc315 = loc("cur_N"(#loc27))
#loc316 = loc("cur_N_pe"(#loc28))
#loc317 = loc("cur_head_pe"(#loc29))
#loc318 = loc("mask_h_pe"(#loc30))
#loc319 = loc("offs_c"(#loc31))
#loc320 = loc("offs_om"(#loc32))
#loc321 = loc("offs_qk_r"(#loc33))
#loc322 = loc("offs_k_c"(#loc34))
#loc323 = loc("offs_k_r"(#loc35))
#loc324 = loc("cur_batch_seq_len"(#loc36))
#loc325 = loc("off_q_pe"(#loc38))
#loc326 = loc("off_q_pe"(#loc39))
#loc327 = loc("off_q_pe"(#loc40))
#loc328 = loc("off_q_pe"(#loc41))
#loc329 = loc("off_q_pe"(#loc42))
#loc330 = loc("off_q_pe"(#loc43))
#loc331 = loc("offs_q"(#loc44))
#loc332 = loc("offs_q"(#loc45))
#loc333 = loc("offs_q"(#loc46))
#loc334 = loc("offs_q"(#loc47))
#loc335 = loc("offs_q"(#loc48))
#loc336 = loc("mask_c"(#loc49))
#loc337 = loc("mask_k_c"(#loc50))
#loc338 = loc("mask_qk_r"(#loc51))
#loc339 = loc("mask_k_r"(#loc52))
#loc340 = loc("split_kv_start"(#loc53))
#loc341 = loc("split_kv_end"(#loc57))
#loc342 = loc("split_kv_end"(#loc58))
#loc343 = loc("q"(#loc59))
#loc344 = loc("q"(#loc60))
#loc345 = loc("q"(#loc61))
#loc346 = loc("q"(#loc62))
#loc347 = loc("q_pe"(#loc63))
#loc348 = loc("q_pe"(#loc64))
#loc349 = loc("q_pe"(#loc65))
#loc350 = loc("q_pe"(#loc66))
#loc351 = loc("kv_loc"(#loc67))
#loc352 = loc("kv_loc"(#loc68))
#loc353 = loc("kv_loc"(#loc69))
#loc354 = loc("kv_loc"(#loc70))
#loc355 = loc("q"(#loc71))
#loc356 = loc("q"(#loc72))
#loc357 = loc("q0"(#loc76))
#loc358 = loc("q1"(#loc77))
#loc359 = loc("q_pe"(#loc79))
#loc360 = loc("smem_k_rope"(#loc83))
#loc361 = loc("k_id"(#loc84))
#loc362 = loc("k_id"(#loc85))
#loc363 = loc("mask_k_id"(#loc86))
#loc364 = loc("mask_k"(#loc87))
#loc365 = loc("offs_buf_kv"(#loc88))
#loc366 = loc("offs_buf_kv"(#loc89))
#loc367 = loc("offs_buf_kv"(#loc90))
#loc368 = loc("offs_buf_kv"(#loc91))
#loc369 = loc("kv1"(#loc92))
#loc370 = loc("kv1"(#loc93))
#loc371 = loc("kv1"(#loc94))
#loc372 = loc("kv1"(#loc95))
#loc373 = loc("kv2"(#loc96))
#loc374 = loc("kv2"(#loc97))
#loc375 = loc("smem_kv1"(#loc98))
#loc376 = loc("smem_kv2"(#loc99))
#loc377 = loc("k_id_pe"(#loc103))
#loc378 = loc("offs_buf_k_pe"(#loc104))
#loc379 = loc("offs_buf_k_pe"(#loc105))
#loc380 = loc("offs_buf_k_pe"(#loc106))
#loc381 = loc("offs_buf_k_pe"(#loc107))
#loc382 = loc("mask_k_id"(#loc108))
#loc383 = loc("mask_k_pe"(#loc109))
#loc384 = loc("k_pe"(#loc110))
#loc385 = loc("k_pe"(#loc111))
#loc386 = loc("k_pe"(#loc112))
#loc387 = loc("k_pe"(#loc113))
#loc388 = loc("e_sum"(#loc114))
#loc389 = loc("e_sum"(#loc115))
#loc390 = loc("e_max"(#loc116))
#loc391 = loc("cur_k1"(#loc117))
#loc392 = loc("cur_k2"(#loc118))
#loc393 = loc("smem_kv1"(#loc120))
#loc394 = loc("smem_kv2"(#loc123))
#loc395 = loc("split_kv_start"(#loc128))
#loc396 = loc("kv_loc"(#loc129))
#loc397 = loc("kv_loc"(#loc130))
#loc398 = loc("kv_loc"(#loc131))
#loc399 = loc("kv_loc"(#loc132))
#loc400 = loc("cur_k_pe"(#loc133))
#loc401 = loc("k_id"(#loc135))
#loc402 = loc("k_id"(#loc136))
#loc403 = loc("offs_buf_kv"(#loc137))
#loc404 = loc("offs_buf_kv"(#loc138))
#loc405 = loc("offs_buf_kv"(#loc139))
#loc406 = loc("mask_k_id"(#loc140))
#loc407 = loc("mask_k_id"(#loc141))
#loc408 = loc("mask_k"(#loc142))
#loc409 = loc("qk"(#loc144))
#loc410 = loc("kv1"(#loc145))
#loc411 = loc("kv1"(#loc146))
#loc412 = loc("kv1"(#loc147))
#loc413 = loc("qk"(#loc149))
#loc414 = loc("kv2"(#loc150))
#loc415 = loc("kv2"(#loc151))
#loc416 = loc("cur_k1"(#loc152))
#loc417 = loc("cur_k2"(#loc153))
#loc418 = loc("qk"(#loc154))
#loc419 = loc("qk"(#loc155))
#loc420 = loc("k_id_pe"(#loc156))
#loc421 = loc("offs_buf_k_pe"(#loc157))
#loc422 = loc("offs_buf_k_pe"(#loc158))
#loc423 = loc("offs_buf_k_pe"(#loc159))
#loc424 = loc("mask_k_id"(#loc160))
#loc425 = loc("mask_k_pe"(#loc161))
#loc426 = loc("k_pe"(#loc163))
#loc427 = loc("k_pe"(#loc164))
#loc428 = loc("k_pe"(#loc165))
#loc430 = loc("n_e_max"(#loc169))
#loc431 = loc("n_e_max"(#loc170))
#loc432 = loc("re_scale"(#loc171))
#loc433 = loc("re_scale"(#loc172))
#loc434 = loc("re_scale"(#loc173))
#loc435 = loc("p"(#loc174))
#loc436 = loc("p"(#loc175))
#loc437 = loc("p"(#loc176))
#loc438 = loc("p"(#loc177))
#loc439 = loc("cur_p"(#loc181))
#loc440 = loc("smem_kv1"(#loc182))
#loc441 = loc("smem_kv2"(#loc183))
#loc442 = loc("acc1"(#loc185))
#loc443 = loc("acc1"(#loc186))
#loc444 = loc("acc1"(#loc187))
#loc445 = loc("e_sum"(#loc188))
#loc447 = loc("e_sum"(#loc192))
#loc448 = loc("acc2"(#loc194))
#loc449 = loc("acc2"(#loc195))
#loc450 = loc("cur_k1"(#loc197))
#loc451 = loc("smem_kv1"(#loc199))
#loc452 = loc("cur_k2"(#loc201))
#loc453 = loc("smem_kv2"(#loc203))
#loc454 = loc("qk"(#loc206))
#loc455 = loc("qk"(#loc207))
#loc456 = loc("cur_k_pe"(#loc208))
#loc457 = loc("qk"(#loc209))
#loc458 = loc("cur_k1"(#loc210))
#loc459 = loc("cur_k2"(#loc211))
#loc460 = loc("qk"(#loc212))
#loc461 = loc("mask_qk_n"(#loc213))
#loc462 = loc("mask_qk_n"(#loc214))
#loc463 = loc("mask_qk_n"(#loc215))
#loc464 = loc("mask_qk_n"(#loc216))
#loc465 = loc("qk"(#loc217))
#loc466 = loc("qk"(#loc218))
#loc467 = loc("qk"(#loc219))
#loc468 = loc("qk"(#loc220))
#loc469 = loc("qk"(#loc221))
#loc470 = loc("qk"(#loc222))
#loc472 = loc("n_e_max"(#loc224))
#loc473 = loc("n_e_max"(#loc225))
#loc474 = loc("re_scale"(#loc226))
#loc475 = loc("re_scale"(#loc227))
#loc476 = loc("re_scale"(#loc228))
#loc477 = loc("p"(#loc229))
#loc478 = loc("p"(#loc230))
#loc479 = loc("p"(#loc231))
#loc480 = loc("p"(#loc232))
#loc481 = loc("acc1"(#loc235))
#loc482 = loc("acc1"(#loc236))
#loc483 = loc("acc2"(#loc237))
#loc484 = loc("e_sum"(#loc238))
#loc486 = loc("e_sum"(#loc240))
#loc487 = loc("cur_p"(#loc242))
#loc488 = loc("acc1"(#loc243))
#loc489 = loc("acc2"(#loc244))
#loc490 = loc("acc"(#loc247))
#loc491 = loc("acc"(#loc248))
#loc492 = loc("acc"(#loc249))
#loc493 = loc("acc"(#loc250))
#loc494 = loc("smem_o"(#loc251))
#loc495 = loc("e_sum"(#loc252))
#loc496 = loc("cur_o"(#loc256))
#loc497 = loc("offs_mid_o"(#loc257))
#loc498 = loc("offs_mid_o"(#loc258))
#loc499 = loc("offs_mid_o"(#loc259))
#loc500 = loc("offs_mid_o"(#loc260))
#loc501 = loc("offs_mid_o"(#loc261))
#loc502 = loc("offs_mid_o"(#loc262))
#loc503 = loc("offs_mid_lse"(#loc264))
#loc504 = loc("offs_mid_lse"(#loc265))
#loc505 = loc("offs_mid_lse"(#loc266))
#loc506 = loc("offs_mid_lse"(#loc267))
#loc507 = loc("offs_mid_lse"(#loc268))
#loc508 = loc("mask_lse"(#loc269))
#loc509 = loc(callsite(#loc2 at #loc293))
#loc510 = loc(callsite(#loc2 at #loc294))
#loc511 = loc(callsite(#loc297 at #loc298))
#loc512 = loc(callsite(#loc299 at #loc298))
#loc513 = loc(callsite(#loc10 at #loc298))
#loc514 = loc(callsite(#loc11 at #loc298))
#loc515 = loc("pid"(#loc300))
#loc516 = loc("pid"(#loc301))
#loc517 = loc(callsite(#loc301 at #loc298))
#loc518 = loc(callsite(#loc37 at #loc294))
#loc519 = loc(callsite(#loc37 at #loc293))
#loc520 = loc("acc1"(#loc396))
#loc521 = loc(callsite(#loc166 at #loc429))
#loc523 = loc(callsite(#loc189 at #loc446))
#loc525 = loc(callsite(#loc166 at #loc471))
#loc527 = loc(callsite(#loc189 at #loc485))
#loc529 = loc(callsite(#loc515 at #loc298))
#loc530 = loc(callsite(#loc516 at #loc298))
#loc531 = loc("acc2"(#loc520))
#loc532 = loc(callsite(#loc168 at #loc521))
#loc533 = loc(callsite(#loc191 at #loc523))
#loc534 = loc(callsite(#loc168 at #loc525))
#loc535 = loc(callsite(#loc191 at #loc527))
#loc536 = loc("k_id"(#loc531))
#loc537 = loc("mask_k_id"(#loc536))
#loc538 = loc("mask_k"(#loc537))
#loc539 = loc("offs_buf_kv"(#loc538))
#loc540 = loc("kv1"(#loc539))
#loc541 = loc("kv2"(#loc540))
#loc542 = loc("smem_kv1"(#loc541))
#loc543 = loc("smem_kv2"(#loc542))
#loc544 = loc("k_id_pe"(#loc543))
#loc545 = loc("offs_buf_k_pe"(#loc544))
#loc546 = loc("mask_k_pe"(#loc545))
#loc547 = loc("k_pe"(#loc546))
#loc548 = loc("e_sum"(#loc547))
#loc549 = loc("e_max"(#loc548))
#loc550 = loc("cur_k1"(#loc549))
#loc551 = loc("cur_k2"(#loc550))
#loc552 = loc("kv1_transpose"(#loc551))
#loc553 = loc("kv2_transpose"(#loc552))
