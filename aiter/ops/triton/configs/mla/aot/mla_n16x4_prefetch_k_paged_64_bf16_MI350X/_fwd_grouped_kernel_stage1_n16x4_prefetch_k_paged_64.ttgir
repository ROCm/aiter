#blocked = #ttg.blocked<{sizePerThread = [4, 16], threadsPerWarp = [16, 4], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 16], threadsPerWarp = [64, 1], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [16, 4], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 16], threadsPerWarp = [16, 4], warpsPerCTA = [1, 4], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1, 16], threadsPerWarp = [16, 1, 4], warpsPerCTA = [1, 1, 4], order = [2, 1, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [1, 16, 1], threadsPerWarp = [16, 4, 1], warpsPerCTA = [1, 4, 1], order = [1, 2, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [16, 4], threadsPerWarp = [4, 16], warpsPerCTA = [4, 1], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [16, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [0, 1]}>
#linear = #ttg.linear<{register = [[0, 0, 1], [0, 1, 0], [0, 2, 0], [0, 64, 0], [0, 128, 0]], lane = [[1, 0, 0], [2, 0, 0], [4, 0, 0], [8, 0, 0], [0, 4, 0], [0, 8, 0]], warp = [[0, 16, 0], [0, 32, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1, 0], [0, 0, 1], [0, 0, 2], [0, 0, 64], [0, 0, 128]], lane = [[1, 0, 0], [2, 0, 0], [4, 0, 0], [8, 0, 0], [0, 0, 4], [0, 0, 8]], warp = [[0, 0, 16], [0, 0, 32]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 256], [0, 1], [0, 2], [0, 64], [0, 128]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [0, 4], [0, 8]], warp = [[0, 16], [0, 32]], block = []}>
#loc = loc(unknown)
#loc1 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":40:0)
#loc166 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":427:47)
#loc189 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":444:45)
#loc222 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":486:43)
#loc238 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":496:41)
#mma = #ttg.amd_mfma<{version = 3, warpsPerCTA = [1, 4], instrShape = [16, 16, 16], isTransposed = true}>
#shared = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 8, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 16, order = [1, 0]}>
#shared2 = #ttg.swizzled_shared<{vec = 16, perPhase = 1, maxPhase = 16, order = [0, 1]}>
#smem = #ttg.shared_memory
#loc273 = loc("Q"(#loc1))
#loc274 = loc("K_Buffer"(#loc1))
#loc275 = loc("V_buffer"(#loc1))
#loc276 = loc("sm_scale"(#loc1))
#loc277 = loc("kv_indptr"(#loc1))
#loc278 = loc("kv_indices"(#loc1))
#loc279 = loc("Att_Out"(#loc1))
#loc280 = loc("Att_Lse"(#loc1))
#loc281 = loc("stride_qb"(#loc1))
#loc282 = loc("stride_qh"(#loc1))
#loc283 = loc("stride_buf_kbs"(#loc1))
#loc284 = loc("stride_buf_kh"(#loc1))
#loc285 = loc("stride_mid_ob"(#loc1))
#loc286 = loc("stride_mid_oh"(#loc1))
#loc287 = loc("stride_mid_os"(#loc1))
#loc288 = loc("stride_mid_lse_b"(#loc1))
#loc289 = loc("stride_mid_lse_h"(#loc1))
#loc290 = loc("stride_mid_lse_s"(#loc1))
#loc291 = loc("stride_b_block_table"(#loc1))
#loc427 = loc("n_e_max"(#loc166))
#loc444 = loc("e_sum"(#loc189))
#loc469 = loc("n_e_max"(#loc222))
#loc483 = loc("e_sum"(#loc238))
#loc520 = loc(callsite(#loc at #loc427))
#loc522 = loc(callsite(#loc at #loc444))
#loc524 = loc(callsite(#loc at #loc469))
#loc526 = loc(callsite(#loc at #loc483))
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_fwd_grouped_kernel_stage1_n16x4_prefetch_k_paged_64(%Q: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("Q"(#loc1)), %K_Buffer: !tt.ptr<bf16> {tt.divisibility = 16 : i32} loc("K_Buffer"(#loc1)), %V_buffer: !tt.ptr<bf16> {tt.divisibility = 16 : i32} loc("V_buffer"(#loc1)), %sm_scale: f32 {tt.divisibility = 16 : i32} loc("sm_scale"(#loc1)), %kv_indptr: !tt.ptr<i32> {tt.divisibility = 16 : i32} loc("kv_indptr"(#loc1)), %kv_indices: !tt.ptr<i32> {tt.divisibility = 16 : i32} loc("kv_indices"(#loc1)), %Att_Out: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("Att_Out"(#loc1)), %Att_Lse: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("Att_Lse"(#loc1)), %stride_qb: i32 {tt.divisibility = 16 : i32} loc("stride_qb"(#loc1)), %stride_qh: i32 {tt.divisibility = 16 : i32} loc("stride_qh"(#loc1)), %stride_buf_kbs: i32 {tt.divisibility = 16 : i32} loc("stride_buf_kbs"(#loc1)), %stride_buf_kh: i32 {tt.divisibility = 16 : i32} loc("stride_buf_kh"(#loc1)), %stride_mid_ob: i32 {tt.divisibility = 16 : i32} loc("stride_mid_ob"(#loc1)), %stride_mid_oh: i32 {tt.divisibility = 16 : i32} loc("stride_mid_oh"(#loc1)), %stride_mid_os: i32 {tt.divisibility = 16 : i32} loc("stride_mid_os"(#loc1)), %stride_mid_lse_b: i32 loc("stride_mid_lse_b"(#loc1)), %stride_mid_lse_h: i32 loc("stride_mid_lse_h"(#loc1)), %stride_mid_lse_s: i32 loc("stride_mid_lse_s"(#loc1)), %stride_b_block_table: i32 loc("stride_b_block_table"(#loc1))) attributes {noinline = false} {
    %blocks_per_split = arith.constant 7 : i32 loc(#loc507)
    %cur_batch_block_nums = arith.constant 63 : i32 loc(#loc508)
    %cst = arith.constant dense<8> : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_0 = arith.constant dense<1.000000e+00> : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_1 = arith.constant dense<1.44269502> : tensor<16x64xf32, #mma> loc(#loc)
    %cst_2 = arith.constant dense<1.44269502> : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_3 = arith.constant dense<0xFF800000> : tensor<16x64xf32, #mma> loc(#loc)
    %cst_4 = arith.constant dense<0> : tensor<16x1xi32, #mma> loc(#loc)
    %cst_5 = arith.constant dense<0x7F800000> : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_7 = arith.constant dense<256> : tensor<64x256xi32, #blocked> loc(#loc)
    %cst_8 = arith.constant dense<0.000000e+00> : tensor<16x64xf32, #mma> loc(#loc)
    %cst_9 = arith.constant dense<0.000000e+00> : tensor<16x256xf32, #mma> loc(#loc)
    %cst_10 = arith.constant dense<576> : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc)
    %cst_11 = arith.constant dense<576> : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc)
    %cst_12 = arith.constant dense<512> : tensor<256xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %cst_13 = arith.constant dense<512> : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %cst_14 = arith.constant dense<8> : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc)
    %cst_15 = arith.constant dense<8> : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc)
    %c1_i32 = arith.constant 1 : i32 loc(#loc)
    %c512_i32 = arith.constant 512 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %pid = tt.get_program_id x : i32 loc(#loc294)
    %pid_head_kv_split = arith.remsi %pid, %c8_i32 : i32 loc(#loc295)
    %xcd = arith.remsi %pid_head_kv_split, %c8_i32 : i32 loc(#loc509)
    %local_pid = arith.divsi %pid_head_kv_split, %c8_i32 : i32 loc(#loc510)
    %pid_head_kv_split_16 = arith.cmpi slt, %xcd, %c8_i32 : i32 loc(#loc511)
    %pid_head_kv_split_17 = scf.if %pid_head_kv_split_16 -> (i32) {
      %pid_141 = arith.addi %xcd, %local_pid : i32 loc(#loc527)
      scf.yield %pid_141 : i32 loc(#loc527)
    } else {
      %pid_141 = arith.addi %local_pid, %c8_i32 : i32 loc(#loc528)
      scf.yield %pid_141 : i32 loc(#loc515)
    } loc(#loc512)
    %split_kv_id = arith.remsi %pid_head_kv_split_17, %c8_i32 : i32 loc(#loc301)
    %cur_batch = arith.divsi %pid, %c8_i32 : i32 loc(#loc302)
    %cur_batch_18 = arith.remsi %cur_batch, %c512_i32 : i32 loc(#loc303)
    %kv_indptr_base = tt.addptr %kv_indptr, %cur_batch_18 : !tt.ptr<i32>, i32 loc(#loc304)
    %cur_batch_kv_start_idx = tt.load %kv_indptr_base : !tt.ptr<i32> loc(#loc305)
    %cur_batch_kv_end_idx = tt.addptr %kv_indptr_base, %c1_i32 : !tt.ptr<i32>, i32 loc(#loc306)
    %cur_batch_kv_end_idx_19 = tt.load %cur_batch_kv_end_idx : !tt.ptr<i32> loc(#loc307)
    %smem_q0_nope = ttg.local_alloc : () -> !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc308)
    %smem_q1_nope = ttg.local_alloc : () -> !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc309)
    %smem_q_rope = ttg.local_alloc : () -> !ttg.memdesc<16x64xbf16, #shared, #smem, mutable> loc(#loc310)
    %smem_p = ttg.local_alloc : () -> !ttg.memdesc<16x64xbf16, #shared1, #smem, mutable> loc(#loc311)
    %cur_head = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc312)
    %mask_h = arith.cmpi slt, %cur_head, %cst_15 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc313)
    %cur_N = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc314)
    %cur_N_pe = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc315)
    %cur_head_pe = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc316)
    %mask_h_pe = arith.cmpi slt, %cur_head_pe, %cst_14 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc317)
    %offs_c = tt.make_range {end = 512 : i32, start = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc318)
    %offs_om = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc319)
    %offs_qk_r = tt.make_range {end = 576 : i32, start = 512 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc320)
    %offs_k_c = tt.make_range {end = 256 : i32, start = 0 : i32} : tensor<256xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc321)
    %offs_k_r = tt.make_range {end = 576 : i32, start = 512 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc322)
    %cur_batch_seq_len = arith.subi %cur_batch_kv_end_idx_19, %cur_batch_kv_start_idx : i32 loc(#loc323)
    %cur_batch_block_nums_20 = arith.addi %cur_batch_seq_len, %cur_batch_block_nums : i32 loc(#loc508)
    %cur_batch_block_nums_21 = arith.divsi %cur_batch_block_nums_20, %c64_i32 : i32 loc(#loc516)
    %cur_batch_offset = arith.muli %cur_batch_18, %stride_qb : i32 loc(#loc324)
    %off_q_pe = tt.expand_dims %cur_head_pe {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<16x1xi32, #blocked2> loc(#loc325)
    %off_q_pe_22 = tt.splat %stride_qh : i32 -> tensor<16x1xi32, #blocked2> loc(#loc326)
    %off_q_pe_23 = arith.muli %off_q_pe, %off_q_pe_22 : tensor<16x1xi32, #blocked2> loc(#loc326)
    %off_q_pe_24 = tt.splat %cur_batch_offset : i32 -> tensor<16x1xi32, #blocked2> loc(#loc327)
    %off_q_pe_25 = arith.addi %off_q_pe_24, %off_q_pe_23 : tensor<16x1xi32, #blocked2> loc(#loc327)
    %off_q_pe_26 = tt.expand_dims %offs_qk_r {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x64xi32, #blocked2> loc(#loc328)
    %off_q_pe_27 = tt.broadcast %off_q_pe_25 : tensor<16x1xi32, #blocked2> -> tensor<16x64xi32, #blocked2> loc(#loc329)
    %off_q_pe_28 = tt.broadcast %off_q_pe_26 : tensor<1x64xi32, #blocked2> -> tensor<16x64xi32, #blocked2> loc(#loc329)
    %off_q_pe_29 = arith.addi %off_q_pe_27, %off_q_pe_28 : tensor<16x64xi32, #blocked2> loc(#loc329)
    %offs_q = tt.expand_dims %cur_head {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<16x1xi32, #blocked3> loc(#loc330)
    %offs_q_30 = tt.splat %stride_qh : i32 -> tensor<16x1xi32, #blocked3> loc(#loc331)
    %offs_q_31 = arith.muli %offs_q, %offs_q_30 : tensor<16x1xi32, #blocked3> loc(#loc331)
    %offs_q_32 = tt.splat %cur_batch_offset : i32 -> tensor<16x1xi32, #blocked3> loc(#loc332)
    %offs_q_33 = arith.addi %offs_q_32, %offs_q_31 : tensor<16x1xi32, #blocked3> loc(#loc332)
    %offs_q_34 = tt.expand_dims %offs_c {axis = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x512xi32, #blocked3> loc(#loc333)
    %offs_q_35 = tt.broadcast %offs_q_33 : tensor<16x1xi32, #blocked3> -> tensor<16x512xi32, #blocked3> loc(#loc334)
    %offs_q_36 = tt.broadcast %offs_q_34 : tensor<1x512xi32, #blocked3> -> tensor<16x512xi32, #blocked3> loc(#loc334)
    %offs_q_37 = arith.addi %offs_q_35, %offs_q_36 : tensor<16x512xi32, #blocked3> loc(#loc334)
    %mask_c = arith.cmpi slt, %offs_c, %cst_13 : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc335)
    %mask_k_c = arith.cmpi slt, %offs_k_c, %cst_12 : tensor<256xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc336)
    %mask_qk_r = arith.cmpi slt, %offs_qk_r, %cst_11 : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc337)
    %mask_k_r = arith.cmpi slt, %offs_k_r, %cst_10 : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc338)
    %blocks_per_split_38 = arith.addi %cur_batch_block_nums_21, %blocks_per_split : i32 loc(#loc507)
    %blocks_per_split_39 = arith.divsi %blocks_per_split_38, %c8_i32 : i32 loc(#loc517)
    %split_kv_start = arith.muli %blocks_per_split_39, %split_kv_id : i32 loc(#loc339)
    %0 = arith.muli %split_kv_start, %c64_i32 : i32 loc(#loc54)
    %1 = arith.cmpi sgt, %0, %cur_batch_seq_len : i32 loc(#loc55)
    cf.cond_br %1, ^bb1, ^bb2 loc(#loc55)
  ^bb1:  // pred: ^bb0
    tt.return loc(#loc56)
  ^bb2:  // pred: ^bb0
    cf.br ^bb3 loc(#loc)
  ^bb3:  // pred: ^bb2
    %split_kv_end = arith.addi %split_kv_start, %blocks_per_split_39 : i32 loc(#loc340)
    %split_kv_end_40 = arith.minsi %split_kv_end, %cur_batch_block_nums_21 : i32 loc(#loc341)
    %kv_indices_base = arith.muli %cur_batch_18, %stride_b_block_table : i32 loc(#loc342)
    %kv_indices_base_41 = tt.addptr %kv_indices, %kv_indices_base : !tt.ptr<i32>, i32 loc(#loc343)
    %q = tt.expand_dims %mask_h {axis = 1 : i32} : tensor<16xi1, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<16x1xi1, #blocked3> loc(#loc344)
    %q_42 = tt.expand_dims %mask_c {axis = 0 : i32} : tensor<512xi1, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x512xi1, #blocked3> loc(#loc345)
    %q_43 = tt.broadcast %q : tensor<16x1xi1, #blocked3> -> tensor<16x512xi1, #blocked3> loc(#loc346)
    %q_44 = tt.broadcast %q_42 : tensor<1x512xi1, #blocked3> -> tensor<16x512xi1, #blocked3> loc(#loc346)
    %q_45 = arith.andi %q_43, %q_44 : tensor<16x512xi1, #blocked3> loc(#loc346)
    %q_46 = amdgpu.buffer_load %Q[%offs_q_37], %q_45 : tensor<16x512xbf16, #blocked3> loc(#loc347)
    %q_pe = tt.expand_dims %mask_h_pe {axis = 1 : i32} : tensor<16xi1, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<16x1xi1, #blocked2> loc(#loc348)
    %q_pe_47 = tt.expand_dims %mask_qk_r {axis = 0 : i32} : tensor<64xi1, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x64xi1, #blocked2> loc(#loc349)
    %q_pe_48 = tt.broadcast %q_pe : tensor<16x1xi1, #blocked2> -> tensor<16x64xi1, #blocked2> loc(#loc350)
    %q_pe_49 = tt.broadcast %q_pe_47 : tensor<1x64xi1, #blocked2> -> tensor<16x64xi1, #blocked2> loc(#loc350)
    %q_pe_50 = arith.andi %q_pe_48, %q_pe_49 : tensor<16x64xi1, #blocked2> loc(#loc350)
    %q_pe_51 = amdgpu.buffer_load %Q[%off_q_pe_29], %q_pe_50 : tensor<16x64xbf16, #blocked2> loc(#loc351)
    %kv_loc = tt.addptr %kv_indices_base_41, %split_kv_start : !tt.ptr<i32>, i32 loc(#loc352)
    %kv_loc_52 = tt.load %kv_loc : !tt.ptr<i32> loc(#loc353)
    %q_53 = tt.reshape %q_46 : tensor<16x512xbf16, #blocked3> -> tensor<16x2x256xbf16, #blocked4> loc(#loc354)
    %q_54 = tt.trans %q_53 {order = array<i32: 0, 2, 1>} : tensor<16x2x256xbf16, #blocked4> -> tensor<16x256x2xbf16, #blocked5> loc(#loc355)
    %outLHS, %outRHS = tt.split %q_54 : tensor<16x256x2xbf16, #blocked5> -> tensor<16x256xbf16, #ttg.slice<{dim = 2, parent = #blocked5}>> loc(#loc73)
    ttg.local_store %outLHS, %smem_q0_nope : tensor<16x256xbf16, #ttg.slice<{dim = 2, parent = #blocked5}>> -> !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc74)
    ttg.local_store %outRHS, %smem_q1_nope : tensor<16x256xbf16, #ttg.slice<{dim = 2, parent = #blocked5}>> -> !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc75)
    %q0 = ttg.local_load %smem_q0_nope : !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> -> tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc356)
    %q1 = ttg.local_load %smem_q1_nope : !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> -> tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc357)
    ttg.local_store %q_pe_51, %smem_q_rope : tensor<16x64xbf16, #blocked2> -> !ttg.memdesc<16x64xbf16, #shared, #smem, mutable> loc(#loc78)
    %q_pe_55 = ttg.local_load %smem_q_rope : !ttg.memdesc<16x64xbf16, #shared, #smem, mutable> -> tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc358)
    ttg.local_dealloc %smem_q0_nope : !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc80)
    ttg.local_dealloc %smem_q1_nope : !ttg.memdesc<16x256xbf16, #shared, #smem, mutable> loc(#loc81)
    ttg.local_dealloc %smem_q_rope : !ttg.memdesc<16x64xbf16, #shared, #smem, mutable> loc(#loc82)
    %smem_k_rope = ttg.local_alloc : () -> !ttg.memdesc<64x64xbf16, #shared2, #smem, mutable> loc(#loc359)
    %k_id = arith.muli %kv_loc_52, %c64_i32 : i32 loc(#loc360)
    %k_id_56 = tt.splat %k_id : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc361)
    %k_id_57 = arith.addi %k_id_56, %cur_N : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc361)
    %mask_k_id = tt.splat %0 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc362)
    %mask_k_id_58 = arith.addi %mask_k_id, %cur_N : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc362)
    %mask_k = tt.splat %cur_batch_seq_len : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc363)
    %mask_k_59 = arith.cmpi slt, %mask_k_id_58, %mask_k : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc363)
    %offs_buf_kv = tt.expand_dims %k_id_57 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<64x1xi32, #blocked> loc(#loc364)
    %offs_buf_kv_60 = tt.splat %stride_buf_kh : i32 -> tensor<64x1xi32, #blocked> loc(#loc365)
    %offs_buf_kv_61 = arith.muli %offs_buf_kv, %offs_buf_kv_60 : tensor<64x1xi32, #blocked> loc(#loc365)
    %offs_buf_kv_62 = tt.expand_dims %offs_k_c {axis = 0 : i32} : tensor<256xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x256xi32, #blocked> loc(#loc366)
    %offs_buf_kv_63 = tt.broadcast %offs_buf_kv_61 : tensor<64x1xi32, #blocked> -> tensor<64x256xi32, #blocked> loc(#loc367)
    %offs_buf_kv_64 = tt.broadcast %offs_buf_kv_62 : tensor<1x256xi32, #blocked> -> tensor<64x256xi32, #blocked> loc(#loc367)
    %offs_buf_kv_65 = arith.addi %offs_buf_kv_63, %offs_buf_kv_64 : tensor<64x256xi32, #blocked> loc(#loc367)
    %mask_k_c_combined = tt.expand_dims %mask_k_59 {axis = 1 : i32} : tensor<64xi1, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<64x1xi1, #blocked> loc(#loc368)
    %mask_k_c_combined_66 = tt.expand_dims %mask_k_c {axis = 0 : i32} : tensor<256xi1, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x256xi1, #blocked> loc(#loc369)
    %mask_k_c_combined_67 = tt.broadcast %mask_k_c_combined : tensor<64x1xi1, #blocked> -> tensor<64x256xi1, #blocked> loc(#loc370)
    %mask_k_c_combined_68 = tt.broadcast %mask_k_c_combined_66 : tensor<1x256xi1, #blocked> -> tensor<64x256xi1, #blocked> loc(#loc370)
    %mask_k_c_combined_69 = arith.andi %mask_k_c_combined_67, %mask_k_c_combined_68 : tensor<64x256xi1, #blocked> loc(#loc370)
    %kv1 = amdgpu.buffer_load %K_Buffer[%offs_buf_kv_65], %mask_k_c_combined_69 : tensor<64x256xbf16, #blocked> loc(#loc371)
    %kv2 = arith.addi %offs_buf_kv_65, %cst_7 : tensor<64x256xi32, #blocked> loc(#loc372)
    %kv2_70 = amdgpu.buffer_load %K_Buffer[%kv2], %mask_k_c_combined_69 : tensor<64x256xbf16, #blocked> loc(#loc373)
    %smem_kv1 = ttg.local_alloc : () -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc374)
    %smem_kv2 = ttg.local_alloc : () -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc375)
    rocdl.sched.barrier 0 loc(#loc100)
    %2 = tt.trans %kv1 {order = array<i32: 1, 0>} : tensor<64x256xbf16, #blocked> -> tensor<256x64xbf16, #blocked6> loc(#loc101)
    ttg.local_store %2, %smem_kv1 : tensor<256x64xbf16, #blocked6> -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc101)
    %3 = tt.trans %kv2_70 {order = array<i32: 1, 0>} : tensor<64x256xbf16, #blocked> -> tensor<256x64xbf16, #blocked6> loc(#loc102)
    ttg.local_store %3, %smem_kv2 : tensor<256x64xbf16, #blocked6> -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc102)
    %k_id_pe = tt.splat %k_id : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc376)
    %k_id_pe_71 = arith.addi %k_id_pe, %cur_N_pe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc376)
    %offs_buf_k_pe = tt.expand_dims %k_id_pe_71 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<64x1xi32, #blocked1> loc(#loc377)
    %offs_buf_k_pe_72 = tt.splat %stride_buf_kh : i32 -> tensor<64x1xi32, #blocked1> loc(#loc378)
    %offs_buf_k_pe_73 = arith.muli %offs_buf_k_pe, %offs_buf_k_pe_72 : tensor<64x1xi32, #blocked1> loc(#loc378)
    %offs_buf_k_pe_74 = tt.expand_dims %offs_k_r {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x64xi32, #blocked1> loc(#loc379)
    %offs_buf_k_pe_75 = tt.broadcast %offs_buf_k_pe_73 : tensor<64x1xi32, #blocked1> -> tensor<64x64xi32, #blocked1> loc(#loc380)
    %offs_buf_k_pe_76 = tt.broadcast %offs_buf_k_pe_74 : tensor<1x64xi32, #blocked1> -> tensor<64x64xi32, #blocked1> loc(#loc380)
    %offs_buf_k_pe_77 = arith.addi %offs_buf_k_pe_75, %offs_buf_k_pe_76 : tensor<64x64xi32, #blocked1> loc(#loc380)
    %mask_k_id_78 = tt.splat %0 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc381)
    %mask_k_id_79 = arith.addi %mask_k_id_78, %cur_N_pe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc381)
    %mask_k_pe = tt.splat %cur_batch_seq_len : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc382)
    %mask_k_pe_80 = arith.cmpi slt, %mask_k_id_79, %mask_k_pe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc382)
    %mask_k_r_combined = tt.expand_dims %mask_k_pe_80 {axis = 1 : i32} : tensor<64xi1, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<64x1xi1, #blocked1> loc(#loc383)
    %mask_k_r_combined_81 = tt.expand_dims %mask_k_r {axis = 0 : i32} : tensor<64xi1, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x64xi1, #blocked1> loc(#loc384)
    %mask_k_r_combined_82 = tt.broadcast %mask_k_r_combined : tensor<64x1xi1, #blocked1> -> tensor<64x64xi1, #blocked1> loc(#loc385)
    %mask_k_r_combined_83 = tt.broadcast %mask_k_r_combined_81 : tensor<1x64xi1, #blocked1> -> tensor<64x64xi1, #blocked1> loc(#loc385)
    %mask_k_r_combined_84 = arith.andi %mask_k_r_combined_82, %mask_k_r_combined_83 : tensor<64x64xi1, #blocked1> loc(#loc385)
    %k_pe = amdgpu.buffer_load %K_Buffer[%offs_buf_k_pe_77], %mask_k_r_combined_84 : tensor<64x64xbf16, #blocked1> loc(#loc386)
    %e_sum = arith.sitofp %offs_om : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> to tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc387)
    %e_sum_85 = arith.mulf %e_sum, %cst_6 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc388)
    %e_max = arith.subf %e_sum_85, %cst_5 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc389)
    %cur_k1 = ttg.local_load %smem_kv1 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc390)
    %cur_k2 = ttg.local_load %smem_kv2 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc391)
    rocdl.sched.barrier 0 loc(#loc119)
    %smem_kv1_86 = ttg.memdesc_reinterpret %smem_kv1 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc392)
    rocdl.sched.barrier 0 loc(#loc121)
    ttg.local_store %kv1, %smem_kv1_86 : tensor<64x256xbf16, #blocked> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc122)
    %smem_kv2_87 = ttg.memdesc_reinterpret %smem_kv2 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc393)
    rocdl.sched.barrier 0 loc(#loc124)
    ttg.local_store %kv2_70, %smem_kv2_87 : tensor<64x256xbf16, #blocked> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc125)
    %4 = tt.trans %k_pe {order = array<i32: 1, 0>} : tensor<64x64xbf16, #blocked1> -> tensor<64x64xbf16, #blocked7> loc(#loc126)
    ttg.local_store %4, %smem_k_rope : tensor<64x64xbf16, #blocked7> -> !ttg.memdesc<64x64xbf16, #shared2, #smem, mutable> loc(#loc126)
    rocdl.sched.barrier 0 loc(#loc127)
    %split_kv_start_88 = arith.addi %split_kv_start, %c1_i32 : i32 loc(#loc394)
    %kv2_transpose:8 = scf.for %kv2_transpose_141 = %split_kv_start_88 to %split_kv_end_40 step %c1_i32 iter_args(%arg20 = %cst_9, %arg21 = %cst_9, %smem_kv1_142 = %smem_kv1_86, %smem_kv2_143 = %smem_kv2_87, %e_sum_144 = %e_sum_85, %e_max_145 = %e_max, %cur_k1_146 = %cur_k1, %cur_k2_147 = %cur_k2) -> (tensor<16x256xf32, #mma>, tensor<16x256xf32, #mma>, !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable>, !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable>, tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>>, tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>>)  : i32 {
      %kv_loc_148 = tt.addptr %kv_indices_base_41, %kv2_transpose_141 : !tt.ptr<i32>, i32 loc(#loc396)
      %kv_loc_149 = tt.load %kv_loc_148 : !tt.ptr<i32> loc(#loc397)
      %cur_k_pe_150 = ttg.local_load %smem_k_rope : !ttg.memdesc<64x64xbf16, #shared2, #smem, mutable> -> tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc398)
      rocdl.sched.barrier 0 loc(#loc133)
      %k_id_151 = arith.muli %kv_loc_149, %c64_i32 : i32 loc(#loc399)
      %k_id_152 = tt.splat %k_id_151 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc400)
      %k_id_153 = arith.addi %k_id_152, %cur_N : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc400)
      %offs_buf_kv_154 = tt.expand_dims %k_id_153 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<64x1xi32, #blocked> loc(#loc401)
      %offs_buf_kv_155 = arith.muli %offs_buf_kv_154, %offs_buf_kv_60 : tensor<64x1xi32, #blocked> loc(#loc402)
      %offs_buf_kv_156 = tt.broadcast %offs_buf_kv_155 : tensor<64x1xi32, #blocked> -> tensor<64x256xi32, #blocked> loc(#loc403)
      %offs_buf_kv_157 = arith.addi %offs_buf_kv_156, %offs_buf_kv_64 : tensor<64x256xi32, #blocked> loc(#loc403)
      %mask_k_id_158 = arith.muli %kv2_transpose_141, %c64_i32 : i32 loc(#loc404)
      %mask_k_id_159 = tt.splat %mask_k_id_158 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc405)
      %mask_k_id_160 = arith.addi %mask_k_id_159, %cur_N : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc405)
      %mask_k_161 = arith.cmpi slt, %mask_k_id_160, %mask_k : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc406)
      %mask_k_combined = tt.expand_dims %mask_k_161 {axis = 1 : i32} : tensor<64xi1, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<64x1xi1, #blocked> loc(#loc407)
      %mask_k_combined_162 = tt.broadcast %mask_k_combined : tensor<64x1xi1, #blocked> -> tensor<64x256xi1, #blocked> loc(#loc408)
      %mask_k_combined_163 = arith.andi %mask_k_combined_162, %mask_k_c_combined_68 : tensor<64x256xi1, #blocked> loc(#loc408)
      rocdl.sched.barrier 0 loc(#loc144)
      %qk_164 = tt.dot %q0, %cur_k1_146, %cst_8 : tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x64xf32, #mma> loc(#loc409)
      %kv1_165 = amdgpu.buffer_load %K_Buffer[%offs_buf_kv_157], %mask_k_combined_163 : tensor<64x256xbf16, #blocked> loc(#loc410)
      rocdl.sched.barrier 0 loc(#loc147)
      %qk_166 = tt.dot %q1, %cur_k2_147, %qk_164 : tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x64xf32, #mma> loc(#loc411)
      %kv2_167 = arith.addi %offs_buf_kv_157, %cst_7 : tensor<64x256xi32, #blocked> loc(#loc412)
      %kv2_168 = amdgpu.buffer_load %K_Buffer[%kv2_167], %mask_k_combined_163 : tensor<64x256xbf16, #blocked> loc(#loc413)
      %cur_k1_169 = ttg.local_load %smem_kv1_142 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> -> tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc414)
      %cur_k2_170 = ttg.local_load %smem_kv2_143 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> -> tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc415)
      %qk_171 = tt.dot %q_pe_55, %cur_k_pe_150, %qk_166 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x64xf32, #mma> loc(#loc416)
      %qk_172 = tt.splat %sm_scale : f32 -> tensor<16x64xf32, #mma> loc(#loc417)
      %qk_173 = arith.mulf %qk_171, %qk_172 : tensor<16x64xf32, #mma> loc(#loc417)
      %k_id_pe_174 = tt.splat %k_id_151 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc418)
      %k_id_pe_175 = arith.addi %k_id_pe_174, %cur_N_pe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc418)
      %offs_buf_k_pe_176 = tt.expand_dims %k_id_pe_175 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<64x1xi32, #blocked1> loc(#loc419)
      %offs_buf_k_pe_177 = arith.muli %offs_buf_k_pe_176, %offs_buf_k_pe_72 : tensor<64x1xi32, #blocked1> loc(#loc420)
      %offs_buf_k_pe_178 = tt.broadcast %offs_buf_k_pe_177 : tensor<64x1xi32, #blocked1> -> tensor<64x64xi32, #blocked1> loc(#loc421)
      %offs_buf_k_pe_179 = arith.addi %offs_buf_k_pe_178, %offs_buf_k_pe_76 : tensor<64x64xi32, #blocked1> loc(#loc421)
      %mask_k_id_180 = tt.splat %mask_k_id_158 : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc422)
      %mask_k_id_181 = arith.addi %mask_k_id_180, %cur_N_pe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc422)
      %mask_k_pe_182 = arith.cmpi slt, %mask_k_id_181, %mask_k_pe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc423)
      %mask_k_pe_combined = tt.expand_dims %mask_k_pe_182 {axis = 1 : i32} : tensor<64xi1, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<64x1xi1, #blocked1> loc(#loc424)
      %mask_k_pe_combined_183 = tt.broadcast %mask_k_pe_combined : tensor<64x1xi1, #blocked1> -> tensor<64x64xi1, #blocked1> loc(#loc425)
      %mask_k_pe_combined_184 = arith.andi %mask_k_pe_combined_183, %mask_k_r_combined_83 : tensor<64x64xi1, #blocked1> loc(#loc425)
      rocdl.sched.barrier 0 loc(#loc163)
      %k_pe_185 = amdgpu.buffer_load %K_Buffer[%offs_buf_k_pe_179], %mask_k_pe_combined_184 : tensor<64x64xbf16, #blocked1> loc(#loc426)
      %n_e_max_186 = "tt.reduce"(%qk_173) <{axis = 1 : i32}> ({
      ^bb0(%n_e_max_213: f32 loc(callsite(#loc at #loc427)), %n_e_max_214: f32 loc(callsite(#loc at #loc427))):
        %n_e_max_215 = arith.maxnumf %n_e_max_213, %n_e_max_214 : f32 loc(#loc530)
        tt.reduce.return %n_e_max_215 : f32 loc(#loc519)
      }) : (tensor<16x64xf32, #mma>) -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc519)
      %n_e_max_187 = ttg.convert_layout %n_e_max_186 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc428)
      %n_e_max_188 = arith.maxnumf %n_e_max_187, %e_max_145 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc429)
      %re_scale_189 = arith.subf %e_max_145, %n_e_max_188 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc430)
      %re_scale_190 = arith.mulf %re_scale_189, %cst_2 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc431)
      %re_scale_191 = math.exp2 %re_scale_190 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc432)
      %p_192 = tt.expand_dims %n_e_max_188 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc433)
      %p_193 = tt.broadcast %p_192 : tensor<16x1xf32, #mma> -> tensor<16x64xf32, #mma> loc(#loc434)
      %p_194 = arith.subf %qk_173, %p_193 : tensor<16x64xf32, #mma> loc(#loc434)
      %p_195 = arith.mulf %p_194, %cst_1 : tensor<16x64xf32, #mma> loc(#loc435)
      %p_196 = math.exp2 %p_195 : tensor<16x64xf32, #mma> loc(#loc436)
      %11 = arith.truncf %p_196 : tensor<16x64xf32, #mma> to tensor<16x64xbf16, #mma> loc(#loc177)
      ttg.local_store %11, %smem_p : tensor<16x64xbf16, #mma> -> !ttg.memdesc<16x64xbf16, #shared1, #smem, mutable> loc(#loc178)
      rocdl.sched.barrier 0 loc(#loc179)
      %cur_p_197 = ttg.local_load %smem_p : !ttg.memdesc<16x64xbf16, #shared1, #smem, mutable> -> tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc437)
      %smem_kv1_198 = ttg.memdesc_reinterpret %smem_kv1_142 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc438)
      %smem_kv2_199 = ttg.memdesc_reinterpret %smem_kv2_143 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc439)
      %12 = tt.trans %kv1_165 {order = array<i32: 1, 0>} : tensor<64x256xbf16, #blocked> -> tensor<256x64xbf16, #blocked6> loc(#loc183)
      ttg.local_store %12, %smem_kv1_198 : tensor<256x64xbf16, #blocked6> -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc183)
      %acc1_200 = tt.expand_dims %re_scale_191 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc440)
      %acc1_201 = tt.broadcast %acc1_200 : tensor<16x1xf32, #mma> -> tensor<16x256xf32, #mma> loc(#loc441)
      %acc1_202 = arith.mulf %arg20, %acc1_201 : tensor<16x256xf32, #mma> loc(#loc441)
      %acc1_203 = tt.dot %cur_p_197, %cur_k1_169, %acc1_202 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x256xf32, #mma> loc(#loc442)
      %e_sum_204 = arith.mulf %e_sum_144, %re_scale_191 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc443)
      %e_sum_205 = "tt.reduce"(%p_196) <{axis = 1 : i32}> ({
      ^bb0(%e_sum_213: f32 loc(callsite(#loc at #loc444)), %e_sum_214: f32 loc(callsite(#loc at #loc444))):
        %e_sum_215 = arith.addf %e_sum_213, %e_sum_214 : f32 loc(#loc531)
        tt.reduce.return %e_sum_215 : f32 loc(#loc521)
      }) : (tensor<16x64xf32, #mma>) -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc521)
      %e_sum_206 = arith.addf %e_sum_204, %e_sum_205 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc445)
      %13 = tt.trans %kv2_168 {order = array<i32: 1, 0>} : tensor<64x256xbf16, #blocked> -> tensor<256x64xbf16, #blocked6> loc(#loc192)
      ttg.local_store %13, %smem_kv2_199 : tensor<256x64xbf16, #blocked6> -> !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> loc(#loc192)
      %acc2_207 = arith.mulf %arg21, %acc1_201 : tensor<16x256xf32, #mma> loc(#loc446)
      %acc2_208 = tt.dot %cur_p_197, %cur_k2_170, %acc2_207 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x256xf32, #mma> loc(#loc447)
      %14 = tt.trans %k_pe_185 {order = array<i32: 1, 0>} : tensor<64x64xbf16, #blocked1> -> tensor<64x64xbf16, #blocked7> loc(#loc195)
      ttg.local_store %14, %smem_k_rope : tensor<64x64xbf16, #blocked7> -> !ttg.memdesc<64x64xbf16, #shared2, #smem, mutable> loc(#loc195)
      %cur_k1_209 = ttg.local_load %smem_kv1_198 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc448)
      rocdl.sched.barrier 0 loc(#loc197)
      %smem_kv1_210 = ttg.memdesc_reinterpret %smem_kv1_198 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc449)
      ttg.local_store %kv1_165, %smem_kv1_210 : tensor<64x256xbf16, #blocked> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc199)
      %cur_k2_211 = ttg.local_load %smem_kv2_199 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc450)
      rocdl.sched.barrier 0 loc(#loc201)
      %smem_kv2_212 = ttg.memdesc_reinterpret %smem_kv2_199 : !ttg.memdesc<256x64xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc451)
      ttg.local_store %kv2_168, %smem_kv2_212 : tensor<64x256xbf16, #blocked> -> !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc203)
      scf.yield %acc1_203, %acc2_208, %smem_kv1_210, %smem_kv2_212, %e_sum_206, %n_e_max_188, %cur_k1_209, %cur_k2_211 : tensor<16x256xf32, #mma>, tensor<16x256xf32, #mma>, !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable>, !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable>, tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>>, tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc204)
    } loc(#loc551)
    %qk = tt.dot %q0, %kv2_transpose#6, %cst_8 : tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x64xf32, #mma> loc(#loc452)
    %qk_89 = tt.dot %q1, %kv2_transpose#7, %qk : tensor<16x256xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<256x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x64xf32, #mma> loc(#loc453)
    %cur_k_pe = ttg.local_load %smem_k_rope : !ttg.memdesc<64x64xbf16, #shared2, #smem, mutable> -> tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc454)
    %qk_90 = tt.dot %q_pe_55, %cur_k_pe, %qk_89 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x64xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x64xf32, #mma> loc(#loc455)
    %cur_k1_91 = ttg.local_load %kv2_transpose#2 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> -> tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc456)
    %cur_k2_92 = ttg.local_load %kv2_transpose#3 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> -> tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> loc(#loc457)
    %qk_93 = tt.splat %sm_scale : f32 -> tensor<16x64xf32, #mma> loc(#loc458)
    %qk_94 = arith.mulf %qk_90, %qk_93 : tensor<16x64xf32, #mma> loc(#loc458)
    %mask_qk_n = arith.subi %split_kv_end_40, %c1_i32 : i32 loc(#loc459)
    %mask_qk_n_95 = arith.muli %mask_qk_n, %c64_i32 : i32 loc(#loc460)
    %mask_qk_n_96 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc461)
    %mask_qk_n_97 = tt.splat %mask_qk_n_95 : i32 -> tensor<64xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc462)
    %mask_qk_n_98 = arith.addi %mask_qk_n_97, %mask_qk_n_96 : tensor<64xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc462)
    %qk_99 = tt.expand_dims %mask_qk_n_98 {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x64xi32, #mma> loc(#loc463)
    %qk_100 = tt.splat %cur_batch_seq_len : i32 -> tensor<1x64xi32, #mma> loc(#loc464)
    %qk_101 = arith.cmpi slt, %qk_99, %qk_100 : tensor<1x64xi32, #mma> loc(#loc464)
    %qk_102 = tt.expand_dims %offs_om {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xi32, #mma> loc(#loc465)
    %qk_103 = arith.cmpi sge, %qk_102, %cst_4 : tensor<16x1xi32, #mma> loc(#loc466)
    %qk_104 = tt.broadcast %qk_101 : tensor<1x64xi1, #mma> -> tensor<16x64xi1, #mma> loc(#loc467)
    %qk_105 = tt.broadcast %qk_103 : tensor<16x1xi1, #mma> -> tensor<16x64xi1, #mma> loc(#loc467)
    %qk_106 = arith.andi %qk_104, %qk_105 : tensor<16x64xi1, #mma> loc(#loc467)
    %qk_107 = arith.select %qk_106, %qk_94, %cst_3 : tensor<16x64xi1, #mma>, tensor<16x64xf32, #mma> loc(#loc468)
    %n_e_max = "tt.reduce"(%qk_107) <{axis = 1 : i32}> ({
    ^bb0(%n_e_max_141: f32 loc(callsite(#loc at #loc469)), %n_e_max_142: f32 loc(callsite(#loc at #loc469))):
      %n_e_max_143 = arith.maxnumf %n_e_max_141, %n_e_max_142 : f32 loc(#loc532)
      tt.reduce.return %n_e_max_143 : f32 loc(#loc523)
    }) : (tensor<16x64xf32, #mma>) -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc523)
    %n_e_max_108 = ttg.convert_layout %n_e_max : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc470)
    %n_e_max_109 = arith.maxnumf %n_e_max_108, %kv2_transpose#5 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc471)
    %re_scale = arith.subf %kv2_transpose#5, %n_e_max_109 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc472)
    %re_scale_110 = arith.mulf %re_scale, %cst_2 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc473)
    %re_scale_111 = math.exp2 %re_scale_110 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc474)
    %p = tt.expand_dims %n_e_max_109 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc475)
    %p_112 = tt.broadcast %p : tensor<16x1xf32, #mma> -> tensor<16x64xf32, #mma> loc(#loc476)
    %p_113 = arith.subf %qk_107, %p_112 : tensor<16x64xf32, #mma> loc(#loc476)
    %p_114 = arith.mulf %p_113, %cst_1 : tensor<16x64xf32, #mma> loc(#loc477)
    %p_115 = math.exp2 %p_114 : tensor<16x64xf32, #mma> loc(#loc478)
    %5 = arith.truncf %p_115 : tensor<16x64xf32, #mma> to tensor<16x64xbf16, #mma> loc(#loc232)
    ttg.local_store %5, %smem_p : tensor<16x64xbf16, #mma> -> !ttg.memdesc<16x64xbf16, #shared1, #smem, mutable> loc(#loc233)
    %acc1 = tt.expand_dims %re_scale_111 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc479)
    %acc1_116 = tt.broadcast %acc1 : tensor<16x1xf32, #mma> -> tensor<16x256xf32, #mma> loc(#loc480)
    %acc1_117 = arith.mulf %kv2_transpose#0, %acc1_116 : tensor<16x256xf32, #mma> loc(#loc480)
    %acc2 = arith.mulf %kv2_transpose#1, %acc1_116 : tensor<16x256xf32, #mma> loc(#loc481)
    %e_sum_118 = arith.mulf %kv2_transpose#4, %re_scale_111 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc482)
    %e_sum_119 = "tt.reduce"(%p_115) <{axis = 1 : i32}> ({
    ^bb0(%e_sum_141: f32 loc(callsite(#loc at #loc483)), %e_sum_142: f32 loc(callsite(#loc at #loc483))):
      %e_sum_143 = arith.addf %e_sum_141, %e_sum_142 : f32 loc(#loc533)
      tt.reduce.return %e_sum_143 : f32 loc(#loc525)
    }) : (tensor<16x64xf32, #mma>) -> tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc525)
    %e_sum_120 = arith.addf %e_sum_118, %e_sum_119 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc484)
    rocdl.sched.barrier 0 loc(#loc240)
    %cur_p = ttg.local_load %smem_p : !ttg.memdesc<16x64xbf16, #shared1, #smem, mutable> -> tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> loc(#loc485)
    %acc1_121 = tt.dot %cur_p, %cur_k1_91, %acc1_117 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x256xf32, #mma> loc(#loc486)
    %acc2_122 = tt.dot %cur_p, %cur_k2_92, %acc2 : tensor<16x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 16}>> * tensor<64x256xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 16}>> -> tensor<16x256xf32, #mma> loc(#loc487)
    ttg.local_dealloc %kv2_transpose#2 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc244)
    ttg.local_dealloc %kv2_transpose#3 : !ttg.memdesc<64x256xbf16, #shared2, #smem, mutable> loc(#loc245)
    %acc = tt.join %acc1_121, %acc2_122 : tensor<16x256xf32, #mma> -> tensor<16x256x2xf32, #linear> loc(#loc488)
    %acc_123 = tt.trans %acc {order = array<i32: 0, 2, 1>} : tensor<16x256x2xf32, #linear> -> tensor<16x2x256xf32, #linear1> loc(#loc489)
    %acc_124 = tt.reshape %acc_123 : tensor<16x2x256xf32, #linear1> -> tensor<16x512xf32, #linear2> loc(#loc490)
    %acc_125 = ttg.convert_layout %acc_124 : tensor<16x512xf32, #linear2> -> tensor<16x512xf32, #mma> loc(#loc491)
    %smem_o = ttg.local_alloc : () -> !ttg.memdesc<16x512xf32, #shared, #smem, mutable> loc(#loc492)
    %e_sum_126 = arith.divf %cst_0, %e_sum_120 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc493)
    %6 = tt.expand_dims %e_sum_126 {axis = 1 : i32} : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<16x1xf32, #mma> loc(#loc252)
    %7 = tt.broadcast %6 : tensor<16x1xf32, #mma> -> tensor<16x512xf32, #mma> loc(#loc253)
    %8 = arith.mulf %acc_125, %7 : tensor<16x512xf32, #mma> loc(#loc253)
    ttg.local_store %8, %smem_o : tensor<16x512xf32, #mma> -> !ttg.memdesc<16x512xf32, #shared, #smem, mutable> loc(#loc254)
    %cur_o = ttg.local_load %smem_o : !ttg.memdesc<16x512xf32, #shared, #smem, mutable> -> tensor<16x512xf32, #blocked3> loc(#loc494)
    %cur_batch_out_offset = arith.muli %cur_batch_18, %stride_mid_ob : i32 loc(#loc495)
    %cur_batch_out_offset_127 = arith.muli %split_kv_id, %stride_mid_os : i32 loc(#loc496)
    %cur_batch_out_offset_128 = arith.addi %cur_batch_out_offset, %cur_batch_out_offset_127 : i32 loc(#loc497)
    %offs_mid_o = tt.splat %stride_mid_oh : i32 -> tensor<16x1xi32, #blocked3> loc(#loc498)
    %offs_mid_o_129 = arith.muli %offs_q, %offs_mid_o : tensor<16x1xi32, #blocked3> loc(#loc498)
    %offs_mid_o_130 = tt.splat %cur_batch_out_offset_128 : i32 -> tensor<16x1xi32, #blocked3> loc(#loc499)
    %offs_mid_o_131 = arith.addi %offs_mid_o_130, %offs_mid_o_129 : tensor<16x1xi32, #blocked3> loc(#loc499)
    %offs_mid_o_132 = tt.broadcast %offs_mid_o_131 : tensor<16x1xi32, #blocked3> -> tensor<16x512xi32, #blocked3> loc(#loc500)
    %offs_mid_o_133 = arith.addi %offs_mid_o_132, %offs_q_36 : tensor<16x512xi32, #blocked3> loc(#loc500)
    amdgpu.buffer_store %cur_o, %Att_Out[%offs_mid_o_133], %q_45 : tensor<16x512xf32, #blocked3> loc(#loc262)
    %offs_mid_lse = arith.muli %cur_batch_18, %stride_mid_lse_b : i32 loc(#loc501)
    %offs_mid_lse_134 = tt.splat %stride_mid_lse_h : i32 -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc502)
    %offs_mid_lse_135 = arith.muli %offs_om, %offs_mid_lse_134 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc502)
    %offs_mid_lse_136 = tt.splat %offs_mid_lse : i32 -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc503)
    %offs_mid_lse_137 = arith.addi %offs_mid_lse_136, %offs_mid_lse_135 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc503)
    %offs_mid_lse_138 = arith.muli %split_kv_id, %stride_mid_lse_s : i32 loc(#loc504)
    %offs_mid_lse_139 = tt.splat %offs_mid_lse_138 : i32 -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc505)
    %offs_mid_lse_140 = arith.addi %offs_mid_lse_137, %offs_mid_lse_139 : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc505)
    %mask_lse = arith.cmpi slt, %offs_om, %cst : tensor<16xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc506)
    %9 = math.log %e_sum_126 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc269)
    %10 = arith.subf %n_e_max_109, %9 : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc270)
    amdgpu.buffer_store %10, %Att_Lse[%offs_mid_lse_140], %mask_lse : tensor<16xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc271)
    tt.return loc(#loc272)
  } loc(#loc1)
} loc(#loc)
#loc2 = loc("/workspace/triton/python/triton/language/standard.py":41:22)
#loc3 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":243:53)
#loc4 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":229:54)
#loc5 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":74:24)
#loc6 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":77:31)
#loc7 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":39:16)
#loc8 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":78:54)
#loc9 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":40:23)
#loc10 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":45:13)
#loc11 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":45:7)
#loc12 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":46:35)
#loc13 = loc("/workspace/aiter/aiter/ops/triton/utils/_triton/pid_preprocessing.py":51:14)
#loc14 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":81:58)
#loc15 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":85:25)
#loc16 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":85:60)
#loc17 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":89:33)
#loc18 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":90:37)
#loc19 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":91:52)
#loc20 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":91:35)
#loc21 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":137:27)
#loc22 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":140:27)
#loc23 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":143:27)
#loc24 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":147:27)
#loc25 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":177:11)
#loc26 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":179:24)
#loc27 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":183:11)
#loc28 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":187:11)
#loc29 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":191:11)
#loc30 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":193:30)
#loc31 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":197:11)
#loc32 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":201:11)
#loc33 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":212:8)
#loc34 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":220:11)
#loc35 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":224:8)
#loc36 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":228:47)
#loc37 = loc("/workspace/triton/python/triton/language/standard.py":41:28)
#loc38 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":232:35)
#loc39 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":234:39)
#loc40 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":234:50)
#loc41 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":234:27)
#loc42 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":234:72)
#loc43 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":234:62)
#loc44 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":236:41)
#loc45 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":236:52)
#loc46 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":236:32)
#loc47 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":236:71)
#loc48 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":236:64)
#loc49 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":238:22)
#loc50 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":239:26)
#loc51 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":240:29)
#loc52 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":241:27)
#loc53 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":244:40)
#loc54 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":247:24)
#loc55 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":247:42)
#loc56 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":248:8)
#loc57 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":250:47)
#loc58 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":250:65)
#loc59 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":256:47)
#loc60 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":256:35)
#loc61 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":261:21)
#loc62 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":261:41)
#loc63 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":261:34)
#loc64 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":261:8)
#loc65 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":266:24)
#loc66 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":266:47)
#loc67 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":266:37)
#loc68 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":266:8)
#loc69 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":269:26)
#loc70 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":269:8)
#loc71 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":272:22)
#loc72 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":273:22)
#loc73 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":274:22)
#loc74 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":276:23)
#loc75 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":277:23)
#loc76 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":278:27)
#loc77 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":279:27)
#loc78 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":281:22)
#loc79 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":282:28)
#loc80 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":284:4)
#loc81 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":285:4)
#loc82 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":286:4)
#loc83 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":290:34)
#loc84 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":304:20)
#loc85 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":304:38)
#loc86 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":305:51)
#loc87 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":306:25)
#loc88 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":307:24)
#loc89 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":307:36)
#loc90 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":307:61)
#loc91 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":307:52)
#loc92 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":308:31)
#loc93 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":308:51)
#loc94 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":308:42)
#loc95 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":313:8)
#loc96 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":318:30)
#loc97 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":319:8)
#loc98 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":323:34)
#loc99 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":326:34)
#loc100 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":329:31)
#loc101 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":331:19)
#loc102 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":332:19)
#loc103 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":334:41)
#loc104 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":335:28)
#loc105 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":335:39)
#loc106 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":335:64)
#loc107 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":335:55)
#loc108 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":336:51)
#loc109 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":337:28)
#loc110 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":338:34)
#loc111 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":338:54)
#loc112 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":338:45)
#loc113 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":343:8)
#loc114 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":346:81)
#loc115 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":346:95)
#loc116 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":347:20)
#loc117 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":350:27)
#loc118 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":351:27)
#loc119 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":353:31)
#loc120 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":355:34)
#loc121 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":357:31)
#loc122 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":359:19)
#loc123 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":361:34)
#loc124 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":363:31)
#loc125 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":365:19)
#loc126 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":367:22)
#loc127 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":368:31)
#loc128 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":369:22)
#loc129 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":374:41)
#loc130 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":376:30)
#loc131 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":376:12)
#loc132 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":379:36)
#loc133 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":381:35)
#loc134 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":382:24)
#loc135 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":382:42)
#loc136 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":383:27)
#loc137 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":383:38)
#loc138 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":383:54)
#loc139 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":384:30)
#loc140 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":384:48)
#loc141 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":385:29)
#loc142 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":387:33)
#loc143 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":387:44)
#loc144 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":388:35)
#loc145 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":390:43)
#loc146 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":394:12)
#loc147 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":397:35)
#loc148 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":399:43)
#loc149 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":402:34)
#loc150 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":403:12)
#loc151 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":406:31)
#loc152 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":407:31)
#loc153 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":409:47)
#loc154 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":411:14)
#loc155 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":413:45)
#loc156 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":414:32)
#loc157 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":414:43)
#loc158 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":414:59)
#loc159 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":415:48)
#loc160 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":416:32)
#loc161 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":418:39)
#loc162 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":418:50)
#loc163 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":420:35)
#loc164 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":424:12)
#loc165 = loc("/workspace/triton/python/triton/language/standard.py":189:40)
#loc167 = loc("/workspace/triton/python/triton/language/standard.py":168:27)
#loc168 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":427:51)
#loc169 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":428:38)
#loc170 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":430:41)
#loc171 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":430:52)
#loc172 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":430:32)
#loc173 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":431:39)
#loc174 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":431:31)
#loc175 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":431:51)
#loc176 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":431:25)
#loc177 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":432:26)
#loc178 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":432:21)
#loc179 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":433:35)
#loc180 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":435:28)
#loc181 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":437:38)
#loc182 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":439:38)
#loc183 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":441:23)
#loc184 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":442:31)
#loc185 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":442:22)
#loc186 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":443:48)
#loc187 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":444:24)
#loc188 = loc("/workspace/triton/python/triton/language/standard.py":291:36)
#loc190 = loc("/workspace/triton/python/triton/language/standard.py":261:15)
#loc191 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":444:35)
#loc192 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":446:23)
#loc193 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":447:22)
#loc194 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":448:48)
#loc195 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":449:26)
#loc196 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":452:31)
#loc197 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":454:35)
#loc198 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":456:38)
#loc199 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":458:23)
#loc200 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":459:31)
#loc201 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":462:35)
#loc202 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":464:38)
#loc203 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":465:23)
#loc204 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":465:8)
#loc205 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":468:39)
#loc206 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":469:39)
#loc207 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":471:32)
#loc208 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":473:43)
#loc209 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":475:27)
#loc210 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":476:27)
#loc211 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":478:10)
#loc212 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":480:32)
#loc213 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":480:37)
#loc214 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":480:77)
#loc215 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":480:55)
#loc216 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":483:19)
#loc217 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":483:30)
#loc218 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":483:62)
#loc219 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":483:74)
#loc220 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":483:52)
#loc221 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":483:82)
#loc223 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":486:47)
#loc224 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":488:34)
#loc225 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":489:37)
#loc226 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":489:48)
#loc227 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":489:28)
#loc228 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":490:35)
#loc229 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":490:27)
#loc230 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":490:47)
#loc231 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":490:21)
#loc232 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":492:22)
#loc233 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":492:17)
#loc234 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":494:27)
#loc235 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":494:18)
#loc236 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":495:18)
#loc237 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":496:20)
#loc239 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":496:31)
#loc240 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":497:31)
#loc241 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":498:24)
#loc242 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":501:44)
#loc243 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":502:44)
#loc244 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":504:4)
#loc245 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":505:4)
#loc246 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":507:24)
#loc247 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":508:26)
#loc248 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":509:26)
#loc249 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":510:33)
#loc250 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":513:33)
#loc251 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":517:16)
#loc252 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":518:29)
#loc253 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":518:23)
#loc254 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":518:17)
#loc255 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":519:24)
#loc256 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":522:39)
#loc257 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":522:69)
#loc258 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":522:55)
#loc259 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":525:30)
#loc260 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":525:10)
#loc261 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":526:10)
#loc262 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":533:8)
#loc263 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":537:20)
#loc264 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":538:20)
#loc265 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":538:10)
#loc266 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":539:24)
#loc267 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":539:10)
#loc268 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":542:25)
#loc269 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":544:36)
#loc270 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":544:29)
#loc271 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":547:8)
#loc272 = loc("/workspace/aiter/aiter/ops/triton/gluon/mla_decode_mi355.py":543:4)
#loc292 = loc("blocks_per_split"(#loc3))
#loc293 = loc("cur_batch_block_nums"(#loc4))
#loc294 = loc("pid"(#loc5))
#loc295 = loc("pid_head_kv_split"(#loc6))
#loc296 = loc("xcd"(#loc7))
#loc297 = loc("pid_head_kv_split"(#loc8))
#loc298 = loc("local_pid"(#loc9))
#loc299 = loc("pid"(#loc12))
#loc300 = loc("pid"(#loc13))
#loc301 = loc("split_kv_id"(#loc14))
#loc302 = loc("cur_batch"(#loc15))
#loc303 = loc("cur_batch"(#loc16))
#loc304 = loc("kv_indptr_base"(#loc17))
#loc305 = loc("cur_batch_kv_start_idx"(#loc18))
#loc306 = loc("cur_batch_kv_end_idx"(#loc19))
#loc307 = loc("cur_batch_kv_end_idx"(#loc20))
#loc308 = loc("smem_q0_nope"(#loc21))
#loc309 = loc("smem_q1_nope"(#loc22))
#loc310 = loc("smem_q_rope"(#loc23))
#loc311 = loc("smem_p"(#loc24))
#loc312 = loc("cur_head"(#loc25))
#loc313 = loc("mask_h"(#loc26))
#loc314 = loc("cur_N"(#loc27))
#loc315 = loc("cur_N_pe"(#loc28))
#loc316 = loc("cur_head_pe"(#loc29))
#loc317 = loc("mask_h_pe"(#loc30))
#loc318 = loc("offs_c"(#loc31))
#loc319 = loc("offs_om"(#loc32))
#loc320 = loc("offs_qk_r"(#loc33))
#loc321 = loc("offs_k_c"(#loc34))
#loc322 = loc("offs_k_r"(#loc35))
#loc323 = loc("cur_batch_seq_len"(#loc36))
#loc324 = loc("cur_batch_offset"(#loc38))
#loc325 = loc("off_q_pe"(#loc39))
#loc326 = loc("off_q_pe"(#loc40))
#loc327 = loc("off_q_pe"(#loc41))
#loc328 = loc("off_q_pe"(#loc42))
#loc329 = loc("off_q_pe"(#loc43))
#loc330 = loc("offs_q"(#loc44))
#loc331 = loc("offs_q"(#loc45))
#loc332 = loc("offs_q"(#loc46))
#loc333 = loc("offs_q"(#loc47))
#loc334 = loc("offs_q"(#loc48))
#loc335 = loc("mask_c"(#loc49))
#loc336 = loc("mask_k_c"(#loc50))
#loc337 = loc("mask_qk_r"(#loc51))
#loc338 = loc("mask_k_r"(#loc52))
#loc339 = loc("split_kv_start"(#loc53))
#loc340 = loc("split_kv_end"(#loc57))
#loc341 = loc("split_kv_end"(#loc58))
#loc342 = loc("kv_indices_base"(#loc59))
#loc343 = loc("kv_indices_base"(#loc60))
#loc344 = loc("q"(#loc61))
#loc345 = loc("q"(#loc62))
#loc346 = loc("q"(#loc63))
#loc347 = loc("q"(#loc64))
#loc348 = loc("q_pe"(#loc65))
#loc349 = loc("q_pe"(#loc66))
#loc350 = loc("q_pe"(#loc67))
#loc351 = loc("q_pe"(#loc68))
#loc352 = loc("kv_loc"(#loc69))
#loc353 = loc("kv_loc"(#loc70))
#loc354 = loc("q"(#loc71))
#loc355 = loc("q"(#loc72))
#loc356 = loc("q0"(#loc76))
#loc357 = loc("q1"(#loc77))
#loc358 = loc("q_pe"(#loc79))
#loc359 = loc("smem_k_rope"(#loc83))
#loc360 = loc("k_id"(#loc84))
#loc361 = loc("k_id"(#loc85))
#loc362 = loc("mask_k_id"(#loc86))
#loc363 = loc("mask_k"(#loc87))
#loc364 = loc("offs_buf_kv"(#loc88))
#loc365 = loc("offs_buf_kv"(#loc89))
#loc366 = loc("offs_buf_kv"(#loc90))
#loc367 = loc("offs_buf_kv"(#loc91))
#loc368 = loc("mask_k_c_combined"(#loc92))
#loc369 = loc("mask_k_c_combined"(#loc93))
#loc370 = loc("mask_k_c_combined"(#loc94))
#loc371 = loc("kv1"(#loc95))
#loc372 = loc("kv2"(#loc96))
#loc373 = loc("kv2"(#loc97))
#loc374 = loc("smem_kv1"(#loc98))
#loc375 = loc("smem_kv2"(#loc99))
#loc376 = loc("k_id_pe"(#loc103))
#loc377 = loc("offs_buf_k_pe"(#loc104))
#loc378 = loc("offs_buf_k_pe"(#loc105))
#loc379 = loc("offs_buf_k_pe"(#loc106))
#loc380 = loc("offs_buf_k_pe"(#loc107))
#loc381 = loc("mask_k_id"(#loc108))
#loc382 = loc("mask_k_pe"(#loc109))
#loc383 = loc("mask_k_r_combined"(#loc110))
#loc384 = loc("mask_k_r_combined"(#loc111))
#loc385 = loc("mask_k_r_combined"(#loc112))
#loc386 = loc("k_pe"(#loc113))
#loc387 = loc("e_sum"(#loc114))
#loc388 = loc("e_sum"(#loc115))
#loc389 = loc("e_max"(#loc116))
#loc390 = loc("cur_k1"(#loc117))
#loc391 = loc("cur_k2"(#loc118))
#loc392 = loc("smem_kv1"(#loc120))
#loc393 = loc("smem_kv2"(#loc123))
#loc394 = loc("split_kv_start"(#loc128))
#loc395 = loc("kv_loc"(#loc129))
#loc396 = loc("kv_loc"(#loc130))
#loc397 = loc("kv_loc"(#loc131))
#loc398 = loc("cur_k_pe"(#loc132))
#loc399 = loc("k_id"(#loc134))
#loc400 = loc("k_id"(#loc135))
#loc401 = loc("offs_buf_kv"(#loc136))
#loc402 = loc("offs_buf_kv"(#loc137))
#loc403 = loc("offs_buf_kv"(#loc138))
#loc404 = loc("mask_k_id"(#loc139))
#loc405 = loc("mask_k_id"(#loc140))
#loc406 = loc("mask_k"(#loc141))
#loc407 = loc("mask_k_combined"(#loc142))
#loc408 = loc("mask_k_combined"(#loc143))
#loc409 = loc("qk"(#loc145))
#loc410 = loc("kv1"(#loc146))
#loc411 = loc("qk"(#loc148))
#loc412 = loc("kv2"(#loc149))
#loc413 = loc("kv2"(#loc150))
#loc414 = loc("cur_k1"(#loc151))
#loc415 = loc("cur_k2"(#loc152))
#loc416 = loc("qk"(#loc153))
#loc417 = loc("qk"(#loc154))
#loc418 = loc("k_id_pe"(#loc155))
#loc419 = loc("offs_buf_k_pe"(#loc156))
#loc420 = loc("offs_buf_k_pe"(#loc157))
#loc421 = loc("offs_buf_k_pe"(#loc158))
#loc422 = loc("mask_k_id"(#loc159))
#loc423 = loc("mask_k_pe"(#loc160))
#loc424 = loc("mask_k_pe_combined"(#loc161))
#loc425 = loc("mask_k_pe_combined"(#loc162))
#loc426 = loc("k_pe"(#loc164))
#loc428 = loc("n_e_max"(#loc168))
#loc429 = loc("n_e_max"(#loc169))
#loc430 = loc("re_scale"(#loc170))
#loc431 = loc("re_scale"(#loc171))
#loc432 = loc("re_scale"(#loc172))
#loc433 = loc("p"(#loc173))
#loc434 = loc("p"(#loc174))
#loc435 = loc("p"(#loc175))
#loc436 = loc("p"(#loc176))
#loc437 = loc("cur_p"(#loc180))
#loc438 = loc("smem_kv1"(#loc181))
#loc439 = loc("smem_kv2"(#loc182))
#loc440 = loc("acc1"(#loc184))
#loc441 = loc("acc1"(#loc185))
#loc442 = loc("acc1"(#loc186))
#loc443 = loc("e_sum"(#loc187))
#loc445 = loc("e_sum"(#loc191))
#loc446 = loc("acc2"(#loc193))
#loc447 = loc("acc2"(#loc194))
#loc448 = loc("cur_k1"(#loc196))
#loc449 = loc("smem_kv1"(#loc198))
#loc450 = loc("cur_k2"(#loc200))
#loc451 = loc("smem_kv2"(#loc202))
#loc452 = loc("qk"(#loc205))
#loc453 = loc("qk"(#loc206))
#loc454 = loc("cur_k_pe"(#loc207))
#loc455 = loc("qk"(#loc208))
#loc456 = loc("cur_k1"(#loc209))
#loc457 = loc("cur_k2"(#loc210))
#loc458 = loc("qk"(#loc211))
#loc459 = loc("mask_qk_n"(#loc212))
#loc460 = loc("mask_qk_n"(#loc213))
#loc461 = loc("mask_qk_n"(#loc214))
#loc462 = loc("mask_qk_n"(#loc215))
#loc463 = loc("qk"(#loc216))
#loc464 = loc("qk"(#loc217))
#loc465 = loc("qk"(#loc218))
#loc466 = loc("qk"(#loc219))
#loc467 = loc("qk"(#loc220))
#loc468 = loc("qk"(#loc221))
#loc470 = loc("n_e_max"(#loc223))
#loc471 = loc("n_e_max"(#loc224))
#loc472 = loc("re_scale"(#loc225))
#loc473 = loc("re_scale"(#loc226))
#loc474 = loc("re_scale"(#loc227))
#loc475 = loc("p"(#loc228))
#loc476 = loc("p"(#loc229))
#loc477 = loc("p"(#loc230))
#loc478 = loc("p"(#loc231))
#loc479 = loc("acc1"(#loc234))
#loc480 = loc("acc1"(#loc235))
#loc481 = loc("acc2"(#loc236))
#loc482 = loc("e_sum"(#loc237))
#loc484 = loc("e_sum"(#loc239))
#loc485 = loc("cur_p"(#loc241))
#loc486 = loc("acc1"(#loc242))
#loc487 = loc("acc2"(#loc243))
#loc488 = loc("acc"(#loc246))
#loc489 = loc("acc"(#loc247))
#loc490 = loc("acc"(#loc248))
#loc491 = loc("acc"(#loc249))
#loc492 = loc("smem_o"(#loc250))
#loc493 = loc("e_sum"(#loc251))
#loc494 = loc("cur_o"(#loc255))
#loc495 = loc("cur_batch_out_offset"(#loc256))
#loc496 = loc("cur_batch_out_offset"(#loc257))
#loc497 = loc("cur_batch_out_offset"(#loc258))
#loc498 = loc("offs_mid_o"(#loc259))
#loc499 = loc("offs_mid_o"(#loc260))
#loc500 = loc("offs_mid_o"(#loc261))
#loc501 = loc("offs_mid_lse"(#loc263))
#loc502 = loc("offs_mid_lse"(#loc264))
#loc503 = loc("offs_mid_lse"(#loc265))
#loc504 = loc("offs_mid_lse"(#loc266))
#loc505 = loc("offs_mid_lse"(#loc267))
#loc506 = loc("mask_lse"(#loc268))
#loc507 = loc(callsite(#loc2 at #loc292))
#loc508 = loc(callsite(#loc2 at #loc293))
#loc509 = loc(callsite(#loc296 at #loc297))
#loc510 = loc(callsite(#loc298 at #loc297))
#loc511 = loc(callsite(#loc10 at #loc297))
#loc512 = loc(callsite(#loc11 at #loc297))
#loc513 = loc("pid"(#loc299))
#loc514 = loc("pid"(#loc300))
#loc515 = loc(callsite(#loc300 at #loc297))
#loc516 = loc(callsite(#loc37 at #loc293))
#loc517 = loc(callsite(#loc37 at #loc292))
#loc518 = loc("acc1"(#loc395))
#loc519 = loc(callsite(#loc165 at #loc427))
#loc521 = loc(callsite(#loc188 at #loc444))
#loc523 = loc(callsite(#loc165 at #loc469))
#loc525 = loc(callsite(#loc188 at #loc483))
#loc527 = loc(callsite(#loc513 at #loc297))
#loc528 = loc(callsite(#loc514 at #loc297))
#loc529 = loc("acc2"(#loc518))
#loc530 = loc(callsite(#loc167 at #loc519))
#loc531 = loc(callsite(#loc190 at #loc521))
#loc532 = loc(callsite(#loc167 at #loc523))
#loc533 = loc(callsite(#loc190 at #loc525))
#loc534 = loc("k_id"(#loc529))
#loc535 = loc("mask_k_id"(#loc534))
#loc536 = loc("mask_k"(#loc535))
#loc537 = loc("offs_buf_kv"(#loc536))
#loc538 = loc("kv1"(#loc537))
#loc539 = loc("kv2"(#loc538))
#loc540 = loc("smem_kv1"(#loc539))
#loc541 = loc("smem_kv2"(#loc540))
#loc542 = loc("k_id_pe"(#loc541))
#loc543 = loc("offs_buf_k_pe"(#loc542))
#loc544 = loc("mask_k_pe"(#loc543))
#loc545 = loc("k_pe"(#loc544))
#loc546 = loc("e_sum"(#loc545))
#loc547 = loc("e_max"(#loc546))
#loc548 = loc("cur_k1"(#loc547))
#loc549 = loc("cur_k2"(#loc548))
#loc550 = loc("kv1_transpose"(#loc549))
#loc551 = loc("kv2_transpose"(#loc550))
