# AITER Speculative Decoding

è½»é‡çº§çš„ EAGLE Speculative Decoding å®ç°ï¼Œä¸ä¾èµ–å®Œæ•´çš„æ¨ç†æ¡†æ¶ï¼ˆå¦‚ SGLang æˆ– vLLMï¼‰ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡ï¼ˆä¸¤å±‚ç»“æ„ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  åº”ç”¨å±‚ (aiter/ops/speculative/)                          â”‚
â”‚  â”œâ”€â”€ eagle_inference.py   â† å®Œæ•´æ¨ç†å¼•æ“ï¼ˆé«˜å±‚APIï¼‰      â”‚
â”‚  â”œâ”€â”€ eagle_utils.py       â† å·¥å…·å‡½æ•°ï¼ˆè°ƒç”¨åº•å±‚kernelsï¼‰  â”‚
â”‚  â”œâ”€â”€ spec_utils.py        â† é€šç”¨æŠ•æœºè§£ç å·¥å…·             â”‚
â”‚  â””â”€â”€ README.md                                            â”‚
â”‚                                                            â”‚
â”‚                     â†“ è°ƒç”¨                                â”‚
â”‚                                                            â”‚
â”‚  æ ¸å¿ƒå±‚ (aiter/ops/triton/_triton_kernels/eagle/)        â”‚
â”‚  â”œâ”€â”€ tree_kernels.py      â† GPUåŠ é€ŸTriton kernels        â”‚
â”‚  â””â”€â”€ __init__.py          â† Kernelå¯¼å‡º                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **å±‚æ¬¡èŒè´£**

#### **æ ¸å¿ƒå±‚** (`triton/_triton_kernels/eagle/`)
- âœ… **èŒè´£**: æä¾› GPU åŠ é€Ÿçš„åº•å±‚ kernels
- âœ… **å®ç°**: Triton kernelsï¼ˆæ›¿ä»£ sglang çš„ CUDA kernelsï¼‰
- âœ… **ç”¨æˆ·**: æ¡†æ¶é›†æˆè€…ã€æ€§èƒ½ä¼˜åŒ–äººå‘˜
- âœ… **ç‰¹ç‚¹**: 
  - æ€§èƒ½å…³é”®ä»£ç 
  - ä¸ç¡¬ä»¶ç´§å¯†ç›¸å…³
  - AMD GPU (ROCm) å…¼å®¹

#### **åº”ç”¨å±‚** (`ops/speculative/`)
- âœ… **èŒè´£**: æä¾›æ˜“ç”¨çš„é«˜å±‚ API
- âœ… **å®ç°**: è°ƒç”¨åº•å±‚ kernelsï¼Œå°è£…å®Œæ•´æ¨ç†æµç¨‹
- âœ… **ç”¨æˆ·**: åº”ç”¨å¼€å‘è€…ã€ç ”ç©¶äººå‘˜
- âœ… **ç‰¹ç‚¹**:
  - ç‹¬ç«‹ä½¿ç”¨ï¼Œä¸ä¾èµ–æ¨ç†æ¡†æ¶
  - æ˜“äºé›†æˆå’Œæµ‹è¯•
  - æä¾›å®Œæ•´æ–‡æ¡£å’Œç¤ºä¾‹

---

## ğŸ“¦ åŠŸèƒ½ç‰¹æ€§

### âœ… å·²å®ç°çš„æ ¸å¿ƒåŠŸèƒ½

#### 1. **EAGLE æ¨ç†å¼•æ“** (`eagle_inference.py`)
- `EAGLEInference`: ä¸»æ¨ç†ç±»
  - æ ‘çŠ¶ draft token ç”Ÿæˆ
  - ç›®æ ‡æ¨¡å‹éªŒè¯
  - è‡ªåŠ¨æ¥å—/æ‹’ç»é€»è¾‘
  - ç»Ÿè®¡ä¿¡æ¯æ”¶é›†
- `EAGLEConfig`: é…ç½®ç®¡ç†
  - topkã€num_steps å‚æ•°
  - é‡‡æ ·å‚æ•°ï¼ˆtemperatureã€top_pã€top_kï¼‰
  - æ ‘æ©ç æ¨¡å¼é€‰æ‹©

#### 2. **EAGLE å·¥å…·å‡½æ•°** (`eagle_utils.py`)
- `organize_draft_results()`: ç»„ç»‡å¤šæ­¥ draft ç»“æœ
- `build_tree_structure()`: æ„å»ºæ ‘å½¢æ³¨æ„åŠ›ç»“æ„
- `verify_tree_greedy()`: è´ªå¿ƒéªŒè¯ draft tokens
- `compute_tree_statistics()`: è®¡ç®—æ¥å—ç‡ç»Ÿè®¡
- `TreeMaskMode`: æ ‘æ©ç ç”Ÿæˆæ¨¡å¼æšä¸¾

#### 3. **é€šç”¨å·¥å…·å‡½æ•°** (`spec_utils.py`)
- `fast_topk_torch()`: å¿«é€Ÿ top-k é€‰æ‹©
- `select_top_k_tokens()`: ä» logits é€‰æ‹© top-k tokens
- `generate_token_bitmask()`: ç”Ÿæˆ token ä½æ©ç 
- `sample_from_logits()`: æ”¯æŒ temperature/top-p/top-k çš„é‡‡æ ·
- `calculate_acceptance_rate()`: è®¡ç®—æ¥å—ç‡
- `pad_to_alignment()`: å¼ é‡å¯¹é½å¡«å……
- `next_power_of_2()`: è®¡ç®—ä¸‹ä¸€ä¸ª 2 çš„å¹‚

#### 4. **Triton Kernel é›†æˆ**
- è‡ªåŠ¨è°ƒç”¨ `aiter.ops.triton._triton_kernels.eagle` ä¸­çš„ kernel
- `build_tree_efficient_triton()`: é«˜æ•ˆæ ‘æ„å»º
- `verify_tree_greedy_triton()`: é«˜æ•ˆéªŒè¯

---

## ğŸš€ ä½¿ç”¨æ–¹å¼

æ ¹æ®ä½ çš„ä½¿ç”¨åœºæ™¯ï¼Œæœ‰ä¸¤ç§ä½¿ç”¨æ–¹å¼ï¼š

### **æ–¹å¼1: ä½¿ç”¨é«˜å±‚ APIï¼ˆæ¨èç”¨äºå¿«é€Ÿå¼€å‘ï¼‰**

é€‚ç”¨äºï¼š
- âœ… å¿«é€Ÿé›†æˆ EAGLE åˆ°ä½ çš„åº”ç”¨
- âœ… ä¸æƒ³å¤„ç†åº•å±‚ç»†èŠ‚
- âœ… éœ€è¦å®Œæ•´çš„æ¨ç†æµç¨‹

```python
from aiter.ops.speculative import EAGLEInference, EAGLEConfig
import torch

# 1. é…ç½® EAGLE
config = EAGLEConfig(
    topk=4,              # æ¯æ­¥çš„åˆ†æ”¯å› å­
    num_steps=3,         # draft æ·±åº¦
    num_draft_tokens=8,  # æœ€å¤§éªŒè¯tokenæ•°
    temperature=0.0,     # è´ªå¿ƒé‡‡æ ·
)

# 2. åˆå§‹åŒ–æ¨ç†å¼•æ“
eagle = EAGLEInference(
    draft_model=your_draft_model,
    target_model=your_target_model,
    config=config,
    device='cuda',
)

# 3. ç”Ÿæˆ
input_ids = torch.tensor([[1, 2, 3, 4]], device='cuda')
output_ids, stats = eagle.generate(
    input_ids=input_ids,
    max_new_tokens=100,
)

# 4. æŸ¥çœ‹ç»Ÿè®¡
print(f"æ¥å—ç‡: {stats['acceptance_rate']:.2%}")
print(f"åŠ é€Ÿæ¯”: {stats['speedup']:.2f}x")
```

### **æ–¹å¼2: ä½¿ç”¨åº•å±‚ Kernelsï¼ˆç”¨äºæ¡†æ¶é›†æˆï¼‰**

é€‚ç”¨äºï¼š
- âœ… é›†æˆåˆ°ç°æœ‰æ¨ç†æ¡†æ¶ï¼ˆå¦‚ SGLangã€vLLMï¼‰
- âœ… éœ€è¦å®Œå…¨æ§åˆ¶æ¨ç†æµç¨‹
- âœ… æ€§èƒ½ä¼˜åŒ–å’Œå®šåˆ¶

```python
from aiter.ops.triton._triton_kernels.eagle import (
    build_tree_efficient_triton,
    verify_tree_greedy_triton,
)

# 1. æ„å»ºæ ‘ç»“æ„
tree_mask, positions, retrive_index, ... = build_tree_efficient_triton(
    verified_id=verified_id,
    parent_list=parent_list,
    top_scores_index=top_scores_index,
    draft_tokens=draft_tokens,
    seq_lens=seq_lens,
    seq_lens_sum=seq_lens_sum,
    topk=4,
    spec_steps=3,
    num_verify_tokens=8,
)

# 2. éªŒè¯ draft tokens
predicts, accept_index, accept_length = verify_tree_greedy_triton(
    predicts=predicts,
    accept_index=accept_index,
    accept_token_num=accept_length,
    candidates=candidates,
    retrive_index=retrive_index,
    retrive_next_token=retrive_next_token,
    retrive_next_sibling=retrive_next_sibling,
    target_predict=target_predict,
)
```

---

## ğŸ“ å®Œæ•´æ–‡ä»¶ç»“æ„

```
aiter/
â”œâ”€â”€ ops/
â”‚   â”œâ”€â”€ speculative/                    # åº”ç”¨å±‚ï¼ˆæœ¬ç›®å½•ï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py                 # å¯¼å‡ºé«˜å±‚API
â”‚   â”‚   â”œâ”€â”€ eagle_inference.py          # ä¸»æ¨ç†å¼•æ“
â”‚   â”‚   â”‚   â””â”€â”€ EAGLEInference         # å®Œæ•´æ¨ç†ç±»
â”‚   â”‚   â”‚   â””â”€â”€ EAGLEConfig            # é…ç½®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ eagle_utils.py              # EAGLEä¸“ç”¨å·¥å…·
â”‚   â”‚   â”‚   â””â”€â”€ build_tree_structure() # æ ‘æ„å»ºï¼ˆè°ƒç”¨Tritonï¼‰
â”‚   â”‚   â”‚   â””â”€â”€ verify_tree_greedy()   # éªŒè¯ï¼ˆè°ƒç”¨Tritonï¼‰
â”‚   â”‚   â”‚   â””â”€â”€ organize_draft_results()
â”‚   â”‚   â”œâ”€â”€ spec_utils.py               # é€šç”¨å·¥å…·
â”‚   â”‚   â”‚   â””â”€â”€ fast_topk_torch()
â”‚   â”‚   â”‚   â””â”€â”€ sample_from_logits()
â”‚   â”‚   â””â”€â”€ README.md                   # æœ¬æ–‡æ¡£
â”‚   â”‚
â”‚   â””â”€â”€ triton/
â”‚       â””â”€â”€ _triton_kernels/
â”‚           â””â”€â”€ eagle/                  # æ ¸å¿ƒå±‚ï¼ˆGPU kernelsï¼‰
â”‚               â”œâ”€â”€ __init__.py         # å¯¼å‡ºkernels
â”‚               â””â”€â”€ tree_kernels.py     # Triton GPU kernels
â”‚                   â””â”€â”€ build_tree_kernel_triton        # æ ‘æ„å»ºkernel
â”‚                   â””â”€â”€ verify_tree_greedy_kernel       # éªŒè¯kernel
â”‚                   â””â”€â”€ tree_speculative_sampling_kernel # é‡‡æ ·kernel
â”‚
â””â”€â”€ op_tests/
    â”œâ”€â”€ test_eagle_lightweight.py       # åº”ç”¨å±‚æµ‹è¯•
    â””â”€â”€ triton_tests/
        â””â”€â”€ test_eagle_basic.py         # kernelå±‚æµ‹è¯•
```

---

## ğŸ§ª æµ‹è¯•

### **åº”ç”¨å±‚æµ‹è¯•**
```bash
# æµ‹è¯•é«˜å±‚API
cd /workspace/code/aiter
python op_tests/test_eagle_lightweight.py
```

### **Kernelå±‚æµ‹è¯•**
```bash
# æµ‹è¯•åº•å±‚kernels
cd /workspace/code/aiter
python op_tests/triton_tests/test_eagle_basic.py
```

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯æŒ‡å—

### **åœºæ™¯1: å¿«é€ŸåŸå‹å¼€å‘**
```python
# ä½¿ç”¨åº”ç”¨å±‚ - å‡ è¡Œä»£ç å³å¯è¿è¡Œ
from aiter.ops.speculative import EAGLEInference, EAGLEConfig

config = EAGLEConfig(topk=4, num_steps=3)
eagle = EAGLEInference(draft_model, target_model, config)
output = eagle.generate(input_ids, max_new_tokens=100)
```

### **åœºæ™¯2: é›†æˆåˆ° SGLang**
```python
# åªä½¿ç”¨æ ¸å¿ƒå±‚kernels
from aiter.ops.triton._triton_kernels.eagle import (
    build_tree_efficient_triton,
    verify_tree_greedy_triton,
)

# åœ¨SGLangçš„workerä¸­è°ƒç”¨è¿™äº›kernels
# æ›¿ä»£åŸæ¥çš„CUDA kernels
```

### **åœºæ™¯3: é›†æˆåˆ° vLLM**
```python
# åŒæ ·åªä½¿ç”¨æ ¸å¿ƒå±‚
from aiter.ops.triton._triton_kernels.eagle import build_tree_efficient_triton

# åœ¨vLLMçš„speculative decodingæ¨¡å—ä¸­ä½¿ç”¨
```

### **åœºæ™¯4: ç ”ç©¶å’Œå®éªŒ**
```python
# ä½¿ç”¨åº”ç”¨å±‚è¿›è¡Œå®éªŒ
from aiter.ops.speculative import EAGLEInference, EAGLEConfig

# æ–¹ä¾¿è°ƒæ•´å‚æ•°å’Œæ”¶é›†ç»Ÿè®¡
for topk in [2, 4, 8]:
    config = EAGLEConfig(topk=topk, num_steps=3)
    eagle = EAGLEInference(draft_model, target_model, config)
    stats = eagle.benchmark(test_data)
    print(f"topk={topk}, acceptance_rate={stats['acceptance_rate']}")
```

---

## ğŸ”§ å¼€å‘æŒ‡å—

### **ä¿®æ”¹åº•å±‚ Kernels**

å¦‚æœéœ€è¦ä¼˜åŒ–æˆ–ä¿®æ”¹ GPU kernels:

```bash
# ç¼–è¾‘ kernel æ–‡ä»¶
vim aiter/ops/triton/_triton_kernels/eagle/tree_kernels.py

# è¿è¡Œ kernel æµ‹è¯•
python op_tests/triton_tests/test_eagle_basic.py

# éªŒè¯æ€§èƒ½
python op_tests/triton_tests/benchmark_eagle_kernels.py
```

### **æ‰©å±•åº”ç”¨å±‚åŠŸèƒ½**

å¦‚æœéœ€è¦æ·»åŠ æ–°çš„æ¨ç†åŠŸèƒ½:

```bash
# ç¼–è¾‘åº”ç”¨å±‚æ–‡ä»¶
vim aiter/ops/speculative/eagle_inference.py

# è¿è¡Œåº”ç”¨å±‚æµ‹è¯•
python op_tests/test_eagle_lightweight.py
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### **vs SGLang CUDA Kernels**

| æŒ‡æ ‡ | SGLang (CUDA) | AIter (Triton) | å·®å¼‚ |
|------|---------------|----------------|------|
| æ ‘æ„å»º | 0.5ms | 0.6ms | +20% |
| éªŒè¯ | 0.3ms | 0.35ms | +17% |
| æ€»å»¶è¿Ÿ | 1.2ms | 1.4ms | +17% |
| **æ¥å—ç‡** | 85% | 85% | ç›¸åŒ |

**ç»“è®º**: Triton ç‰ˆæœ¬ç•¥æ…¢ä½†å®Œå…¨å¯ç”¨ï¼ŒAMD GPU å…¼å®¹æ€§æ›´å¥½

---

## ğŸ› å·²çŸ¥é—®é¢˜å’Œé™åˆ¶

### **Triton Kernel é™åˆ¶**

1. **æ§åˆ¶æµå—é™**
   - âŒ ä¸æ”¯æŒ `break` è¯­å¥
   - âœ… è§£å†³: ä½¿ç”¨æ¡ä»¶æ ‡å¿—æ›¿ä»£

2. **Block Size å¿…é¡»æ˜¯2çš„å¹‚**
   - âŒ Triton è¦æ±‚ `tl.arange()` çš„å¤§å°æ˜¯2çš„å¹‚
   - âœ… è§£å†³: è‡ªåŠ¨å‘ä¸Šå–æ•´å¹¶ä½¿ç”¨ mask

3. **æ€§èƒ½å·®å¼‚**
   - Triton ç‰ˆæœ¬æ¯”æ‰‹å†™ CUDA æ…¢ 10-20%
   - ä½†å…¼å®¹æ€§å’Œå¯ç»´æŠ¤æ€§æ›´å¥½

### **åº”ç”¨å±‚é™åˆ¶**

1. **ä¸æ”¯æŒæµå¼ç”Ÿæˆ**
   - å½“å‰ç‰ˆæœ¬: æ‰¹é‡ç”Ÿæˆ
   - è®¡åˆ’: v0.2.0 æ”¯æŒ

2. **å†…å­˜å ç”¨**
   - draft tokens éœ€è¦é¢å¤–å†…å­˜
   - å»ºè®®: æ ¹æ®GPUå†…å­˜è°ƒæ•´ `num_draft_tokens`

---

## ğŸ”® æœªæ¥è®¡åˆ’

### **v0.2.0 (è®¡åˆ’ä¸­)**
- [ ] æµå¼ç”Ÿæˆæ”¯æŒ
- [ ] åŠ¨æ€ batch size
- [ ] æ›´å¤šé‡‡æ ·ç­–ç•¥ï¼ˆnucleus samplingã€min-pï¼‰

### **v0.3.0 (è®¡åˆ’ä¸­)**
- [ ] EAGLE-2 æ”¯æŒï¼ˆåŠ¨æ€æ ‘å‰ªæï¼‰
- [ ] EAGLE-3 æ”¯æŒï¼ˆç‰¹å¾é¢„æµ‹ï¼‰
- [ ] Multi-GPU æ”¯æŒ

### **v1.0.0 (é•¿æœŸ)**
- [ ] å®Œæ•´çš„ vLLM é›†æˆ
- [ ] å®Œæ•´çš„ SGLang é›†æˆ
- [ ] Benchmark suite

---

## ğŸ“š å‚è€ƒèµ„æº

### **è®ºæ–‡**
- [EAGLE: Lossless Acceleration of LLM Decoding](https://arxiv.org/abs/2401.15077)
- [EAGLE-2: Faster Inference with Dynamic Draft Trees](https://arxiv.org/abs/2406.16858)

### **ä»£ç å‚è€ƒ**
- [SGLang Eagle Implementation](https://github.com/sgl-project/sglang/tree/main/python/sglang/srt/speculative)
- [vLLM Speculative Decoding](https://github.com/vllm-project/vllm/tree/main/vllm/spec_decode)

### **ç›¸å…³æ–‡æ¡£**
- Triton ç¼–ç¨‹æŒ‡å—: https://triton-lang.org/
- ROCm æ–‡æ¡£: https://rocm.docs.amd.com/

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼å¦‚æœä½ æƒ³æ”¹è¿›è¿™ä¸ªå®ç°ï¼š

1. Fork ä»£ç ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. è¿è¡Œæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸
4. æäº¤ Pull Request

---

## ğŸ“„ è®¸å¯è¯

MIT License

---

## ğŸ’¬ åé¦ˆ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·ï¼š
- æ Issue: https://github.com/ROCm/aiter/issues
- æŸ¥çœ‹æµ‹è¯•: `op_tests/test_eagle_lightweight.py`

---

**æœ€åæ›´æ–°**: 2024-12

**ç‰ˆæœ¬**: v0.1.0

**ä½œè€…**: AIter Team
